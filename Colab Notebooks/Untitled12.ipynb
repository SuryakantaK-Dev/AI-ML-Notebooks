{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMfu26oMUjSscAs73mwhOlU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sf9VPy5EMuM6","outputId":"0ff5d812-dc8b-4685-956f-37bba246930c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Training with Adam\n"]}],"source":["import torch\n","import torchvision\n","from torchvision import transforms, datasets\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Subset\n","import matplotlib.pyplot as plt\n","\n","# Check if CUDA is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define the transforms for data augmentation\n","transform_train = transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","])\n","\n","# Choose the dataset based on the roll number\n","roll_no = 207  # Replace with your roll number\n","mod_value = roll_no % 3\n","if mod_value == 0:\n","    dataset_name = \"STL10\"\n","    full_trainset = datasets.STL10(root='./data', split='train', download=True, transform=transform_train)\n","    full_testset = datasets.STL10(root='./data', split='test', download=True, transform=transform_test)\n","elif mod_value == 1:\n","    dataset_name = \"SVHN\"\n","    full_trainset = datasets.SVHN(root='./data', split='train', download=True, transform=transform_train)\n","    full_testset = datasets.SVHN(root='./data', split='test', download=True, transform=transform_test)\n","else:\n","    dataset_name = \"FashionMNIST\"\n","    full_trainset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform_train)\n","    full_testset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform_test)\n","\n","# Define the data loaders with sub-sampling\n","train_indices = torch.randperm(len(full_trainset))[:10000]\n","test_indices = torch.randperm(len(full_testset))[:2000]\n","\n","trainset = Subset(full_trainset, train_indices)\n","testset = Subset(full_testset, test_indices)\n","\n","trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n","testloader = DataLoader(testset, batch_size=32, shuffle=False)\n","\n","# Load the pre-trained ResNet101 model\n","model = torchvision.models.resnet101(pretrained=True)\n","\n","# Freeze convolutional layers\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# Modify the fully connected layer\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 10)  # 10 classes for our datasets\n","model = model.to(device)\n","\n","# Define the loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# Define the optimizers\n","optimizers = {\n","    \"Adam\": optim.Adam(model.parameters(), lr=0.001),\n","    \"Adagrad\": optim.Adagrad(model.parameters(), lr=0.01),\n","    \"Adadelta\": optim.Adadelta(model.parameters(), lr=1.0),\n","    \"RMSprop\": optim.RMSprop(model.parameters(), lr=0.001)\n","}\n","\n","# Training function\n","def train(optimizer):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (inputs, targets) in enumerate(trainloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","    train_loss = running_loss / len(trainloader)\n","    train_acc = 100. * correct / total\n","    return train_loss, train_acc\n","\n","# Testing function\n","def test():\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(testloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","    test_loss /= len(testloader)\n","    test_acc = 100. * correct / total\n","    return test_loss, test_acc\n","\n","# Training loop for each optimizer\n","epochs = 10\n","for optimizer_name, optimizer in optimizers.items():\n","    train_losses = []\n","    train_accuracies = []\n","    test_losses = []\n","    test_accuracies = []\n","\n","    print(f\"Training with {optimizer_name}\")\n","    for epoch in range(epochs):\n","        train_loss, train_acc = train(optimizer)\n","        test_loss, test_acc = test()\n","\n","        train_losses.append(train_loss)\n","        train_accuracies.append(train_acc)\n","        test_losses.append(test_loss)\n","        test_accuracies.append(test_acc)\n","\n","        print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n","              f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n","\n","    # Plotting\n","    plt.figure(figsize=(10, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n","    plt.plot(range(1, epochs + 1), test_losses, label='Test Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.title(f'Loss Curve ({optimizer_name})')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(range(1, epochs + 1), train_accuracies, label='Training Accuracy')\n","    plt.plot(range(1, epochs + 1), test_accuracies, label='Test Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy (%)')\n","    plt.title(f'Accuracy Curve ({optimizer_name})')\n","    plt.legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Report final top-5 test accuracy\n","model.eval()\n","top5_correct = 0\n","total = 0\n","with torch.no_grad():\n","    for inputs, targets in testloader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        outputs = model(inputs)\n","        _, predicted = outputs.topk(5, 1, True, True)\n","        targets = targets.view(-1, 1)\n","        top5_correct += predicted.eq(targets).sum().item()\n","        total += targets.size(0)\n","\n","top5_acc = 100. * top5_correct / total\n","print(f\"Final Top-5 Test Accuracy: {top5_acc:.2f}%\")\n"]}]}