{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPbozhnyPGS2aeqrDmSRDV6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Kl6Mano_6i3","executionInfo":{"status":"ok","timestamp":1694890632434,"user_tz":-330,"elapsed":5886,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"fe4d3600-a76b-4970-d73a-56de9b01386f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","os.chdir('/content/drive/MyDrive/surya/DL_Assignment/Fractal-1_Assignment-1')"]},{"cell_type":"code","source":["import torch\n","import torchvision.models as models\n","model = models.resnet18(pretrained=True)\n","\n","import random\n","import os\n","random.seed(42) # for reproducibility\n","category_A = \"aeroplane\"\n","category_not_A = []\n","image_names_A = []\n","image_names_not_A = []\n","selected_images_not_A = []\n","# read the file names from the ImageSets folder\n","with open(f\"/content/drive/MyDrive/surya/DL_Assignment/Fractal-1_Assignment-1/VOC2011/TrainVal/VOCdevkit/VOC2011/ImageSets/Main/{category_A}_train.txt\", \"r\") as f:\n","    for line in f:\n","        image_name, label = line.split()\n","        if label == \"1\": # image belongs to category A\n","            image_names_A.append(image_name)\n","        elif label == \"-1\": # image does not belong to category A\n","            image_names_not_A.append(image_name)\n","# randomly select 20%-50% images from category A\n","num_images_A = len(image_names_A)\n","num_select_A = random.randint(int(0.2 * num_images_A), int(0.5 * num_images_A))\n","selected_images_A = random.sample(image_names_A, num_select_A)\n","# randomly select 10% images from each of the remaining categories\n","for file in os.listdir(\"/content/drive/MyDrive/surya/DL_Assignment/Fractal-1_Assignment-1/VOC2011/TrainVal/VOCdevkit/VOC2011/ImageSets/Main\"):\n","    if file.endswith(\"_train.txt\") and file != f\"{category_A}_train.txt\":\n","        category = file.split(\"_\")[0]\n","        category_not_A.append(category)\n","        image_names = []\n","        with open(f\"/content/drive/MyDrive/surya/DL_Assignment/Fractal-1_Assignment-1/VOC2011/TrainVal/VOCdevkit/VOC2011/ImageSets/Main/{file}\", \"r\") as f:\n","            for line in f:\n","                image_name, label = line.split()\n","                if label == \"-1\": # image does not belong to category A\n","                    image_names.append(image_name)\n","        num_images = len(image_names)\n","        num_select = int(0.1 * num_images)\n","        selected_images_not_A.extend(random.sample(image_names, num_select))\n","# combine the selected images from both categories\n","training_images = selected_images_A + selected_images_not_A\n","# shuffle the training images\n","random.shuffle(training_images)\n","#print(training_images)\n","\n","\n","import torchvision.transforms as transforms\n","from PIL import Image\n","# define a transform function to resize and normalize the images\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","# set the model to evaluation mode and disable gradient computation\n","model.eval()\n","with torch.no_grad():\n","    # create an empty feature matrix with shape (number of training images, 1000)\n","    features = torch.zeros((len(training_images), 1000))\n","    # loop through the training images and extract features\n","    for i, image_name in enumerate(training_images):\n","        # load the image from the JPEGImages folder\n","        image = Image.open(f\"/content/drive/MyDrive/surya/DL_Assignment/Fractal-1_Assignment-1/VOC2011/TrainVal/VOCdevkit/VOC2011/JPEGImages/{image_name}.jpg\")\n","        # apply the transform function to the image\n","        image = transform(image)\n","        # add a batch dimension to the image tensor\n","        image = image.unsqueeze(0)\n","        # pass the image through the model and get the output of the last fully-connected layer\n","        #output = model.fc(model(image))\n","        output = model(image)\n","        # store the output in the feature matrix\n","        features[i] = output\n","\n","import torch\n","import os\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","# create an empty feature matrix with shape (number of validation images, 1000)\n","val_features = torch.zeros((5823, 1000))\n","# create an empty label vector with shape (number of validation images,)\n","val_labels = torch.zeros((5823,))\n","# loop through the validation images and extract features and labels\n","for i, file in enumerate(os.listdir(\"/content/drive/MyDrive/surya/DL_Assignment/Fractal-1_Assignment-1/VOC2011/TrainVal/VOCdevkit/VOC2011/ImageSets/Main\")):\n","    if file.endswith(\"_val.txt\"):\n","        category = file.split(\"_\")[0]\n","        with open(f\"/content/drive/MyDrive/surya/DL_Assignment/Fractal-1_Assignment-1/VOC2011/TrainVal/VOCdevkit/VOC2011/ImageSets/Main/{file}\", \"r\") as f:\n","            for j, line in enumerate(f):\n","                image_name, label = line.split()\n","                # load the image from the JPEGImages folder\n","                image = Image.open(f\"/content/drive/MyDrive/surya/DL_Assignment/Fractal-1_Assignment-1/VOC2011/TrainVal/VOCdevkit/VOC2011/JPEGImages/{image_name}.jpg\")\n","                # apply the transform function to the image\n","                image = transform(image)\n","                # add a batch dimension to the image tensor\n","                image = image.unsqueeze(0)\n","                # pass the image through the model and get the output of the last fully-connected layer\n","                #output = model.fc(model(image))\n","                output = model(image)\n","                # store the output in the feature matrix\n","                val_features[i * 582 + j] = output\n","                # store the label in the label vector\n","                if category == category_A:\n","                    val_labels[i * 582 + j] = int(label)\n","                else:\n","                    val_labels[i * 582 + j] = -int(label)\n","# create a kNN classifier with k=5 and Euclidean distance\n","knn = KNeighborsClassifier(n_neighbors=5, metric=\"euclidean\")\n","# fit the classifier on the training features and labels\n","knn.fit(features, torch.ones((len(training_images),))) # use 1 for category A and 0 for category not A\n","# predict the labels for the validation features\n","val_pred = knn.predict(val_features)\n","# calculate and print the accuracy score\n","acc = accuracy_score(val_labels, val_pred)\n","print(f\"Accuracy: {acc}\")\n","# calculate and print the confusion matrix\n","cm = confusion_matrix(val_labels, val_pred)\n","print(f\"Confusion matrix:\\n{cm}\")\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","# create a figure and an axis object\n","fig, ax = plt.subplots()\n","# plot a heatmap of the confusion matrix using seaborn\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n","# set the axis labels and title\n","ax.set_xlabel(\"Predicted label\")\n","ax.set_ylabel(\"True label\")\n","ax.set_title(\"Confusion matrix\")\n","# show the plot\n","plt.show()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"uQXRShoq_9xY","executionInfo":{"status":"error","timestamp":1694889099121,"user_tz":-330,"elapsed":2564353,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"3e78d7c9-ecb0-4e17-d240-1b9ba0ba9049"},"execution_count":3,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-4018574b8950>\u001b[0m in \u001b[0;36m<cell line: 84>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;31m# store the output in the feature matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mval_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m582\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# store the label in the label vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcategory_A\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 13386 is out of bounds for dimension 0 with size 5823"]}]}]}