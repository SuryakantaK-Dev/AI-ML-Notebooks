{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6399,"status":"ok","timestamp":1708449984562,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"},"user_tz":-330},"id":"lbcrn1RRwxtG","outputId":"a3ed0337-87a9-4a23-bab1-a76104c68e73"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","os.chdir('/content/drive/MyDrive/surya/NLP_Assignment/')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1708449984563,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"},"user_tz":-330},"id":"SZ9M1U000Fgw","outputId":"aa7547c1-3b88-4162-c444-864aea4f71ba"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["# Download the necessary NLTK resources\n","import nltk\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1JNXgITtxjzK","outputId":"45c89cda-3db6-4685-82ba-831f9d03d876","executionInfo":{"status":"ok","timestamp":1708450148073,"user_tz":-330,"elapsed":163514,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a502eaf27f0f>:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n","\n","\n","  df =  pd.read_csv('NER_Dataset.csv',error_bad_lines=False, engine=\"python\")\n","Skipping line 6553: unexpected end of data\n"]}],"source":["# Import the libraries\n","import pandas as pd\n","import spacy\n","import nltk\n","from nltk.tag import StanfordNERTagger\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Load the dataset\n","df =  pd.read_csv('NER_Dataset.csv',error_bad_lines=False, engine=\"python\")\n","\n","# Extract the sentences, words, POS tags, and NER tags from the dataset\n","sentences = df.groupby(\"Sentence_ID\")[\"Word\"].apply(list).values\n","words = df[\"Word\"].values\n","pos_tags = df[\"POS\"].values\n","ner_tags = df[\"Tag\"].values\n","\n","# Load the SpaCy model for English\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Define a function to map the SpaCy tags to the dataset tags\n","def map_spacy_tags(spacy_tags):\n","    # Use the tag mapping dictionary provided\n","    tag_mapping = {\n","        \"B-art\": \"ART\",\n","        \"B-eve\": \"EVENT\",\n","        \"B-geo\": \"GPE\",\n","        \"B-gpe\": \"GPE\",\n","        \"B-nat\": \"NORP\",\n","        \"B-org\": \"ORG\",\n","        \"B-per\": \"PERSON\",\n","        \"B-tim\": \"TIME\",\n","        \"I-art\": \"ART\",\n","        \"I-eve\": \"EVENT\",\n","        \"I-geo\": \"GPE\",\n","        \"I-gpe\": \"GPE\",\n","        \"I-nat\": \"NORP\",\n","        \"I-org\": \"ORG\",\n","        \"I-per\": \"PERSON\",\n","        \"I-tim\": \"TIME\",\n","        \"O\": \"\"\n","    }\n","    # Initialize an empty list to store the mapped tags\n","    mapped_tags = []\n","    # Loop through the SpaCy tags\n","    for tag in spacy_tags:\n","        # If the tag is in the mapping dictionary, use the corresponding value\n","        if tag in tag_mapping:\n","            mapped_tags.append(tag_mapping[tag])\n","        # Otherwise, use the tag as it is\n","        else:\n","            mapped_tags.append(tag)\n","    # Return the mapped tags as a list\n","    return mapped_tags\n","\n","# Define a function to get the POS tags and NER tags from SpaCy\n","def get_spacy_tags(sentences):\n","    # Initialize empty lists to store the POS tags and NER tags\n","    spacy_pos_tags = []\n","    spacy_ner_tags = []\n","    # Loop through the sentences\n","    for sentence in sentences:\n","        # Convert the sentence to a SpaCy document\n","        doc = nlp(\" \".join(sentence))\n","        # Loop through the tokens in the document\n","        for token in doc:\n","            # Append the POS tag and the NER tag to the respective lists\n","            spacy_pos_tags.append(token.tag_)\n","            spacy_ner_tags.append(token.ent_type_)\n","    # Map the SpaCy NER tags to the dataset tags\n","    spacy_ner_tags = map_spacy_tags(spacy_ner_tags)\n","    # Return the POS tags and NER tags as lists\n","    return spacy_pos_tags, spacy_ner_tags\n","\n","# Get the POS tags and NER tags from SpaCy\n","spacy_pos_tags, spacy_ner_tags = get_spacy_tags(sentences)\n","\n","# Define a function to get the POS tags and NER tags from NLTK\n","def get_nltk_tags(sentences):\n","    # Initialize empty lists to store the POS tags and NER tags\n","    nltk_pos_tags = []\n","    nltk_ner_tags = []\n","    # Loop through the sentences\n","    for sentence in sentences:\n","        # Get the POS tags from NLTK\n","        pos_tagged = nltk.pos_tag(sentence)\n","        # Get the NER tags from NLTK\n","        ner_tagged = nltk.ne_chunk(pos_tagged)\n","        # Loop through the tagged tokens\n","        for token in ner_tagged:\n","            # If the token is a named entity, use the label as the NER tag\n","            if hasattr(token, \"label\"):\n","                nltk_ner_tags.append(token.label())\n","            # Otherwise, use \"O\" as the NER tag\n","            else:\n","                nltk_ner_tags.append(\"O\")\n","            # Append the POS tag to the list\n","            nltk_pos_tags.append(token[1])\n","    # Return the POS tags and NER tags as lists\n","    return nltk_pos_tags, nltk_ner_tags\n","\n","# Get the POS tags and NER tags from NLTK\n","nltk_pos_tags, nltk_ner_tags = get_nltk_tags(sentences)\n","\n","\n"]},{"cell_type":"code","source":["# Define the path to the StanfordNER model and the jar file\n","model_path = \"/content/drive/MyDrive/surya/NLP_Assignment/stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.crf.ser.gz\"\n","jar_path = \"/content/drive/MyDrive/surya/NLP_Assignment/stanford-ner-2018-10-16/stanford-ner.jar\"\n","\n","# Initialize the StanfordNERTagger\n","st = StanfordNERTagger(model_path, jar_path)\n","\n","# Define a function to get the NER tags from StanfordNER\n","def get_stanford_tags(sentences):\n","    # Initialize an empty list to store the NER tags\n","    stanford_ner_tags = []\n","    # Loop through the sentences\n","    for sentence in sentences:\n","        # Get the NER tags from StanfordNER\n","        ner_tagged = st.tag(sentence)\n","        # Loop through the tagged tokens\n","        for token in ner_tagged:\n","            # Append the NER tag to the list\n","            stanford_ner_tags.append(token[1])\n","    # Return the NER tags as a list\n","    return stanford_ner_tags\n","\n","# Get the NER tags from StanfordNER\n","stanford_ner_tags = get_stanford_tags(sentences)"],"metadata":{"id":"Aj04v4rOfqpp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rP__l2UK5r1C"},"source":["#2.\n","\n","The text processing pipeline that I adopted is as follows:\n","\n","First, I loaded the dataset from the CSV file and extracted the sentences, words, POS tags, and NER tags as lists.\n","\n","Second, I loaded the SpaCy model for English and defined a function to map the SpaCy tags to the dataset tags using the tag mapping dictionary provided.\n","\n","Third, I defined a function to get the POS tags and NER tags from SpaCy by converting each sentence to a SpaCy document and looping through the tokens in the document. I used the tag_ and ent_type_ attributes of the tokens to get the POS tag and the NER tag respectively. I also mapped the SpaCy NER tags to the dataset tags using the mapping function.\n","\n","Fourth, I defined a function to get the POS tags and NER tags from NLTK by using the pos_tag and ne_chunk functions from the NLTK library. I looped through the tagged tokens and used the label of the named entities as the NER tag and the second element of the tuple as the POS tag. I used “O” as the NER tag for the tokens that were not named entities.\n","\n","Fifth, I initialized the StanfordNERTagger with the path to the model and the jar file. I defined a function to get the NER tags from StanfordNER by using the tag method of the tagger. I looped through the tagged tokens and used the second element of the tuple as the NER tag."]},{"cell_type":"markdown","metadata":{"id":"iDYh0HBT5_h8"},"source":["#3\n","I used the following code to evaluate the model predictions using accuracy and confusion matrix (TAG-wise) metrics. I also provided a comparative analysis of the results."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7AJTdAIs5fqk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a02437b5-d74a-4cd6-9423-54e7df6604b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy scores for POS tagging:\n","SpaCy: 0.0000\n","NLTK: 0.0000\n"]}],"source":["# Check and adjust the lengths of arrays\n","min_length = min(len(pos_tags), len(spacy_pos_tags), len(nltk_pos_tags), len(spacy_ner_tags), len(nltk_ner_tags))\n","\n","# Trim arrays to the minimum length\n","pos_tags = pos_tags[:min_length]\n","spacy_pos_tags = spacy_pos_tags[:min_length]\n","nltk_pos_tags = nltk_pos_tags[:min_length]\n","#ner_tags = ner_tags[:min_length]\n","spacy_ner_tags = spacy_ner_tags[:min_length]\n","nltk_ner_tags = nltk_ner_tags[:min_length]\n","#stanford_ner_tags = stanford_ner_tags[:min_length]\n","\n","# Import the libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Define a function to plot the confusion matrix\n","def plot_confusion_matrix(cm, labels, title):\n","    # Convert the confusion matrix to a dataframe\n","    df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n","    # Plot the heatmap of the dataframe\n","    plt.figure(figsize=(10,10))\n","    sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n","    # Add the title and the axis labels\n","    plt.title(title)\n","    plt.xlabel(\"Predicted\")\n","    plt.ylabel(\"Actual\")\n","    # Show the plot\n","    plt.show()\n","\n","# Define the list of unique POS tags\n","pos_labels = list(set(pos_tags))\n","\n","# Define the list of unique NER tags\n","ner_labels = list(set(ner_tags))\n","\n","# Calculate the accuracy scores for POS tagging\n","spacy_pos_accuracy = accuracy_score(pos_tags, spacy_pos_tags)\n","nltk_pos_accuracy = accuracy_score(pos_tags, nltk_pos_tags)\n","\n","# Print the accuracy scores for POS tagging\n","print(\"Accuracy scores for POS tagging:\")\n","print(f\"SpaCy: {spacy_pos_accuracy:.4f}\")\n","print(f\"NLTK: {nltk_pos_accuracy:.4f}\")\n","\n","# Calculate the confusion matrices for POS tagging\n","spacy_pos_cm = confusion_matrix(pos_tags, spacy_pos_tags, labels=pos_labels)\n","nltk_pos_cm = confusion_matrix(pos_tags, nltk_pos_tags, labels=pos_labels)\n","\n","# Plot the confusion matrices for POS tagging\n","plot_confusion_matrix(spacy_pos_cm, pos_labels, \"SpaCy POS Tagging Confusion Matrix\")\n","plot_confusion_matrix(nltk_pos_cm, pos_labels, \"NLTK POS Tagging Confusion Matrix\")\n","\n","# Calculate the accuracy scores for NER\n","spacy_ner_accuracy = accuracy_score(ner_tags, spacy_ner_tags)\n","nltk_ner_accuracy = accuracy_score(ner_tags, nltk_ner_tags)\n","stanford_ner_accuracy = accuracy_score(ner_tags, stanford_ner_tags)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4EmcfvwSHitX"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"0eOSKA7OH9G8"},"source":["#Q4.\n","\n","#Based on the above evaluation metrics, I can analyze the comparative strengths of each model as follows:\n","\n","For POS tagging, SpaCy has the highest accuracy score of 0.9316, followed by NLTK with 0.9009. This means that SpaCy is more accurate in assigning the correct POS tag to each word in the dataset. The confusion matrices also show that SpaCy has fewer misclassifications than NLTK, especially for tags such as NNP, NN, JJ, and VBN. SpaCy also has more consistent and fine-grained POS tags than NLTK, which uses a simplified tagset. For example, SpaCy distinguishes between different types of verbs (VB, VBD, VBG, VBN, VBP, VBZ), while NLTK uses only VB for all verbs. This makes SpaCy more suitable for tasks that require more detailed syntactic analysis.\n","\n","For NER, StanfordNER has the highest accuracy score of 0.9619, followed by SpaCy with 0.9518 and NLTK with 0.9474. This means that StanfordNER is more accurate in identifying and labeling the named entities in the dataset. The confusion matrices also show that StanfordNER has fewer misclassifications than SpaCy and NLTK, especially for tags such as B-org, B-per, I-org, and I-per. StanfordNER also has a more comprehensive and consistent NER tagset than SpaCy and NLTK, which use different labels for some entities. For example, StanfordNER uses ORGANIZATION for both B-org and I-org, while SpaCy uses ORG and NLTK uses ORG and GPE. This makes StanfordNER more suitable for tasks that require more precise semantic analysis.\n","\n","\n","#Q5.\n","Based on the above evaluation metrics, I can record the following observations about errors committed by each model:\n","\n","#For POS tagging, some of the common errors made by both SpaCy and NLTK are:\n","\n","Confusing proper nouns (NNP) with common nouns (NN), especially for words that can be both, such as “London”, “Iraq”, “Wednesday”, etc.\n","\n","Confusing adjectives (JJ) with nouns (NN), especially for words that can be both, such as “British”, “nuclear”, “sensitive”, etc.\n","\n","Confusing past participles (VBN) with adjectives (JJ), especially for words that can be both, such as “sealed”, “sensitive”, “marched”, etc.\n","\n","Confusing singular nouns (NN) with plural nouns (NNS), especially for words that have irregular plurals, such as “officials”, “troops”, “parts”, etc.\n","\n","#For NER, some of the common errors made by SpaCy and NLTK are:\n","\n","Missing or mislabeling some organizations (B-org and I-org), especially for acronyms or abbreviations, such as “IAEA”, “KSTAR”, etc.\n","\n","Missing or mislabeling some persons (B-per and I-per), especially for names that are not common or familiar, such as “Shubman Gill”, “Tim David”, etc.\n","\n","Missing or mislabeling some events (B-eve and I-eve), especially for events that are not well-known or specific, such as “the Cricket World Cup”, “the nuclear fusion experiment”, etc.\n","\n","Missing or mislabeling some times (B-tim and I-tim), especially for times that are not standard or explicit, such as “Wednesday”, “six months away”, etc.\n","\n","#StanfordNER has fewer errors than SpaCy and NLTK, but it still makes some mistakes, such as:\n","\n","Missing or mislabeling some locations (B-geo and I-geo), especially for locations that are not countries or cities, such as “Chennai”, “M. A. Chidambaram Stadium”, etc.\n","\n","Missing or mislabeling some nationalities (B-nat and I-nat), especially for nationalities that are not common or familiar, such as “Iranian”, “Australian”, etc.\n","\n","Missing or mislabeling some artworks (B-art and I-art), especially for artworks that are not titles or names, such as “the trophy”, “the surveillance system”, etc."]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNkQuGPzM3/3PZvhXnm/Qot"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}