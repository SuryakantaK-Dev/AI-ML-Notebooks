{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"w-HczEQFHkfy"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["import os\n","import cv2\n","import numpy as np\n","from sklearn.metrics import f1_score, roc_auc_score\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","os.chdir('/content/drive/MyDrive/surya/NCVPRIPG-writer-verification-main/')\n","import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, roc_auc_score\n","\n","# Set the paths to the dataset folders\n","train_folder = '/content/drive/MyDrive/surya/NCVPRIPG-writer-verification-main/dataset/train'\n","val_folder = '/content/drive/MyDrive/surya/NCVPRIPG-writer-verification-main/dataset/val'\n","\n","# Set the path to the validation CSV file\n","val_csv_file = '/content/drive/MyDrive/surya/NCVPRIPG-writer-verification-main/dataset/val.csv'\n","\n","# Define the image size for resizing\n","image_size = (64, 64)\n","\n","# Preprocess the images\n","def preprocess_image(image_path):\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_jpeg(image, channels=3)\n","    image = tf.image.resize(image, image_size)\n","    image = tf.image.convert_image_dtype(image, tf.float32)\n","    return image\n","\n","# Load the training data\n","train_images = []\n","train_labels = []\n","\n","for folder_name in os.listdir(train_folder):\n","    folder_path = os.path.join(train_folder, folder_name)\n","    if os.path.isdir(folder_path):\n","        image_paths = sorted(os.listdir(folder_path))\n","        for i in range(len(image_paths) - 1):\n","            image1_path = os.path.join(folder_path, image_paths[i])\n","            image2_path = os.path.join(folder_path, image_paths[i + 1])\n","            image1 = preprocess_image(image1_path)\n","            image2 = preprocess_image(image2_path)\n","            train_images.append(image1)\n","            train_images.append(image2)\n","            train_labels.append(1)  # Same writer label\n","            train_labels.append(1)  # Same writer label\n","\n","# Load the validation data\n","val_data = pd.read_csv(val_csv_file)\n","val_image_pairs = []\n","\n","for i, row in val_data.iterrows():\n","    image1_path = os.path.join(val_folder, row['img1_name'])\n","    image2_path = os.path.join(val_folder, row['img2_name'])\n","    image1 = preprocess_image(image1_path)\n","    image2 = preprocess_image(image2_path)\n","    val_image_pairs.append((image1, image2))\n","\n","# Convert the training data to NumPy arrays\n","train_images = np.array(train_images)\n","train_labels = np.array(train_labels)\n","\n","# Split the training data into training and validation sets\n","train_images, val_images, train_labels, val_labels = train_test_split(\n","    train_images, train_labels, test_size=0.2, random_state=42)\n","\n","# Define the CNN model\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","# Compile and train the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(val_images, val_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EYko0aUsH8qD"},"outputs":[],"source":["# Make predictions on the validation set\n","val_predictions = []\n","\n","for pair in val_image_pairs:\n","    image1, image2 = pair\n","    prediction = model.predict(np.array([image1, image2]))\n","    val_predictions.append(prediction[0][0])\n","\n","# Calculate F1 score and AUC\n","val_true_labels = val_data['label']\n","f1 = f1_score(val_true_labels, np.round(val_predictions))\n","auc = roc_auc_score(val_true_labels, val_predictions)\n","\n","# Create the submission CSV file\n","submission_file = '/content/drive/MyDrive/surya/NCVPRIPG-writer-verification-main/dataset/submission.csv'\n","submission_data = val_data.copy()\n","submission_data['proba'] = val_predictions\n","submission_data.to_csv(submission_file, index=False)\n","\n","# Print F1 score and AUC\n","print(\"F1 score:\", f1)\n","print(\"AUC:\", auc)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNMBCaSCG/2cRz50ZGzVzpg","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}