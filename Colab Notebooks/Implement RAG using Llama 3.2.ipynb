{"cells":[{"cell_type":"markdown","id":"dbd20d6a","metadata":{"id":"dbd20d6a"},"source":["\n","## Building a Conversational Chatbot in your local with Llama 3.2 using Ollama\n","\n","This notebook demonstrates a streamlined workflow for building a **Retrieval-Augmented Generation (RAG)** system locally using **Llama 3.2** via **Ollama**. The goal is to enable efficient document-based question answering by integrating document ingestion, vector database storage, and a conversational retrieval system.\n","\n","The following steps are covered:\n","\n","1. **Document Preparation and Splitting**:  PDF, CSV, and DOCX files from a specified directory are loaded, and the content is split into smaller, manageable chunks using the RecursiveCharacterTextSplitter. This process ensures optimal chunking based on size and overlap to improve retrieval accuracy during further processing.\n","\n","2. **Ingesting Documents into Vector Database**: The split documents are embedded using `HuggingFaceEmbeddings` and stored in a local FAISS vector database, facilitating fast and scalable document retrieval.\n","\n","3. **Building the Conversation Chain**: A conversational chain is built using **Llama 3.2** to retrieve relevant information based on user queries. This chain ensures that the responses are accurate, concise, and relevant to the context of the chat history, while managing session history to maintain the flow of conversation.\n","\n","4. **Similarity Score Calculation**: To evaluate the relevancy of the system’s responses, the notebook includes a function to calculate the similarity score between the generated answers and the source documents using `SentenceTransformer`.\n","\n","The notebook is designed for local execution, leveraging the performance and capabilities of Llama 3.2 via the **Ollama** API to offer a robust and efficient Q&A solution."]},{"cell_type":"markdown","id":"2e379a0a","metadata":{"id":"2e379a0a"},"source":["Below cell imports the required libraries to run this notebook."]},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZOlXTC3OIic","executionInfo":{"status":"ok","timestamp":1728124098549,"user_tz":-330,"elapsed":23002,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"ef738df2-c52c-4b16-ed40-b828cd1f8cbb"},"id":"RZOlXTC3OIic","execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":22,"id":"cc305674","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cc305674","executionInfo":{"status":"ok","timestamp":1728124266537,"user_tz":-330,"elapsed":6103,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"0e7eb572-485b-47e5-db9a-c8a873ef8a1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (1.39.0)\n","Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (0.3.2)\n","Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 3)) (0.3.1)\n","Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 4)) (0.3.9)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 5)) (3.1.1)\n","Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 6)) (1.8.0.post1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 7)) (0.24.7)\n","Requirement already satisfied: ollama in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 8)) (0.3.3)\n","Requirement already satisfied: unstructured[docx] in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (0.15.13)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (4.2.2)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (1.4)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (5.5.0)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (8.1.7)\n","Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (1.26.4)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (24.1)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (2.2.2)\n","Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (10.4.0)\n","Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (3.20.3)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (16.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (2.32.3)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (13.8.1)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (8.5.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (4.12.2)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (3.1.43)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (0.9.1)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (6.3.3)\n","Requirement already satisfied: watchdog<6,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (5.0.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (3.10.8)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (4.0.3)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (0.3.0)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (0.1.131)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (2.9.2)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 3)) (0.6.7)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 3)) (2.5.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 4)) (1.33)\n","Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 5)) (4.44.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 5)) (4.66.5)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 5)) (2.4.1+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 5)) (1.5.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 5)) (1.13.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 7)) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 7)) (2024.6.1)\n","Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from ollama->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 8)) (0.27.2)\n","Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (5.2.0)\n","Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (1.2.0)\n","Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (0.4.27)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (4.9.4)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (3.8.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (0.9.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (4.12.3)\n","Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (2.14.0)\n","Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (2024.4.27)\n","Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (1.0.9)\n","Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (3.10.0)\n","Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (2.2.1)\n","Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (0.25.9)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (1.16.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (5.9.5)\n","Requirement already satisfied: python-oxmsg in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (0.0.1)\n","Requirement already satisfied: python-docx>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (1.1.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (1.13.1)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (3.1.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (4.23.0)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (0.12.1)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 3)) (3.22.0)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 3)) (0.9.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (4.0.11)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 8)) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 8)) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 8)) (1.0.6)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 8)) (3.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 8)) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 8)) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 4)) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (3.10.7)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (2024.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (2.23.4)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 3)) (1.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (2.2.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (2.18.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 2)) (3.1.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 5)) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 5)) (3.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 5)) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 5)) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 5)) (0.19.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (2.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (1.16.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (1.4.2)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.10/dist-packages (from python-oxmsg->unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (0.47)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 5)) (3.5.0)\n","Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (43.0.1)\n","Requirement already satisfied: deepdiff>=6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (8.0.1)\n","Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (1.0.6)\n","Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (1.0.0)\n","Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (1.6.0)\n","Requirement already satisfied: pypdf>=4.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (5.0.1)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.1->unstructured-client->unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (1.17.1)\n","Requirement already satisfied: orderly-set==5.2.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff>=6.0->unstructured-client->unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (5.2.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (5.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (2.1.5)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (0.20.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 1)) (0.1.2)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 8)) (1.2.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 5)) (1.3.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured[docx]->-r /content/drive/MyDrive/surya/FMGAI/requirements.txt (line 9)) (2.22)\n"]}],"source":["!pip install -r /content/drive/MyDrive/surya/FMGAI/requirements.txt\n"]},{"cell_type":"code","source":[],"metadata":{"id":"adcySTSiOF5U"},"id":"adcySTSiOF5U","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langchain-huggingface\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0nXHmdvEMrO8","executionInfo":{"status":"ok","timestamp":1728124272084,"user_tz":-330,"elapsed":5550,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"9592d9f9-6731-4ad0-ab6c-6f665be001ab"},"id":"0nXHmdvEMrO8","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.10/dist-packages (0.1.0)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.24.7)\n","Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.3.9)\n","Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (3.1.1)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.19.1)\n","Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (4.44.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.66.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.1.131)\n","Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (2.9.2)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (8.5.0)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.4.1+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.5.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.4.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-huggingface) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (3.10.7)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-huggingface) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.8.30)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.0.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.14.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.2.2)\n"]}]},{"cell_type":"code","execution_count":24,"id":"5c4177b0","metadata":{"id":"5c4177b0","executionInfo":{"status":"ok","timestamp":1728124272085,"user_tz":-330,"elapsed":3,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"outputs":[],"source":["from langchain.document_loaders import DirectoryLoader, CSVLoader, UnstructuredWordDocumentLoader, PyPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_community.llms import Ollama\n","from langchain.vectorstores import FAISS\n","from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.runnables.history import RunnableWithMessageHistory\n","from langchain_community.chat_message_histories import ChatMessageHistory\n","from langchain.chains import create_retrieval_chain\n","from langchain.chains.combine_documents import create_stuff_documents_chain\n","from sentence_transformers import SentenceTransformer, util\n","#from htmlTemplate import css, bot_template, user_template\n","from langchain_core.chat_history import BaseChatMessageHistory\n","from langchain.chains import create_history_aware_retriever\n","from langchain_huggingface import HuggingFaceEmbeddings"]},{"cell_type":"markdown","id":"0c264d9e","metadata":{"id":"0c264d9e"},"source":["#### Specify values for the following:\n","\n","- **`file_directory`**: Provide the name of the folder where your PDF,docx or csv files are stored.\n","\n","- **`embedding_model`**: This is the model used to generate text embeddings. It will be applied to both chunked documents and for calculating the similarity score between the source documents and the LLM's response.\n","\n","- **`llm_model`**: Refers to the language model being used,  \"llama3.2\" in this case."]},{"cell_type":"code","execution_count":26,"id":"83e771c1","metadata":{"id":"83e771c1","executionInfo":{"status":"ok","timestamp":1728124416920,"user_tz":-330,"elapsed":486,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"outputs":[],"source":["file_directory=\"/content/drive/MyDrive/surya/FMGAI/data_directory\"\n","embedding_model='sentence-transformers/all-MiniLM-L6-v2'\n","llm_model =\"llama3.2\""]},{"cell_type":"markdown","id":"7158eb08","metadata":{"id":"7158eb08"},"source":["### Step 1: Prepare documents and their metadata\n","This function, `prepare_and_split_docs()`, loads documents from a given directory, including PDFs, DOCX files, and CSVs, using `DirectoryLoader` with specific loaders for each file type. It then splits these documents into smaller chunks using a `RecursiveCharacterTextSplitter` with a defined chunk size and overlap. Finally, the function returns the split documents while maintaining metadata."]},{"cell_type":"code","execution_count":27,"id":"97e49bddd35c6d1a","metadata":{"ExecuteTime":{"end_time":"2024-01-07T08:05:12.765779Z","start_time":"2024-01-07T08:05:12.763477Z"},"jupyter":{"outputs_hidden":false},"id":"97e49bddd35c6d1a","executionInfo":{"status":"ok","timestamp":1728124419289,"user_tz":-330,"elapsed":482,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"outputs":[],"source":["def prepare_and_split_docs(directory):\n","    # Load the documents\n","    loaders = [\n","        DirectoryLoader(directory, glob=\"**/*.pdf\",show_progress=True, loader_cls=PyPDFLoader),\n","        DirectoryLoader(directory, glob=\"**/*.docx\",show_progress=True),\n","        DirectoryLoader(directory, glob=\"**/*.csv\",loader_cls=CSVLoader)\n","    ]\n","\n","\n","    documents=[]\n","    for loader in loaders:\n","        data =loader.load()\n","        documents.extend(data)\n","\n","    # Initialize a text splitter\n","    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n","        chunk_size=512,  # Use the smaller chunk size here to avoid repeating splitting logic\n","        chunk_overlap=256,\n","        disallowed_special=(),\n","        separators=[\"\\n\\n\", \"\\n\", \" \"]\n","    )\n","\n","    # Split the documents and keep metadata\n","    split_docs = splitter.split_documents(documents)\n","\n","    print(f\"Documents are split into {len(split_docs)} passages\")\n","    return split_docs\n"]},{"cell_type":"markdown","id":"c0f576d0","metadata":{"id":"c0f576d0"},"source":["### Step 3: Ingest into Vector Database locally\n","\n","The `ingest_into_vectordb` function is designed for processing and indexing a collection of documents into a vector database using FAISS (Facebook AI Similarity Search) for efficient similarity searches. It operates as follows:\n","\n","1. **Embedding Creation**: It generates embeddings for the input documents (`split_docs`) using the Hugging Face model `'sentence-transformers/all-MiniLM-L6-v2'`. This model is specifically chosen for its efficiency in creating sentence-level embeddings and is set to run on the CPU.\n","\n","2. **Vector Database Indexing**: Utilizes the generated embeddings to create a FAISS vector database. FAISS is used for its ability to efficiently handle large-scale similarity searches and clustering of dense vectors.\n","\n","3. **Local Storage**: After creating the vector database, the function saves it locally to the path specified by `DB_FAISS_PATH`, ensuring the data can be easily accessed for future similarity searches or retrieval tasks.\n","\n","The primary purpose of this function is to transform textual data into a structured, searchable vector format, facilitating efficient and scalable retrieval tasks such as document similarity searches or clustering."]},{"cell_type":"code","execution_count":28,"id":"ba2d9675","metadata":{"id":"ba2d9675","executionInfo":{"status":"ok","timestamp":1728124427658,"user_tz":-330,"elapsed":1537,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"outputs":[],"source":["embeddings = HuggingFaceEmbeddings(model_name=embedding_model)\n","def ingest_into_vectordb(split_docs):\n","    db = FAISS.from_documents(split_docs, embeddings)\n","\n","    DB_FAISS_PATH = 'vectorstore/db_faiss'\n","    db.save_local(DB_FAISS_PATH)\n","    print(\"Documents are inserted into FAISS vectorstore\")\n","    return db"]},{"cell_type":"markdown","id":"1d7ba4cd","metadata":{"id":"1d7ba4cd"},"source":["### Step 4: Set up Conversation Chain using LLM\n","The `get_conversation_chain(retriever)` function creates a stateful conversational RAG system.\n","\n","1. It initializes the `llama3.2` model and defines two prompts:\n","   - A contextualization prompt to handle the user's query in light of the chat history.\n","   - A system prompt for answering concisely with 2-3 sentences based on retrieved documents.\n","\n","2. It builds a `history_aware_retriever` using the retriever, LLM, and the contextualization prompt to ensure responses are context-aware.\n","\n","3. A `question_answer_chain` is set up to respond with answers limited to 50 words.\n","\n","4. These components are combined into a RAG chain using `create_retrieval_chain`.\n","\n","5. To manage chat history across sessions, it defines `get_session_history`, which stores and retrieves message history by session ID.\n","\n","6. Finally, a `RunnableWithMessageHistory` integrates the RAG chain with chat history management, ensuring the bot maintains state and provides contextually relevant responses throughout the conversation.\n","\n","This function sets up a sophisticated conversational AI system combining the LLaMA model for language generation and a vector database for information retrieval, enhanced with a callback manager for additional processing and a conversation memory buffer for context management."]},{"cell_type":"code","execution_count":29,"id":"daeb1adc421d294e","metadata":{"ExecuteTime":{"end_time":"2024-01-07T07:48:11.383224Z","start_time":"2024-01-07T07:48:11.380239Z"},"jupyter":{"outputs_hidden":false},"id":"daeb1adc421d294e","executionInfo":{"status":"ok","timestamp":1728124432492,"user_tz":-330,"elapsed":448,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"outputs":[],"source":["def get_conversation_chain(retriever):\n","    llm = Ollama(model=llm_model)\n","    contextualize_q_system_prompt = (\n","        \"Given the chat history and the latest user question, \"\n","        \"provide a response that directly addresses the user's query based on the provided  documents. \"\n","        \"Do not rephrase the question or ask follow-up questions.\"\n","    )\n","\n","\n","    contextualize_q_prompt = ChatPromptTemplate.from_messages(\n","        [\n","            (\"system\", contextualize_q_system_prompt),\n","            MessagesPlaceholder(\"chat_history\"),\n","            (\"human\", \"{input}\"),\n","        ]\n","    )\n","    history_aware_retriever = create_history_aware_retriever(\n","        llm, retriever, contextualize_q_prompt\n","    )\n","\n","\n","    ### Answer question ###\n","    system_prompt = (\n","        \"As a personal chat assistant, provide accurate and relevant information based on the provided document in 2-3 sentences. \"\n","        \"Answe should be limited to 50 words and 2-3 sentences.  do not prompt to select answers or do not formualate a stand alone question. do not ask questions in the response. \"\n","        \"{context}\"\n","    )\n","\n","    qa_prompt = ChatPromptTemplate.from_messages(\n","        [\n","            (\"system\", system_prompt),\n","            MessagesPlaceholder(\"chat_history\"),\n","            (\"human\", \"{input}\"),\n","        ]\n","    )\n","    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n","\n","    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n","\n","\n","    ### Statefully manage chat history ###\n","    store = {}\n","\n","\n","    def get_session_history(session_id: str) -> BaseChatMessageHistory:\n","        if session_id not in store:\n","            store[session_id] = ChatMessageHistory()\n","        return store[session_id]\n","\n","\n","    conversational_rag_chain = RunnableWithMessageHistory(\n","        rag_chain,\n","        get_session_history,\n","        input_messages_key=\"input\",\n","        history_messages_key=\"chat_history\",\n","        output_messages_key=\"answer\",\n","    )\n","    print(\"Conversational chain created\")\n","    return conversational_rag_chain"]},{"cell_type":"markdown","id":"43e69dfd","metadata":{"id":"43e69dfd"},"source":["### Step 5: Calculate Document Similarity in the LLMs Response\n","The `calculate_similarity_score` function computes the cosine similarity between a given answer and a list of context documents using Sentence Transformers. It first encodes the answer and context documents into embeddings. Then, it calculates the cosine similarities between the answer embedding and the context embeddings. The function returns the maximum similarity score, indicating how closely the answer relates to the most relevant context document. Scores range from 0 (no similarity) to 1 (perfect similarity), with higher scores reflecting better alignment with the context.\n","\n","Essentially, this function serves as a mechanism to check the alignment of the chatbot's response with the information in the source documents, ensuring the response's accuracy and relevance."]},{"cell_type":"code","execution_count":30,"id":"8d0cc0f87a9595c7","metadata":{"ExecuteTime":{"end_time":"2024-01-07T07:48:35.893137Z","start_time":"2024-01-07T07:48:35.887077Z"},"jupyter":{"outputs_hidden":false},"id":"8d0cc0f87a9595c7","executionInfo":{"status":"ok","timestamp":1728124437393,"user_tz":-330,"elapsed":462,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"outputs":[],"source":["def calculate_similarity_score(answer: str, context_docs: list) -> float:\n","\n","    context_docs = [doc.page_content for doc in context_docs]\n","\n","    # Encode the answer and context documents\n","    answer_embedding = embeddings.embed_query(answer)\n","    context_embeddings = embeddings.embed_documents(context_docs)\n","\n","    # Calculate cosine similarities\n","    similarities = util.pytorch_cos_sim(answer_embedding, context_embeddings)\n","\n","    # Return the maximum similarity score from the context documents\n","    max_score = similarities.max().item()\n","    return max_score\n"]},{"cell_type":"markdown","id":"9f38df5c","metadata":{"id":"9f38df5c"},"source":["Now that we have crafted all the necessary functions, it's time to put them into action and test their functionality."]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","!pip install tiktoken\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_JUKsRRDPyCH","executionInfo":{"status":"ok","timestamp":1728124639494,"user_tz":-330,"elapsed":4728,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"99af02ba-f1eb-4f70-feaf-4b73f3b0f60e"},"id":"_JUKsRRDPyCH","execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Collecting tiktoken\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n","Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.2 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken\n","Successfully installed tiktoken-0.8.0\n"]}]},{"cell_type":"code","execution_count":36,"id":"e435e003cfe91c1a","metadata":{"ExecuteTime":{"end_time":"2024-01-07T10:24:11.041141Z","start_time":"2024-01-07T10:24:10.938343Z"},"jupyter":{"outputs_hidden":false},"colab":{"base_uri":"https://localhost:8080/"},"id":"e435e003cfe91c1a","executionInfo":{"status":"ok","timestamp":1728124645915,"user_tz":-330,"elapsed":4198,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"d8027fcf-1b57-44e7-cf07-076bad504338"},"outputs":[{"output_type":"stream","name":"stderr","text":["\n","\n","100%|██████████| 1/1 [00:00<00:00, 72.95it/s]\n","\n","\n","0it [00:00, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Documents are split into 1 passages\n","Documents are inserted into FAISS vectorstore\n","Conversational chain created\n"]}],"source":["split_docs=prepare_and_split_docs(file_directory)\n","vector_db= ingest_into_vectordb(split_docs)\n","retriever =vector_db.as_retriever()\n","conversational_rag_chain=get_conversation_chain(retriever)\n"]},{"cell_type":"markdown","id":"df276c10","metadata":{"id":"df276c10"},"source":["### Ask your Question\n","\n","We created a conversational chain and now ready to chat with your own data.\n","\n","\n","### Question 1"]},{"cell_type":"code","execution_count":37,"id":"e513bd28","metadata":{"id":"e513bd28","executionInfo":{"status":"ok","timestamp":1728124657793,"user_tz":-330,"elapsed":461,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"outputs":[],"source":["user_question=\"Can you summarise the documents ?\""]},{"cell_type":"code","execution_count":43,"id":"e0c000474595b40e","metadata":{"ExecuteTime":{"end_time":"2024-01-07T10:44:54.014449Z","start_time":"2024-01-07T10:44:50.322823Z"},"jupyter":{"outputs_hidden":false},"vscode":{"languageId":"javascript"},"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"e0c000474595b40e","executionInfo":{"status":"error","timestamp":1728124847089,"user_tz":-330,"elapsed":464,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"2d61ab0c-cecc-4afe-a05c-c090aeec227c"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Missing keys ['session_id'] in config['configurable'] Expected keys are ['session_id'].When using via .invoke() or .stream(), pass in a config; e.g., chain.invoke({'input': 'foo'}, {'configurable': {'session_id': '[your-value-here]'}})","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-e082b659cbb7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m qa1 = conversational_rag_chain.invoke(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_question\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Check if 'answer' exists in the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5337\u001b[0m         return self.bound.invoke(\n\u001b[1;32m   5338\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5339\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5340\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5341\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/history.py\u001b[0m in \u001b[0;36m_merge_configs\u001b[0;34m(self, *configs)\u001b[0m\n\u001b[1;32m    594\u001b[0m             }\n\u001b[1;32m    595\u001b[0m             \u001b[0mexample_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"configurable\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexample_configurable\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    597\u001b[0m                 \u001b[0;34mf\"Missing keys {sorted(missing_keys)} in config['configurable'] \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;34mf\"Expected keys are {sorted(expected_keys)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Missing keys ['session_id'] in config['configurable'] Expected keys are ['session_id'].When using via .invoke() or .stream(), pass in a config; e.g., chain.invoke({'input': 'foo'}, {'configurable': {'session_id': '[your-value-here]'}})"]}],"source":["qa1 = conversational_rag_chain.invoke(\n","    {\"input\": user_question},\n","    config={\n","        \"configurable\": {\"session_id\": \"abc123\"}\n","    }\n",")\n","\n","# Check if 'answer' exists in the response\n","if \"answer\" in qa1:\n","    print(qa1[\"answer\"])\n","else:\n","    print(\"No answer found in the response. Here's the raw response:\")\n","    print(qa1)\n"]},{"cell_type":"code","source":["!curl http://localhost:11434/api/generate\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8AKV7qNsQ6j2","executionInfo":{"status":"ok","timestamp":1728124814394,"user_tz":-330,"elapsed":574,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"05843082-baf6-4a43-e05f-f32016ae53b4"},"id":"8AKV7qNsQ6j2","execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["curl: (7) Failed to connect to localhost port 11434 after 0 ms: Connection refused\n"]}]},{"cell_type":"markdown","id":"33c22c53","metadata":{"vscode":{"languageId":"javascript"},"id":"33c22c53"},"source":["We have now received an answer for a provided question. We can also view the conversation history and source documents in the response.\n"]},{"cell_type":"code","execution_count":39,"id":"be79e26f","metadata":{"vscode":{"languageId":"javascript"},"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"be79e26f","executionInfo":{"status":"error","timestamp":1728124699520,"user_tz":-330,"elapsed":491,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"e2da9453-9bb0-4e18-bfff-2705e760e7be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Conversation Chain\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'qa1' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-ad3f71089402>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Conversation Chain\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqa1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'qa1' is not defined"]}],"source":["print(\"Conversation Chain\")\n","print(qa1)"]},{"cell_type":"markdown","id":"17d31975","metadata":{"vscode":{"languageId":"javascript"},"id":"17d31975"},"source":["### Calculate Similarity score between the LLM Response and context documents"]},{"cell_type":"code","execution_count":null,"id":"acfdf2f4","metadata":{"vscode":{"languageId":"javascript"},"id":"acfdf2f4","outputId":"a28fd5db-c40e-4f35-801e-1a668ee42169"},"outputs":[{"name":"stdout","output_type":"stream","text":["Context Similarity Score: 0.75\n"]}],"source":["\n","answer = qa1[\"answer\"]\n","context_docs = qa1[\"context\"]\n","similarity_score = calculate_similarity_score(answer, context_docs)\n","\n","print(\"Context Similarity Score:\", round(similarity_score,2))"]},{"cell_type":"markdown","id":"2018700c","metadata":{"id":"2018700c"},"source":["### Sumamry\n","This notebook demonstrates the implementation of a Retrieval-Augmented Generation (RAG) pipeline using Llama 3.2 via the Ollama API. We began by preparing and splitting PDF, docx or csv documents into manageable chunks, then ingested these into a vector database with FAISS and Hugging Face embeddings for efficient retrieval.\n","\n","We integrated the retriever with a conversation chain driven by an LLM, using customized system prompts to generate concise responses based on relevant documents. Additionally, we implemented a method for managing conversation history to maintain context in multi-turn interactions, along with calculating similarity scores between generated answers and source documents using SentenceTransformers.\n","\n","Overall, this notebook serves as a guide for creating a locally deployable RAG application, effectively combining Llama 3.2 for inference and FAISS for document retrieval."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}