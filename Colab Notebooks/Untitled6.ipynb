{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNmwNnh/RIBPAUj8Mes4PYH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install torch==1.0.1.post2\n","!pip install torchvision==0.2.2.post2\n","!pip install qpth==0.0.13\n","!pip install torchnet\n","!pip install tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"IKTkiUBNf5v0","executionInfo":{"status":"ok","timestamp":1700144443466,"user_tz":-330,"elapsed":28386,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"42a0cc62-e40c-4e5e-82df-343edc2b03e1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.0.1.post2 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.0.1.post2\u001b[0m\u001b[31m\n","\u001b[0mCollecting torchvision==0.2.2.post2\n","  Downloading torchvision-0.2.2.post2-py2.py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.2.2.post2) (1.23.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchvision==0.2.2.post2) (1.16.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchvision==0.2.2.post2) (2.1.0+cu118)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.2.2.post2) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchvision==0.2.2.post2) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchvision==0.2.2.post2) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchvision==0.2.2.post2) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchvision==0.2.2.post2) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchvision==0.2.2.post2) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchvision==0.2.2.post2) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchvision==0.2.2.post2) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchvision==0.2.2.post2) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchvision==0.2.2.post2) (1.3.0)\n","\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'torchvision' candidate (version 0.2.2.post2 at https://files.pythonhosted.org/packages/21/9e/3d41372cf9e0f009172a7ad351070657d02e8b424f7efd38433086c82681/torchvision-0.2.2.post2-py2.py3-none-any.whl (from https://pypi.org/simple/torchvision/))\n","Reason for being yanked: So that users won't accidentally install this when using python 3.11\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: torchvision\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.16.0+cu118\n","    Uninstalling torchvision-0.16.0+cu118:\n","      Successfully uninstalled torchvision-0.16.0+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.13 requires torchvision>=0.11, but you have torchvision 0.2.2.post2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torchvision-0.2.2.post2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torchvision"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting qpth==0.0.13\n","  Downloading qpth-0.0.13.tar.gz (11 kB)\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n","Collecting torchnet\n","  Downloading torchnet-0.0.4.tar.gz (23 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchnet) (2.1.0+cu118)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchnet) (1.16.0)\n","Collecting visdom (from torchnet)\n","  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchnet) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchnet) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchnet) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchnet) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchnet) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchnet) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchnet) (2.1.0)\n","Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.10/dist-packages (from visdom->torchnet) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from visdom->torchnet) (1.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visdom->torchnet) (2.31.0)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom->torchnet) (6.3.2)\n","Collecting jsonpatch (from visdom->torchnet)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from visdom->torchnet) (1.6.4)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from visdom->torchnet) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchnet) (2.1.3)\n","Collecting jsonpointer>=1.9 (from jsonpatch->visdom->torchnet)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->visdom->torchnet) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visdom->torchnet) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visdom->torchnet) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visdom->torchnet) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchnet) (1.3.0)\n","Building wheels for collected packages: torchnet, visdom\n","  Building wheel for torchnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchnet: filename=torchnet-0.0.4-py3-none-any.whl size=29729 sha256=a850b4ec8626fa4ed7f9d5bda9c80e9c0b9113f6585fe6d27fd6e8f6a61b9dc2\n","  Stored in directory: /root/.cache/pip/wheels/f7/ae/94/9f5edd6871983f30967ad11d60ef434c3d1b007654de4c8065\n","  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408194 sha256=adeee6d5b9f95b324841109ec988afa2791305e3c76252f13ef76101f066d01c\n","  Stored in directory: /root/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n","Successfully built torchnet visdom\n","Installing collected packages: jsonpointer, jsonpatch, visdom, torchnet\n","Successfully installed jsonpatch-1.33 jsonpointer-2.4 torchnet-0.0.4 visdom-0.2.4\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"5f8oS45vfpWq","executionInfo":{"status":"ok","timestamp":1700144447968,"user_tz":-330,"elapsed":2,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"outputs":[],"source":["# Dataloader of Gidaris & Komodakis, CVPR 2018\n","# Adapted from:\n","# https://github.com/gidariss/FewShotWithoutForgetting/blob/master/dataloader.py\n","from __future__ import print_function\n","\n","import os\n","import os.path\n","import numpy as np\n","import random\n","import pickle\n","import json\n","import math\n","\n","import torch\n","import torch.utils.data as data\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torchnet as tnt\n","\n","import h5py\n","\n","from PIL import Image\n","from PIL import ImageEnhance\n","\n","from pdb import set_trace as breakpoint\n","\n","\n","# Set the appropriate paths of the datasets here.\n","_CIFAR_FS_DATASET_DIR = '/mnt/cube/datasets/few-shot/CIFAR_FS'\n","\n","def buildLabelIndex(labels):\n","    label2inds = {}\n","    for idx, label in enumerate(labels):\n","        if label not in label2inds:\n","            label2inds[label] = []\n","        label2inds[label].append(idx)\n","\n","    return label2inds\n","\n","def load_data(file):\n","    try:\n","        with open(file, 'rb') as fo:\n","            data = pickle.load(fo)\n","        return data\n","    except:\n","        with open(file, 'rb') as f:\n","            u = pickle._Unpickler(f)\n","            u.encoding = 'latin1'\n","            data = u.load()\n","        return data\n","\n","class CIFAR_FS(data.Dataset):\n","    def __init__(self, phase='train', do_not_use_random_transf=False):\n","\n","        assert(phase=='train' or phase=='val' or phase=='test')\n","        self.phase = phase\n","        self.name = 'CIFAR_FS_' + phase\n","\n","        print('Loading CIFAR-FS dataset - phase {0}'.format(phase))\n","        file_train_categories_train_phase = os.path.join(\n","            _CIFAR_FS_DATASET_DIR,\n","            'CIFAR_FS_train.pickle')\n","        file_train_categories_val_phase = os.path.join(\n","            _CIFAR_FS_DATASET_DIR,\n","            'CIFAR_FS_train.pickle')\n","        file_train_categories_test_phase = os.path.join(\n","            _CIFAR_FS_DATASET_DIR,\n","            'CIFAR_FS_train.pickle')\n","        file_val_categories_val_phase = os.path.join(\n","            _CIFAR_FS_DATASET_DIR,\n","            'CIFAR_FS_val.pickle')\n","        file_test_categories_test_phase = os.path.join(\n","            _CIFAR_FS_DATASET_DIR,\n","            'CIFAR_FS_test.pickle')\n","\n","        if self.phase=='train':\n","            # During training phase we only load the training phase images\n","            # of the training categories (aka base categories).\n","            data_train = load_data(file_train_categories_train_phase)\n","            self.data = data_train['data']\n","            self.labels = data_train['labels']\n","\n","            self.label2ind = buildLabelIndex(self.labels)\n","            self.labelIds = sorted(self.label2ind.keys())\n","            self.num_cats = len(self.labelIds)\n","            self.labelIds_base = self.labelIds\n","            self.num_cats_base = len(self.labelIds_base)\n","\n","        elif self.phase=='val' or self.phase=='test':\n","            if self.phase=='test':\n","                # load data that will be used for evaluating the recognition\n","                # accuracy of the base categories.\n","                data_base = load_data(file_train_categories_test_phase)\n","                # load data that will be use for evaluating the few-shot recogniton\n","                # accuracy on the novel categories.\n","                data_novel = load_data(file_test_categories_test_phase)\n","            else: # phase=='val'\n","                # load data that will be used for evaluating the recognition\n","                # accuracy of the base categories.\n","                data_base = load_data(file_train_categories_val_phase)\n","                # load data that will be use for evaluating the few-shot recogniton\n","                # accuracy on the novel categories.\n","                data_novel = load_data(file_val_categories_val_phase)\n","\n","            self.data = np.concatenate(\n","                [data_base['data'], data_novel['data']], axis=0)\n","            self.labels = data_base['labels'] + data_novel['labels']\n","\n","            self.label2ind = buildLabelIndex(self.labels)\n","            self.labelIds = sorted(self.label2ind.keys())\n","            self.num_cats = len(self.labelIds)\n","\n","            self.labelIds_base = buildLabelIndex(data_base['labels']).keys()\n","            self.labelIds_novel = buildLabelIndex(data_novel['labels']).keys()\n","            self.num_cats_base = len(self.labelIds_base)\n","            self.num_cats_novel = len(self.labelIds_novel)\n","            intersection = set(self.labelIds_base) & set(self.labelIds_novel)\n","            assert(len(intersection) == 0)\n","        else:\n","            raise ValueError('Not valid phase {0}'.format(self.phase))\n","\n","        mean_pix = [x/255.0 for x in [129.37731888, 124.10583864, 112.47758569]]\n","\n","        std_pix = [x/255.0 for x in [68.20947949, 65.43124043, 70.45866994]]\n","\n","        normalize = transforms.Normalize(mean=mean_pix, std=std_pix)\n","\n","        if (self.phase=='test' or self.phase=='val') or (do_not_use_random_transf==True):\n","\n","            self.transform = transforms.Compose([\n","                lambda x: np.asarray(x),\n","                transforms.ToTensor(),\n","                normalize\n","            ])\n","        else:\n","\n","            self.transform = transforms.Compose([\n","                transforms.RandomCrop(32, padding=4),\n","                transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n","                transforms.RandomHorizontalFlip(),\n","                lambda x: np.asarray(x),\n","                transforms.ToTensor(),\n","                normalize\n","            ])\n","\n","    def __getitem__(self, index):\n","        img, label = self.data[index], self.labels[index]\n","        # doing this so that it is consistent with all other datasets\n","        # to return a PIL Image\n","        img = Image.fromarray(img)\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        return img, label\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","class FewShotDataloader():\n","    def __init__(self,\n","                 dataset,\n","                 nKnovel=5, # number of novel categories.\n","                 nKbase=-1, # number of base categories.\n","                 nExemplars=1, # number of training examples per novel category.\n","                 nTestNovel=15*5, # number of test examples for all the novel categories.\n","                 nTestBase=15*5, # number of test examples for all the base categories.\n","                 batch_size=1, # number of training episodes per batch.\n","                 num_workers=4,\n","                 epoch_size=2000, # number of batches per epoch.\n","                 ):\n","\n","        self.dataset = dataset\n","        self.phase = self.dataset.phase\n","        max_possible_nKnovel = (self.dataset.num_cats_base if self.phase=='train'\n","                                else self.dataset.num_cats_novel)\n","        assert(nKnovel >= 0 and nKnovel < max_possible_nKnovel)\n","        self.nKnovel = nKnovel\n","\n","        max_possible_nKbase = self.dataset.num_cats_base\n","        nKbase = nKbase if nKbase >= 0 else max_possible_nKbase\n","        if self.phase=='train' and nKbase > 0:\n","            nKbase -= self.nKnovel\n","            max_possible_nKbase -= self.nKnovel\n","\n","        assert(nKbase >= 0 and nKbase <= max_possible_nKbase)\n","        self.nKbase = nKbase\n","\n","        self.nExemplars = nExemplars\n","        self.nTestNovel = nTestNovel\n","        self.nTestBase = nTestBase\n","        self.batch_size = batch_size\n","        self.epoch_size = epoch_size\n","        self.num_workers = num_workers\n","        self.is_eval_mode = (self.phase=='test') or (self.phase=='val')\n","\n","    def sampleImageIdsFrom(self, cat_id, sample_size=1):\n","        \"\"\"\n","        Samples `sample_size` number of unique image ids picked from the\n","        category `cat_id` (i.e., self.dataset.label2ind[cat_id]).\n","\n","        Args:\n","            cat_id: a scalar with the id of the category from which images will\n","                be sampled.\n","            sample_size: number of images that will be sampled.\n","\n","        Returns:\n","            image_ids: a list of length `sample_size` with unique image ids.\n","        \"\"\"\n","        assert(cat_id in self.dataset.label2ind)\n","        assert(len(self.dataset.label2ind[cat_id]) >= sample_size)\n","        # Note: random.sample samples elements without replacement.\n","        return random.sample(self.dataset.label2ind[cat_id], sample_size)\n","\n","    def sampleCategories(self, cat_set, sample_size=1):\n","        \"\"\"\n","        Samples `sample_size` number of unique categories picked from the\n","        `cat_set` set of categories. `cat_set` can be either 'base' or 'novel'.\n","\n","        Args:\n","            cat_set: string that specifies the set of categories from which\n","                categories will be sampled.\n","            sample_size: number of categories that will be sampled.\n","\n","        Returns:\n","            cat_ids: a list of length `sample_size` with unique category ids.\n","        \"\"\"\n","        if cat_set=='base':\n","            labelIds = self.dataset.labelIds_base\n","        elif cat_set=='novel':\n","            labelIds = self.dataset.labelIds_novel\n","        else:\n","            raise ValueError('Not recognized category set {}'.format(cat_set))\n","\n","        assert(len(labelIds) >= sample_size)\n","        # return sample_size unique categories chosen from labelIds set of\n","        # categories (that can be either self.labelIds_base or self.labelIds_novel)\n","        # Note: random.sample samples elements without replacement.\n","        return random.sample(labelIds, sample_size)\n","\n","    def sample_base_and_novel_categories(self, nKbase, nKnovel):\n","        \"\"\"\n","        Samples `nKbase` number of base categories and `nKnovel` number of novel\n","        categories.\n","\n","        Args:\n","            nKbase: number of base categories\n","            nKnovel: number of novel categories\n","\n","        Returns:\n","            Kbase: a list of length 'nKbase' with the ids of the sampled base\n","                categories.\n","            Knovel: a list of lenght 'nKnovel' with the ids of the sampled novel\n","                categories.\n","        \"\"\"\n","        if self.is_eval_mode:\n","            assert(nKnovel <= self.dataset.num_cats_novel)\n","            # sample from the set of base categories 'nKbase' number of base\n","            # categories.\n","            Kbase = sorted(self.sampleCategories('base', nKbase))\n","            # sample from the set of novel categories 'nKnovel' number of novel\n","            # categories.\n","            Knovel = sorted(self.sampleCategories('novel', nKnovel))\n","        else:\n","            # sample from the set of base categories 'nKnovel' + 'nKbase' number\n","            # of categories.\n","            cats_ids = self.sampleCategories('base', nKnovel+nKbase)\n","            assert(len(cats_ids) == (nKnovel+nKbase))\n","            # Randomly pick 'nKnovel' number of fake novel categories and keep\n","            # the rest as base categories.\n","            random.shuffle(cats_ids)\n","            Knovel = sorted(cats_ids[:nKnovel])\n","            Kbase = sorted(cats_ids[nKnovel:])\n","\n","        return Kbase, Knovel\n","\n","    def sample_test_examples_for_base_categories(self, Kbase, nTestBase):\n","        \"\"\"\n","        Sample `nTestBase` number of images from the `Kbase` categories.\n","\n","        Args:\n","            Kbase: a list of length `nKbase` with the ids of the categories from\n","                where the images will be sampled.\n","            nTestBase: the total number of images that will be sampled.\n","\n","        Returns:\n","            Tbase: a list of length `nTestBase` with 2-element tuples. The 1st\n","                element of each tuple is the image id that was sampled and the\n","                2nd elemend is its category label (which is in the range\n","                [0, len(Kbase)-1]).\n","        \"\"\"\n","        Tbase = []\n","        if len(Kbase) > 0:\n","            # Sample for each base category a number images such that the total\n","            # number sampled images of all categories to be equal to `nTestBase`.\n","            KbaseIndices = np.random.choice(\n","                np.arange(len(Kbase)), size=nTestBase, replace=True)\n","            KbaseIndices, NumImagesPerCategory = np.unique(\n","                KbaseIndices, return_counts=True)\n","\n","            for Kbase_idx, NumImages in zip(KbaseIndices, NumImagesPerCategory):\n","                imd_ids = self.sampleImageIdsFrom(\n","                    Kbase[Kbase_idx], sample_size=NumImages)\n","                Tbase += [(img_id, Kbase_idx) for img_id in imd_ids]\n","\n","        assert(len(Tbase) == nTestBase)\n","\n","        return Tbase\n","\n","    def sample_train_and_test_examples_for_novel_categories(\n","            self, Knovel, nTestNovel, nExemplars, nKbase):\n","        \"\"\"Samples train and test examples of the novel categories.\n","\n","        Args:\n","    \t    Knovel: a list with the ids of the novel categories.\n","            nTestNovel: the total number of test images that will be sampled\n","                from all the novel categories.\n","            nExemplars: the number of training examples per novel category that\n","                will be sampled.\n","            nKbase: the number of base categories. It is used as offset of the\n","                category index of each sampled image.\n","\n","        Returns:\n","            Tnovel: a list of length `nTestNovel` with 2-element tuples. The\n","                1st element of each tuple is the image id that was sampled and\n","                the 2nd element is its category label (which is in the range\n","                [nKbase, nKbase + len(Knovel) - 1]).\n","            Exemplars: a list of length len(Knovel) * nExemplars of 2-element\n","                tuples. The 1st element of each tuple is the image id that was\n","                sampled and the 2nd element is its category label (which is in\n","                the ragne [nKbase, nKbase + len(Knovel) - 1]).\n","        \"\"\"\n","\n","        if len(Knovel) == 0:\n","            return [], []\n","\n","        nKnovel = len(Knovel)\n","        Tnovel = []\n","        Exemplars = []\n","        assert((nTestNovel % nKnovel) == 0)\n","        nEvalExamplesPerClass = int(nTestNovel / nKnovel)\n","\n","        for Knovel_idx in range(len(Knovel)):\n","            imd_ids = self.sampleImageIdsFrom(\n","                Knovel[Knovel_idx],\n","                sample_size=(nEvalExamplesPerClass + nExemplars))\n","\n","            imds_tnovel = imd_ids[:nEvalExamplesPerClass]\n","            imds_ememplars = imd_ids[nEvalExamplesPerClass:]\n","\n","            Tnovel += [(img_id, nKbase+Knovel_idx) for img_id in imds_tnovel]\n","            Exemplars += [(img_id, nKbase+Knovel_idx) for img_id in imds_ememplars]\n","        assert(len(Tnovel) == nTestNovel)\n","        assert(len(Exemplars) == len(Knovel) * nExemplars)\n","        random.shuffle(Exemplars)\n","\n","        return Tnovel, Exemplars\n","\n","    def sample_episode(self):\n","        \"\"\"Samples a training episode.\"\"\"\n","        nKnovel = self.nKnovel\n","        nKbase = self.nKbase\n","        nTestNovel = self.nTestNovel\n","        nTestBase = self.nTestBase\n","        nExemplars = self.nExemplars\n","\n","        Kbase, Knovel = self.sample_base_and_novel_categories(nKbase, nKnovel)\n","        Tbase = self.sample_test_examples_for_base_categories(Kbase, nTestBase)\n","        Tnovel, Exemplars = self.sample_train_and_test_examples_for_novel_categories(\n","            Knovel, nTestNovel, nExemplars, nKbase)\n","\n","        # concatenate the base and novel category examples.\n","        Test = Tbase + Tnovel\n","        random.shuffle(Test)\n","        Kall = Kbase + Knovel\n","\n","        return Exemplars, Test, Kall, nKbase\n","\n","    def createExamplesTensorData(self, examples):\n","        \"\"\"\n","        Creates the examples image and label tensor data.\n","\n","        Args:\n","            examples: a list of 2-element tuples, each representing a\n","                train or test example. The 1st element of each tuple\n","                is the image id of the example and 2nd element is the\n","                category label of the example, which is in the range\n","                [0, nK - 1], where nK is the total number of categories\n","                (both novel and base).\n","\n","        Returns:\n","            images: a tensor of shape [nExamples, Height, Width, 3] with the\n","                example images, where nExamples is the number of examples\n","                (i.e., nExamples = len(examples)).\n","            labels: a tensor of shape [nExamples] with the category label\n","                of each example.\n","        \"\"\"\n","        images = torch.stack(\n","            [self.dataset[img_idx][0] for img_idx, _ in examples], dim=0)\n","        labels = torch.LongTensor([label for _, label in examples])\n","        return images, labels\n","\n","    def get_iterator(self, epoch=0):\n","        rand_seed = epoch\n","        random.seed(rand_seed)\n","        np.random.seed(rand_seed)\n","        def load_function(iter_idx):\n","            Exemplars, Test, Kall, nKbase = self.sample_episode()\n","            Xt, Yt = self.createExamplesTensorData(Test)\n","            Kall = torch.LongTensor(Kall)\n","            if len(Exemplars) > 0:\n","                Xe, Ye = self.createExamplesTensorData(Exemplars)\n","                return Xe, Ye, Xt, Yt, Kall, nKbase\n","            else:\n","                return Xt, Yt, Kall, nKbase\n","\n","        tnt_dataset = tnt.dataset.ListDataset(\n","            elem_list=range(self.epoch_size), load=load_function)\n","        data_loader = tnt_dataset.parallel(\n","            batch_size=self.batch_size,\n","            num_workers=(0 if self.is_eval_mode else self.num_workers),\n","            shuffle=(False if self.is_eval_mode else True))\n","\n","        return data_loader\n","\n","    def __call__(self, epoch=0):\n","        return self.get_iterator(epoch)\n","\n","    def __len__(self):\n","        return int(self.epoch_size / self.batch_size)"]},{"cell_type":"code","source":["# Dataloader of Gidaris & Komodakis, CVPR 2018\n","# Adapted from:\n","# https://github.com/gidariss/FewShotWithoutForgetting/blob/master/dataloader.py\n","from __future__ import print_function\n","\n","import os\n","import os.path\n","import numpy as np\n","import random\n","import pickle\n","import json\n","import math\n","\n","import torch\n","import torch.utils.data as data\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torchnet as tnt\n","\n","import h5py\n","\n","from PIL import Image\n","from PIL import ImageEnhance\n","\n","from pdb import set_trace as breakpoint\n","\n","\n","# Set the appropriate paths of the datasets here.\n","_FC100_DATASET_DIR = '/mnt/cube/datasets/few-shot/FC100'\n","\n","def buildLabelIndex(labels):\n","    label2inds = {}\n","    for idx, label in enumerate(labels):\n","        if label not in label2inds:\n","            label2inds[label] = []\n","        label2inds[label].append(idx)\n","\n","    return label2inds\n","\n","def load_data(file):\n","    try:\n","        with open(file, 'rb') as fo:\n","            data = pickle.load(fo)\n","        return data\n","    except:\n","        with open(file, 'rb') as f:\n","            u = pickle._Unpickler(f)\n","            u.encoding = 'latin1'\n","            data = u.load()\n","        return data\n","\n","class FC100(data.Dataset):\n","    def __init__(self, phase='train', do_not_use_random_transf=False):\n","\n","        assert(phase=='train' or phase=='val' or phase=='test')\n","        self.phase = phase\n","        self.name = 'FC100_' + phase\n","\n","        print('Loading FC100 dataset - phase {0}'.format(phase))\n","        file_train_categories_train_phase = os.path.join(\n","            _FC100_DATASET_DIR,\n","            'FC100_train.pickle')\n","        file_train_categories_val_phase = os.path.join(\n","            _FC100_DATASET_DIR,\n","            'FC100_train.pickle')\n","        file_train_categories_test_phase = os.path.join(\n","            _FC100_DATASET_DIR,\n","            'FC100_train.pickle')\n","        file_val_categories_val_phase = os.path.join(\n","            _FC100_DATASET_DIR,\n","            'FC100_val.pickle')\n","        file_test_categories_test_phase = os.path.join(\n","            _FC100_DATASET_DIR,\n","            'FC100_test.pickle')\n","\n","        if self.phase=='train':\n","            # During training phase we only load the training phase images\n","            # of the training categories (aka base categories).\n","            data_train = load_data(file_train_categories_train_phase)\n","            self.data = data_train['data']\n","            self.labels = data_train['labels']\n","            #print (self.labels)\n","            self.label2ind = buildLabelIndex(self.labels)\n","            self.labelIds = sorted(self.label2ind.keys())\n","            self.num_cats = len(self.labelIds)\n","            self.labelIds_base = self.labelIds\n","            self.num_cats_base = len(self.labelIds_base)\n","            #print (self.data.shape)\n","        elif self.phase=='val' or self.phase=='test':\n","            if self.phase=='test':\n","                # load data that will be used for evaluating the recognition\n","                # accuracy of the base categories.\n","                data_base = load_data(file_train_categories_test_phase)\n","                # load data that will be use for evaluating the few-shot recogniton\n","                # accuracy on the novel categories.\n","                data_novel = load_data(file_test_categories_test_phase)\n","            else: # phase=='val'\n","                # load data that will be used for evaluating the recognition\n","                # accuracy of the base categories.\n","                data_base = load_data(file_train_categories_val_phase)\n","                # load data that will be use for evaluating the few-shot recogniton\n","                # accuracy on the novel categories.\n","                data_novel = load_data(file_val_categories_val_phase)\n","\n","            self.data = np.concatenate(\n","                [data_base['data'], data_novel['data']], axis=0)\n","            self.labels = data_base['labels'] + data_novel['labels']\n","\n","            self.label2ind = buildLabelIndex(self.labels)\n","            self.labelIds = sorted(self.label2ind.keys())\n","            self.num_cats = len(self.labelIds)\n","\n","            self.labelIds_base = buildLabelIndex(data_base['labels']).keys()\n","            self.labelIds_novel = buildLabelIndex(data_novel['labels']).keys()\n","            self.num_cats_base = len(self.labelIds_base)\n","            self.num_cats_novel = len(self.labelIds_novel)\n","            intersection = set(self.labelIds_base) & set(self.labelIds_novel)\n","            assert(len(intersection) == 0)\n","        else:\n","            raise ValueError('Not valid phase {0}'.format(self.phase))\n","\n","        mean_pix = [x/255.0 for x in [129.37731888, 124.10583864, 112.47758569]]\n","\n","        std_pix = [x/255.0 for x in [68.20947949, 65.43124043, 70.45866994]]\n","\n","        normalize = transforms.Normalize(mean=mean_pix, std=std_pix)\n","\n","        if (self.phase=='test' or self.phase=='val') or (do_not_use_random_transf==True):\n","            self.transform = transforms.Compose([\n","                lambda x: np.asarray(x),\n","                transforms.ToTensor(),\n","                normalize\n","            ])\n","        else:\n","            self.transform = transforms.Compose([\n","                transforms.RandomCrop(32, padding=4),\n","                transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n","                transforms.RandomHorizontalFlip(),\n","                lambda x: np.asarray(x),\n","                transforms.ToTensor(),\n","                normalize\n","            ])\n","\n","    def __getitem__(self, index):\n","        img, label = self.data[index], self.labels[index]\n","        # doing this so that it is consistent with all other datasets\n","        # to return a PIL Image\n","        img = Image.fromarray(img)\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        return img, label\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","class FewShotDataloader():\n","    def __init__(self,\n","                 dataset,\n","                 nKnovel=5, # number of novel categories.\n","                 nKbase=-1, # number of base categories.\n","                 nExemplars=1, # number of training examples per novel category.\n","                 nTestNovel=15*5, # number of test examples for all the novel categories.\n","                 nTestBase=15*5, # number of test examples for all the base categories.\n","                 batch_size=1, # number of training episodes per batch.\n","                 num_workers=4,\n","                 epoch_size=2000, # number of batches per epoch.\n","                 ):\n","\n","        self.dataset = dataset\n","        self.phase = self.dataset.phase\n","        max_possible_nKnovel = (self.dataset.num_cats_base if self.phase=='train'\n","                                else self.dataset.num_cats_novel)\n","        assert(nKnovel >= 0 and nKnovel < max_possible_nKnovel)\n","        self.nKnovel = nKnovel\n","\n","        max_possible_nKbase = self.dataset.num_cats_base\n","        nKbase = nKbase if nKbase >= 0 else max_possible_nKbase\n","        if self.phase=='train' and nKbase > 0:\n","            nKbase -= self.nKnovel\n","            max_possible_nKbase -= self.nKnovel\n","\n","        assert(nKbase >= 0 and nKbase <= max_possible_nKbase)\n","        self.nKbase = nKbase\n","\n","        self.nExemplars = nExemplars\n","        self.nTestNovel = nTestNovel\n","        self.nTestBase = nTestBase\n","        self.batch_size = batch_size\n","        self.epoch_size = epoch_size\n","        self.num_workers = num_workers\n","        self.is_eval_mode = (self.phase=='test') or (self.phase=='val')\n","\n","    def sampleImageIdsFrom(self, cat_id, sample_size=1):\n","        \"\"\"\n","        Samples `sample_size` number of unique image ids picked from the\n","        category `cat_id` (i.e., self.dataset.label2ind[cat_id]).\n","\n","        Args:\n","            cat_id: a scalar with the id of the category from which images will\n","                be sampled.\n","            sample_size: number of images that will be sampled.\n","\n","        Returns:\n","            image_ids: a list of length `sample_size` with unique image ids.\n","        \"\"\"\n","        assert(cat_id in self.dataset.label2ind)\n","        assert(len(self.dataset.label2ind[cat_id]) >= sample_size)\n","        # Note: random.sample samples elements without replacement.\n","        return random.sample(self.dataset.label2ind[cat_id], sample_size)\n","\n","    def sampleCategories(self, cat_set, sample_size=1):\n","        \"\"\"\n","        Samples `sample_size` number of unique categories picked from the\n","        `cat_set` set of categories. `cat_set` can be either 'base' or 'novel'.\n","\n","        Args:\n","            cat_set: string that specifies the set of categories from which\n","                categories will be sampled.\n","            sample_size: number of categories that will be sampled.\n","\n","        Returns:\n","            cat_ids: a list of length `sample_size` with unique category ids.\n","        \"\"\"\n","        if cat_set=='base':\n","            labelIds = self.dataset.labelIds_base\n","        elif cat_set=='novel':\n","            labelIds = self.dataset.labelIds_novel\n","        else:\n","            raise ValueError('Not recognized category set {}'.format(cat_set))\n","\n","        assert(len(labelIds) >= sample_size)\n","        # return sample_size unique categories chosen from labelIds set of\n","        # categories (that can be either self.labelIds_base or self.labelIds_novel)\n","        # Note: random.sample samples elements without replacement.\n","        return random.sample(labelIds, sample_size)\n","\n","    def sample_base_and_novel_categories(self, nKbase, nKnovel):\n","        \"\"\"\n","        Samples `nKbase` number of base categories and `nKnovel` number of novel\n","        categories.\n","\n","        Args:\n","            nKbase: number of base categories\n","            nKnovel: number of novel categories\n","\n","        Returns:\n","            Kbase: a list of length 'nKbase' with the ids of the sampled base\n","                categories.\n","            Knovel: a list of lenght 'nKnovel' with the ids of the sampled novel\n","                categories.\n","        \"\"\"\n","        if self.is_eval_mode:\n","            assert(nKnovel <= self.dataset.num_cats_novel)\n","            # sample from the set of base categories 'nKbase' number of base\n","            # categories.\n","            Kbase = sorted(self.sampleCategories('base', nKbase))\n","            # sample from the set of novel categories 'nKnovel' number of novel\n","            # categories.\n","            Knovel = sorted(self.sampleCategories('novel', nKnovel))\n","        else:\n","            # sample from the set of base categories 'nKnovel' + 'nKbase' number\n","            # of categories.\n","            cats_ids = self.sampleCategories('base', nKnovel+nKbase)\n","            assert(len(cats_ids) == (nKnovel+nKbase))\n","            # Randomly pick 'nKnovel' number of fake novel categories and keep\n","            # the rest as base categories.\n","            random.shuffle(cats_ids)\n","            Knovel = sorted(cats_ids[:nKnovel])\n","            Kbase = sorted(cats_ids[nKnovel:])\n","\n","        return Kbase, Knovel\n","\n","    def sample_test_examples_for_base_categories(self, Kbase, nTestBase):\n","        \"\"\"\n","        Sample `nTestBase` number of images from the `Kbase` categories.\n","\n","        Args:\n","            Kbase: a list of length `nKbase` with the ids of the categories from\n","                where the images will be sampled.\n","            nTestBase: the total number of images that will be sampled.\n","\n","        Returns:\n","            Tbase: a list of length `nTestBase` with 2-element tuples. The 1st\n","                element of each tuple is the image id that was sampled and the\n","                2nd elemend is its category label (which is in the range\n","                [0, len(Kbase)-1]).\n","        \"\"\"\n","        Tbase = []\n","        if len(Kbase) > 0:\n","            # Sample for each base category a number images such that the total\n","            # number sampled images of all categories to be equal to `nTestBase`.\n","            KbaseIndices = np.random.choice(\n","                np.arange(len(Kbase)), size=nTestBase, replace=True)\n","            KbaseIndices, NumImagesPerCategory = np.unique(\n","                KbaseIndices, return_counts=True)\n","\n","            for Kbase_idx, NumImages in zip(KbaseIndices, NumImagesPerCategory):\n","                imd_ids = self.sampleImageIdsFrom(\n","                    Kbase[Kbase_idx], sample_size=NumImages)\n","                Tbase += [(img_id, Kbase_idx) for img_id in imd_ids]\n","\n","        assert(len(Tbase) == nTestBase)\n","\n","        return Tbase\n","\n","    def sample_train_and_test_examples_for_novel_categories(\n","            self, Knovel, nTestNovel, nExemplars, nKbase):\n","        \"\"\"Samples train and test examples of the novel categories.\n","\n","        Args:\n","    \t    Knovel: a list with the ids of the novel categories.\n","            nTestNovel: the total number of test images that will be sampled\n","                from all the novel categories.\n","            nExemplars: the number of training examples per novel category that\n","                will be sampled.\n","            nKbase: the number of base categories. It is used as offset of the\n","                category index of each sampled image.\n","\n","        Returns:\n","            Tnovel: a list of length `nTestNovel` with 2-element tuples. The\n","                1st element of each tuple is the image id that was sampled and\n","                the 2nd element is its category label (which is in the range\n","                [nKbase, nKbase + len(Knovel) - 1]).\n","            Exemplars: a list of length len(Knovel) * nExemplars of 2-element\n","                tuples. The 1st element of each tuple is the image id that was\n","                sampled and the 2nd element is its category label (which is in\n","                the ragne [nKbase, nKbase + len(Knovel) - 1]).\n","        \"\"\"\n","\n","        if len(Knovel) == 0:\n","            return [], []\n","\n","        nKnovel = len(Knovel)\n","        Tnovel = []\n","        Exemplars = []\n","        assert((nTestNovel % nKnovel) == 0)\n","        nEvalExamplesPerClass = int(nTestNovel / nKnovel)\n","\n","        for Knovel_idx in range(len(Knovel)):\n","            imd_ids = self.sampleImageIdsFrom(\n","                Knovel[Knovel_idx],\n","                sample_size=(nEvalExamplesPerClass + nExemplars))\n","\n","            imds_tnovel = imd_ids[:nEvalExamplesPerClass]\n","            imds_ememplars = imd_ids[nEvalExamplesPerClass:]\n","\n","            Tnovel += [(img_id, nKbase+Knovel_idx) for img_id in imds_tnovel]\n","            Exemplars += [(img_id, nKbase+Knovel_idx) for img_id in imds_ememplars]\n","        assert(len(Tnovel) == nTestNovel)\n","        assert(len(Exemplars) == len(Knovel) * nExemplars)\n","        random.shuffle(Exemplars)\n","\n","        return Tnovel, Exemplars\n","\n","    def sample_episode(self):\n","        \"\"\"Samples a training episode.\"\"\"\n","        nKnovel = self.nKnovel\n","        nKbase = self.nKbase\n","        nTestNovel = self.nTestNovel\n","        nTestBase = self.nTestBase\n","        nExemplars = self.nExemplars\n","\n","        Kbase, Knovel = self.sample_base_and_novel_categories(nKbase, nKnovel)\n","        Tbase = self.sample_test_examples_for_base_categories(Kbase, nTestBase)\n","        Tnovel, Exemplars = self.sample_train_and_test_examples_for_novel_categories(\n","            Knovel, nTestNovel, nExemplars, nKbase)\n","\n","        # concatenate the base and novel category examples.\n","        Test = Tbase + Tnovel\n","        random.shuffle(Test)\n","        Kall = Kbase + Knovel\n","\n","        return Exemplars, Test, Kall, nKbase\n","\n","    def createExamplesTensorData(self, examples):\n","        \"\"\"\n","        Creates the examples image and label tensor data.\n","\n","        Args:\n","            examples: a list of 2-element tuples, each representing a\n","                train or test example. The 1st element of each tuple\n","                is the image id of the example and 2nd element is the\n","                category label of the example, which is in the range\n","                [0, nK - 1], where nK is the total number of categories\n","                (both novel and base).\n","\n","        Returns:\n","            images: a tensor of shape [nExamples, Height, Width, 3] with the\n","                example images, where nExamples is the number of examples\n","                (i.e., nExamples = len(examples)).\n","            labels: a tensor of shape [nExamples] with the category label\n","                of each example.\n","        \"\"\"\n","        images = torch.stack(\n","            [self.dataset[img_idx][0] for img_idx, _ in examples], dim=0)\n","        labels = torch.LongTensor([label for _, label in examples])\n","        return images, labels\n","\n","    def get_iterator(self, epoch=0):\n","        rand_seed = epoch\n","        random.seed(rand_seed)\n","        np.random.seed(rand_seed)\n","        def load_function(iter_idx):\n","            Exemplars, Test, Kall, nKbase = self.sample_episode()\n","            Xt, Yt = self.createExamplesTensorData(Test)\n","            Kall = torch.LongTensor(Kall)\n","            if len(Exemplars) > 0:\n","                Xe, Ye = self.createExamplesTensorData(Exemplars)\n","                return Xe, Ye, Xt, Yt, Kall, nKbase\n","            else:\n","                return Xt, Yt, Kall, nKbase\n","\n","        tnt_dataset = tnt.dataset.ListDataset(\n","            elem_list=range(self.epoch_size), load=load_function)\n","        data_loader = tnt_dataset.parallel(\n","            batch_size=self.batch_size,\n","            num_workers=(0 if self.is_eval_mode else self.num_workers),\n","            shuffle=(False if self.is_eval_mode else True))\n","\n","        return data_loader\n","\n","    def __call__(self, epoch=0):\n","        return self.get_iterator(epoch)\n","\n","    def __len__(self):\n","        return int(self.epoch_size / self.batch_size)"],"metadata":{"id":"eIj0Yaltgao8","executionInfo":{"status":"ok","timestamp":1700144486195,"user_tz":-330,"elapsed":480,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Dataloader of Gidaris & Komodakis, CVPR 2018\n","# Adapted from:\n","# https://github.com/gidariss/FewShotWithoutForgetting/blob/master/dataloader.py\n","from __future__ import print_function\n","\n","import os\n","import os.path\n","import numpy as np\n","import random\n","import pickle\n","import json\n","import math\n","\n","import torch\n","import torch.utils.data as data\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torchnet as tnt\n","\n","import h5py\n","\n","from PIL import Image\n","from PIL import ImageEnhance\n","\n","from pdb import set_trace as breakpoint\n","\n","\n","# Set the appropriate paths of the datasets here.\n","_MINI_IMAGENET_DATASET_DIR = '/efs/data/miniimagenet/kwonl/data/miniImageNet_numpy'\n","\n","def buildLabelIndex(labels):\n","    label2inds = {}\n","    for idx, label in enumerate(labels):\n","        if label not in label2inds:\n","            label2inds[label] = []\n","        label2inds[label].append(idx)\n","\n","    return label2inds\n","\n","\n","def load_data(file):\n","    try:\n","        with open(file, 'rb') as fo:\n","            data = pickle.load(fo)\n","        return data\n","    except:\n","        with open(file, 'rb') as f:\n","            u = pickle._Unpickler(f)\n","            u.encoding = 'latin1'\n","            data = u.load()\n","        return data\n","\n","class MiniImageNet(data.Dataset):\n","    def __init__(self, phase='train', do_not_use_random_transf=False):\n","\n","        self.base_folder = 'miniImagenet'\n","        assert(phase=='train' or phase=='val' or phase=='test')\n","        self.phase = phase\n","        self.name = 'MiniImageNet_' + phase\n","\n","        print('Loading mini ImageNet dataset - phase {0}'.format(phase))\n","        file_train_categories_train_phase = os.path.join(\n","            _MINI_IMAGENET_DATASET_DIR,\n","            'miniImageNet_category_split_train_phase_train.pickle')\n","        file_train_categories_val_phase = os.path.join(\n","            _MINI_IMAGENET_DATASET_DIR,\n","            'miniImageNet_category_split_train_phase_val.pickle')\n","        file_train_categories_test_phase = os.path.join(\n","            _MINI_IMAGENET_DATASET_DIR,\n","            'miniImageNet_category_split_train_phase_test.pickle')\n","        file_val_categories_val_phase = os.path.join(\n","            _MINI_IMAGENET_DATASET_DIR,\n","            'miniImageNet_category_split_val.pickle')\n","        file_test_categories_test_phase = os.path.join(\n","            _MINI_IMAGENET_DATASET_DIR,\n","            'miniImageNet_category_split_test.pickle')\n","\n","        if self.phase=='train':\n","            # During training phase we only load the training phase images\n","            # of the training categories (aka base categories).\n","            data_train = load_data(file_train_categories_train_phase)\n","            self.data = data_train['data']\n","            self.labels = data_train['labels']\n","\n","            self.label2ind = buildLabelIndex(self.labels)\n","            self.labelIds = sorted(self.label2ind.keys())\n","            self.num_cats = len(self.labelIds)\n","            self.labelIds_base = self.labelIds\n","            self.num_cats_base = len(self.labelIds_base)\n","\n","        elif self.phase=='val' or self.phase=='test':\n","            if self.phase=='test':\n","                # load data that will be used for evaluating the recognition\n","                # accuracy of the base categories.\n","                data_base = load_data(file_train_categories_test_phase)\n","                # load data that will be use for evaluating the few-shot recogniton\n","                # accuracy on the novel categories.\n","                data_novel = load_data(file_test_categories_test_phase)\n","            else: # phase=='val'\n","                # load data that will be used for evaluating the recognition\n","                # accuracy of the base categories.\n","                data_base = load_data(file_train_categories_val_phase)\n","                # load data that will be use for evaluating the few-shot recogniton\n","                # accuracy on the novel categories.\n","                data_novel = load_data(file_val_categories_val_phase)\n","\n","            self.data = np.concatenate(\n","                [data_base['data'], data_novel['data']], axis=0)\n","            self.labels = data_base['labels'] + data_novel['labels']\n","\n","            self.label2ind = buildLabelIndex(self.labels)\n","            self.labelIds = sorted(self.label2ind.keys())\n","            self.num_cats = len(self.labelIds)\n","\n","            self.labelIds_base = buildLabelIndex(data_base['labels']).keys()\n","            self.labelIds_novel = buildLabelIndex(data_novel['labels']).keys()\n","            self.num_cats_base = len(self.labelIds_base)\n","            self.num_cats_novel = len(self.labelIds_novel)\n","            intersection = set(self.labelIds_base) & set(self.labelIds_novel)\n","            assert(len(intersection) == 0)\n","        else:\n","            raise ValueError('Not valid phase {0}'.format(self.phase))\n","\n","        mean_pix = [x/255.0 for x in [120.39586422,  115.59361427, 104.54012653]]\n","        std_pix = [x/255.0 for x in [70.68188272,  68.27635443,  72.54505529]]\n","        normalize = transforms.Normalize(mean=mean_pix, std=std_pix)\n","\n","        if (self.phase=='test' or self.phase=='val') or (do_not_use_random_transf==True):\n","            self.transform = transforms.Compose([\n","                lambda x: np.asarray(x),\n","                transforms.ToTensor(),\n","                normalize\n","            ])\n","        else:\n","            self.transform = transforms.Compose([\n","                transforms.RandomCrop(84, padding=8),\n","                transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n","                transforms.RandomHorizontalFlip(),\n","                lambda x: np.asarray(x),\n","                transforms.ToTensor(),\n","                normalize\n","            ])\n","\n","    def __getitem__(self, index):\n","        img, label = self.data[index], self.labels[index]\n","        # doing this so that it is consistent with all other datasets\n","        # to return a PIL Image\n","        img = Image.fromarray(img)\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        return img, label\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","class FewShotDataloader():\n","    def __init__(self,\n","                 dataset,\n","                 nKnovel=5, # number of novel categories.\n","                 nKbase=-1, # number of base categories.\n","                 nExemplars=1, # number of training examples per novel category.\n","                 nTestNovel=15*5, # number of test examples for all the novel categories.\n","                 nTestBase=15*5, # number of test examples for all the base categories.\n","                 batch_size=1, # number of training episodes per batch.\n","                 num_workers=4,\n","                 epoch_size=2000, # number of batches per epoch.\n","                 ):\n","\n","        self.dataset = dataset\n","        self.phase = self.dataset.phase\n","        max_possible_nKnovel = (self.dataset.num_cats_base if self.phase=='train'\n","                                else self.dataset.num_cats_novel)\n","        assert(nKnovel >= 0 and nKnovel < max_possible_nKnovel)\n","        self.nKnovel = nKnovel\n","\n","        max_possible_nKbase = self.dataset.num_cats_base\n","        nKbase = nKbase if nKbase >= 0 else max_possible_nKbase\n","        if self.phase=='train' and nKbase > 0:\n","            nKbase -= self.nKnovel\n","            max_possible_nKbase -= self.nKnovel\n","\n","        assert(nKbase >= 0 and nKbase <= max_possible_nKbase)\n","        self.nKbase = nKbase\n","\n","        self.nExemplars = nExemplars\n","        self.nTestNovel = nTestNovel\n","        self.nTestBase = nTestBase\n","        self.batch_size = batch_size\n","        self.epoch_size = epoch_size\n","        self.num_workers = num_workers\n","        self.is_eval_mode = (self.phase=='test') or (self.phase=='val')\n","\n","    def sampleImageIdsFrom(self, cat_id, sample_size=1):\n","        \"\"\"\n","        Samples `sample_size` number of unique image ids picked from the\n","        category `cat_id` (i.e., self.dataset.label2ind[cat_id]).\n","\n","        Args:\n","            cat_id: a scalar with the id of the category from which images will\n","                be sampled.\n","            sample_size: number of images that will be sampled.\n","\n","        Returns:\n","            image_ids: a list of length `sample_size` with unique image ids.\n","        \"\"\"\n","        assert(cat_id in self.dataset.label2ind)\n","        assert(len(self.dataset.label2ind[cat_id]) >= sample_size)\n","        # Note: random.sample samples elements without replacement.\n","        return random.sample(self.dataset.label2ind[cat_id], sample_size)\n","\n","    def sampleCategories(self, cat_set, sample_size=1):\n","        \"\"\"\n","        Samples `sample_size` number of unique categories picked from the\n","        `cat_set` set of categories. `cat_set` can be either 'base' or 'novel'.\n","\n","        Args:\n","            cat_set: string that specifies the set of categories from which\n","                categories will be sampled.\n","            sample_size: number of categories that will be sampled.\n","\n","        Returns:\n","            cat_ids: a list of length `sample_size` with unique category ids.\n","        \"\"\"\n","        if cat_set=='base':\n","            labelIds = self.dataset.labelIds_base\n","        elif cat_set=='novel':\n","            labelIds = self.dataset.labelIds_novel\n","        else:\n","            raise ValueError('Not recognized category set {}'.format(cat_set))\n","\n","        assert(len(labelIds) >= sample_size)\n","        # return sample_size unique categories chosen from labelIds set of\n","        # categories (that can be either self.labelIds_base or self.labelIds_novel)\n","        # Note: random.sample samples elements without replacement.\n","        return random.sample(labelIds, sample_size)\n","\n","    def sample_base_and_novel_categories(self, nKbase, nKnovel):\n","        \"\"\"\n","        Samples `nKbase` number of base categories and `nKnovel` number of novel\n","        categories.\n","\n","        Args:\n","            nKbase: number of base categories\n","            nKnovel: number of novel categories\n","\n","        Returns:\n","            Kbase: a list of length 'nKbase' with the ids of the sampled base\n","                categories.\n","            Knovel: a list of lenght 'nKnovel' with the ids of the sampled novel\n","                categories.\n","        \"\"\"\n","        if self.is_eval_mode:\n","            assert(nKnovel <= self.dataset.num_cats_novel)\n","            # sample from the set of base categories 'nKbase' number of base\n","            # categories.\n","            Kbase = sorted(self.sampleCategories('base', nKbase))\n","            # sample from the set of novel categories 'nKnovel' number of novel\n","            # categories.\n","            Knovel = sorted(self.sampleCategories('novel', nKnovel))\n","        else:\n","            # sample from the set of base categories 'nKnovel' + 'nKbase' number\n","            # of categories.\n","            cats_ids = self.sampleCategories('base', nKnovel+nKbase)\n","            assert(len(cats_ids) == (nKnovel+nKbase))\n","            # Randomly pick 'nKnovel' number of fake novel categories and keep\n","            # the rest as base categories.\n","            random.shuffle(cats_ids)\n","            Knovel = sorted(cats_ids[:nKnovel])\n","            Kbase = sorted(cats_ids[nKnovel:])\n","\n","        return Kbase, Knovel\n","\n","    def sample_test_examples_for_base_categories(self, Kbase, nTestBase):\n","        \"\"\"\n","        Sample `nTestBase` number of images from the `Kbase` categories.\n","\n","        Args:\n","            Kbase: a list of length `nKbase` with the ids of the categories from\n","                where the images will be sampled.\n","            nTestBase: the total number of images that will be sampled.\n","\n","        Returns:\n","            Tbase: a list of length `nTestBase` with 2-element tuples. The 1st\n","                element of each tuple is the image id that was sampled and the\n","                2nd elemend is its category label (which is in the range\n","                [0, len(Kbase)-1]).\n","        \"\"\"\n","        Tbase = []\n","        if len(Kbase) > 0:\n","            # Sample for each base category a number images such that the total\n","            # number sampled images of all categories to be equal to `nTestBase`.\n","            KbaseIndices = np.random.choice(\n","                np.arange(len(Kbase)), size=nTestBase, replace=True)\n","            KbaseIndices, NumImagesPerCategory = np.unique(\n","                KbaseIndices, return_counts=True)\n","\n","            for Kbase_idx, NumImages in zip(KbaseIndices, NumImagesPerCategory):\n","                imd_ids = self.sampleImageIdsFrom(\n","                    Kbase[Kbase_idx], sample_size=NumImages)\n","                Tbase += [(img_id, Kbase_idx) for img_id in imd_ids]\n","\n","        assert(len(Tbase) == nTestBase)\n","\n","        return Tbase\n","\n","    def sample_train_and_test_examples_for_novel_categories(\n","            self, Knovel, nTestNovel, nExemplars, nKbase):\n","        \"\"\"Samples train and test examples of the novel categories.\n","\n","        Args:\n","    \t    Knovel: a list with the ids of the novel categories.\n","            nTestNovel: the total number of test images that will be sampled\n","                from all the novel categories.\n","            nExemplars: the number of training examples per novel category that\n","                will be sampled.\n","            nKbase: the number of base categories. It is used as offset of the\n","                category index of each sampled image.\n","\n","        Returns:\n","            Tnovel: a list of length `nTestNovel` with 2-element tuples. The\n","                1st element of each tuple is the image id that was sampled and\n","                the 2nd element is its category label (which is in the range\n","                [nKbase, nKbase + len(Knovel) - 1]).\n","            Exemplars: a list of length len(Knovel) * nExemplars of 2-element\n","                tuples. The 1st element of each tuple is the image id that was\n","                sampled and the 2nd element is its category label (which is in\n","                the ragne [nKbase, nKbase + len(Knovel) - 1]).\n","        \"\"\"\n","\n","        if len(Knovel) == 0:\n","            return [], []\n","\n","        nKnovel = len(Knovel)\n","        Tnovel = []\n","        Exemplars = []\n","        assert((nTestNovel % nKnovel) == 0)\n","        nEvalExamplesPerClass = int(nTestNovel / nKnovel)\n","\n","        for Knovel_idx in range(len(Knovel)):\n","            imd_ids = self.sampleImageIdsFrom(\n","                Knovel[Knovel_idx],\n","                sample_size=(nEvalExamplesPerClass + nExemplars))\n","\n","            imds_tnovel = imd_ids[:nEvalExamplesPerClass]\n","            imds_ememplars = imd_ids[nEvalExamplesPerClass:]\n","\n","            Tnovel += [(img_id, nKbase+Knovel_idx) for img_id in imds_tnovel]\n","            Exemplars += [(img_id, nKbase+Knovel_idx) for img_id in imds_ememplars]\n","        assert(len(Tnovel) == nTestNovel)\n","        assert(len(Exemplars) == len(Knovel) * nExemplars)\n","        random.shuffle(Exemplars)\n","\n","        return Tnovel, Exemplars\n","\n","    def sample_episode(self):\n","        \"\"\"Samples a training episode.\"\"\"\n","        nKnovel = self.nKnovel\n","        nKbase = self.nKbase\n","        nTestNovel = self.nTestNovel\n","        nTestBase = self.nTestBase\n","        nExemplars = self.nExemplars\n","\n","        Kbase, Knovel = self.sample_base_and_novel_categories(nKbase, nKnovel)\n","        Tbase = self.sample_test_examples_for_base_categories(Kbase, nTestBase)\n","        Tnovel, Exemplars = self.sample_train_and_test_examples_for_novel_categories(\n","            Knovel, nTestNovel, nExemplars, nKbase)\n","\n","        # concatenate the base and novel category examples.\n","        Test = Tbase + Tnovel\n","        random.shuffle(Test)\n","        Kall = Kbase + Knovel\n","\n","        return Exemplars, Test, Kall, nKbase\n","\n","    def createExamplesTensorData(self, examples):\n","        \"\"\"\n","        Creates the examples image and label tensor data.\n","\n","        Args:\n","            examples: a list of 2-element tuples, each representing a\n","                train or test example. The 1st element of each tuple\n","                is the image id of the example and 2nd element is the\n","                category label of the example, which is in the range\n","                [0, nK - 1], where nK is the total number of categories\n","                (both novel and base).\n","\n","        Returns:\n","            images: a tensor of shape [nExamples, Height, Width, 3] with the\n","                example images, where nExamples is the number of examples\n","                (i.e., nExamples = len(examples)).\n","            labels: a tensor of shape [nExamples] with the category label\n","                of each example.\n","        \"\"\"\n","        images = torch.stack(\n","            [self.dataset[img_idx][0] for img_idx, _ in examples], dim=0)\n","        labels = torch.LongTensor([label for _, label in examples])\n","        return images, labels\n","\n","    def get_iterator(self, epoch=0):\n","        rand_seed = epoch\n","        random.seed(rand_seed)\n","        np.random.seed(rand_seed)\n","        def load_function(iter_idx):\n","            Exemplars, Test, Kall, nKbase = self.sample_episode()\n","            Xt, Yt = self.createExamplesTensorData(Test)\n","            Kall = torch.LongTensor(Kall)\n","            if len(Exemplars) > 0:\n","                Xe, Ye = self.createExamplesTensorData(Exemplars)\n","                return Xe, Ye, Xt, Yt, Kall, nKbase\n","            else:\n","                return Xt, Yt, Kall, nKbase\n","\n","        tnt_dataset = tnt.dataset.ListDataset(\n","            elem_list=range(self.epoch_size), load=load_function)\n","        data_loader = tnt_dataset.parallel(\n","            batch_size=self.batch_size,\n","            num_workers=(0 if self.is_eval_mode else self.num_workers),\n","            shuffle=(False if self.is_eval_mode else True))\n","\n","        return data_loader\n","\n","    def __call__(self, epoch=0):\n","        return self.get_iterator(epoch)\n","\n","    def __len__(self):\n","        return int(self.epoch_size / self.batch_size)"],"metadata":{"id":"xu4QyCXPghwK","executionInfo":{"status":"ok","timestamp":1700144534802,"user_tz":-330,"elapsed":3,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Dataloader of Gidaris & Komodakis, CVPR 2018\n","# Adapted from:\n","# https://github.com/gidariss/FewShotWithoutForgetting/blob/master/dataloader.py\n","from __future__ import print_function\n","\n","import os\n","import os.path\n","import numpy as np\n","import random\n","import pickle\n","import json\n","import math\n","\n","import torch\n","import torch.utils.data as data\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torchnet as tnt\n","\n","import h5py\n","\n","from PIL import Image\n","from PIL import ImageEnhance\n","\n","from pdb import set_trace as breakpoint\n","\n","\n","# Set the appropriate paths of the datasets here.\n","_TIERED_IMAGENET_DATASET_DIR = '/mnt/cube/datasets/tiered-imagenet/'\n","\n","def buildLabelIndex(labels):\n","    label2inds = {}\n","    for idx, label in enumerate(labels):\n","        if label not in label2inds:\n","            label2inds[label] = []\n","        label2inds[label].append(idx)\n","\n","    return label2inds\n","\n","\n","def load_data(file):\n","    try:\n","        with open(file, 'rb') as fo:\n","            data = pickle.load(fo)\n","        return data\n","    except:\n","        with open(file, 'rb') as f:\n","            u = pickle._Unpickler(f)\n","            u.encoding = 'latin1'\n","            data = u.load()\n","        return data\n","\n","class tieredImageNet(data.Dataset):\n","    def __init__(self, phase='train', do_not_use_random_transf=False):\n","\n","        assert(phase=='train' or phase=='val' or phase=='test')\n","        self.phase = phase\n","        self.name = 'tieredImageNet_' + phase\n","\n","        print('Loading tiered ImageNet dataset - phase {0}'.format(phase))\n","        file_train_categories_train_phase = os.path.join(\n","            _TIERED_IMAGENET_DATASET_DIR,\n","            'train_images.npz')\n","        label_train_categories_train_phase = os.path.join(\n","            _TIERED_IMAGENET_DATASET_DIR,\n","            'train_labels.pkl')\n","        file_train_categories_val_phase = os.path.join(\n","            _TIERED_IMAGENET_DATASET_DIR,\n","            'train_images.npz')\n","        label_train_categories_val_phase = os.path.join(\n","            _TIERED_IMAGENET_DATASET_DIR,\n","            'train_labels.pkl')\n","        file_train_categories_test_phase = os.path.join(\n","            _TIERED_IMAGENET_DATASET_DIR,\n","            'train_images.npz')\n","        label_train_categories_test_phase = os.path.join(\n","            _TIERED_IMAGENET_DATASET_DIR,\n","            'train_labels.pkl')\n","\n","        file_val_categories_val_phase = os.path.join(\n","            _TIERED_IMAGENET_DATASET_DIR,\n","            'val_images.npz')\n","        label_val_categories_val_phase = os.path.join(\n","            _TIERED_IMAGENET_DATASET_DIR,\n","            'val_labels.pkl')\n","        file_test_categories_test_phase = os.path.join(\n","            _TIERED_IMAGENET_DATASET_DIR,\n","            'test_images.npz')\n","        label_test_categories_test_phase = os.path.join(\n","            _TIERED_IMAGENET_DATASET_DIR,\n","            'test_labels.pkl')\n","\n","        if self.phase=='train':\n","            # During training phase we only load the training phase images\n","            # of the training categories (aka base categories).\n","            data_train = load_data(label_train_categories_train_phase)\n","            #self.data = data_train['data']\n","            self.labels = data_train['labels']\n","            self.data = np.load(file_train_categories_train_phase)['images']#np.array(load_data(file_train_categories_train_phase))\n","            #self.labels = load_data(file_train_categories_train_phase)#data_train['labels']\n","\n","            self.label2ind = buildLabelIndex(self.labels)\n","            self.labelIds = sorted(self.label2ind.keys())\n","            self.num_cats = len(self.labelIds)\n","            self.labelIds_base = self.labelIds\n","            self.num_cats_base = len(self.labelIds_base)\n","\n","        elif self.phase=='val' or self.phase=='test':\n","            if self.phase=='test':\n","                # load data that will be used for evaluating the recognition\n","                # accuracy of the base categories.\n","                data_base = load_data(label_train_categories_test_phase)\n","                data_base_images = np.load(file_train_categories_test_phase)['images']\n","\n","                # load data that will be use for evaluating the few-shot recogniton\n","                # accuracy on the novel categories.\n","                data_novel = load_data(label_test_categories_test_phase)\n","                data_novel_images = np.load(file_test_categories_test_phase)['images']\n","            else: # phase=='val'\n","                # load data that will be used for evaluating the recognition\n","                # accuracy of the base categories.\n","                data_base = load_data(label_train_categories_val_phase)\n","                data_base_images = np.load(file_train_categories_val_phase)['images']\n","                #print (data_base_images)\n","                #print (data_base_images.shape)\n","                # load data that will be use for evaluating the few-shot recogniton\n","                # accuracy on the novel categories.\n","                data_novel = load_data(label_val_categories_val_phase)\n","                data_novel_images = np.load(file_val_categories_val_phase)['images']\n","\n","            self.data = np.concatenate(\n","                [data_base_images, data_novel_images], axis=0)\n","            self.labels = data_base['labels'] + data_novel['labels']\n","\n","            self.label2ind = buildLabelIndex(self.labels)\n","            self.labelIds = sorted(self.label2ind.keys())\n","            self.num_cats = len(self.labelIds)\n","\n","            self.labelIds_base = buildLabelIndex(data_base['labels']).keys()\n","            self.labelIds_novel = buildLabelIndex(data_novel['labels']).keys()\n","            self.num_cats_base = len(self.labelIds_base)\n","            self.num_cats_novel = len(self.labelIds_novel)\n","            intersection = set(self.labelIds_base) & set(self.labelIds_novel)\n","            print (intersection)\n","            assert(len(intersection) == 0)\n","        else:\n","            raise ValueError('Not valid phase {0}'.format(self.phase))\n","\n","        mean_pix = [x/255.0 for x in [120.39586422,  115.59361427, 104.54012653]]\n","        std_pix = [x/255.0 for x in [70.68188272,  68.27635443,  72.54505529]]\n","        normalize = transforms.Normalize(mean=mean_pix, std=std_pix)\n","\n","        if (self.phase=='test' or self.phase=='val') or (do_not_use_random_transf==True):\n","            self.transform = transforms.Compose([\n","                lambda x: np.asarray(x),\n","                transforms.ToTensor(),\n","                normalize\n","            ])\n","        else:\n","            self.transform = transforms.Compose([\n","                transforms.RandomCrop(84, padding=8),\n","                transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n","                transforms.RandomHorizontalFlip(),\n","                lambda x: np.asarray(x),\n","                transforms.ToTensor(),\n","                normalize\n","            ])\n","\n","    def __getitem__(self, index):\n","        img, label = self.data[index], self.labels[index]\n","        # doing this so that it is consistent with all other datasets\n","        # to return a PIL Image\n","        img = Image.fromarray(img)\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        return img, label\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","class FewShotDataloader():\n","    def __init__(self,\n","                 dataset,\n","                 nKnovel=5, # number of novel categories.\n","                 nKbase=-1, # number of base categories.\n","                 nExemplars=1, # number of training examples per novel category.\n","                 nTestNovel=15*5, # number of test examples for all the novel categories.\n","                 nTestBase=15*5, # number of test examples for all the base categories.\n","                 batch_size=1, # number of training episodes per batch.\n","                 num_workers=4,\n","                 epoch_size=2000, # number of batches per epoch.\n","                 ):\n","\n","        self.dataset = dataset\n","        self.phase = self.dataset.phase\n","        max_possible_nKnovel = (self.dataset.num_cats_base if self.phase=='train'\n","                                else self.dataset.num_cats_novel)\n","        assert(nKnovel >= 0 and nKnovel < max_possible_nKnovel)\n","        self.nKnovel = nKnovel\n","\n","        max_possible_nKbase = self.dataset.num_cats_base\n","        nKbase = nKbase if nKbase >= 0 else max_possible_nKbase\n","        if self.phase=='train' and nKbase > 0:\n","            nKbase -= self.nKnovel\n","            max_possible_nKbase -= self.nKnovel\n","\n","        assert(nKbase >= 0 and nKbase <= max_possible_nKbase)\n","        self.nKbase = nKbase\n","\n","        self.nExemplars = nExemplars\n","        self.nTestNovel = nTestNovel\n","        self.nTestBase = nTestBase\n","        self.batch_size = batch_size\n","        self.epoch_size = epoch_size\n","        self.num_workers = num_workers\n","        self.is_eval_mode = (self.phase=='test') or (self.phase=='val')\n","\n","    def sampleImageIdsFrom(self, cat_id, sample_size=1):\n","        \"\"\"\n","        Samples `sample_size` number of unique image ids picked from the\n","        category `cat_id` (i.e., self.dataset.label2ind[cat_id]).\n","\n","        Args:\n","            cat_id: a scalar with the id of the category from which images will\n","                be sampled.\n","            sample_size: number of images that will be sampled.\n","\n","        Returns:\n","            image_ids: a list of length `sample_size` with unique image ids.\n","        \"\"\"\n","        assert(cat_id in self.dataset.label2ind)\n","        assert(len(self.dataset.label2ind[cat_id]) >= sample_size)\n","        # Note: random.sample samples elements without replacement.\n","        return random.sample(self.dataset.label2ind[cat_id], sample_size)\n","\n","    def sampleCategories(self, cat_set, sample_size=1):\n","        \"\"\"\n","        Samples `sample_size` number of unique categories picked from the\n","        `cat_set` set of categories. `cat_set` can be either 'base' or 'novel'.\n","\n","        Args:\n","            cat_set: string that specifies the set of categories from which\n","                categories will be sampled.\n","            sample_size: number of categories that will be sampled.\n","\n","        Returns:\n","            cat_ids: a list of length `sample_size` with unique category ids.\n","        \"\"\"\n","        if cat_set=='base':\n","            labelIds = self.dataset.labelIds_base\n","        elif cat_set=='novel':\n","            labelIds = self.dataset.labelIds_novel\n","        else:\n","            raise ValueError('Not recognized category set {}'.format(cat_set))\n","\n","        assert(len(labelIds) >= sample_size)\n","        # return sample_size unique categories chosen from labelIds set of\n","        # categories (that can be either self.labelIds_base or self.labelIds_novel)\n","        # Note: random.sample samples elements without replacement.\n","        return random.sample(labelIds, sample_size)\n","\n","    def sample_base_and_novel_categories(self, nKbase, nKnovel):\n","        \"\"\"\n","        Samples `nKbase` number of base categories and `nKnovel` number of novel\n","        categories.\n","\n","        Args:\n","            nKbase: number of base categories\n","            nKnovel: number of novel categories\n","\n","        Returns:\n","            Kbase: a list of length 'nKbase' with the ids of the sampled base\n","                categories.\n","            Knovel: a list of lenght 'nKnovel' with the ids of the sampled novel\n","                categories.\n","        \"\"\"\n","        if self.is_eval_mode:\n","            assert(nKnovel <= self.dataset.num_cats_novel)\n","            # sample from the set of base categories 'nKbase' number of base\n","            # categories.\n","            Kbase = sorted(self.sampleCategories('base', nKbase))\n","            # sample from the set of novel categories 'nKnovel' number of novel\n","            # categories.\n","            Knovel = sorted(self.sampleCategories('novel', nKnovel))\n","        else:\n","            # sample from the set of base categories 'nKnovel' + 'nKbase' number\n","            # of categories.\n","            cats_ids = self.sampleCategories('base', nKnovel+nKbase)\n","            assert(len(cats_ids) == (nKnovel+nKbase))\n","            # Randomly pick 'nKnovel' number of fake novel categories and keep\n","            # the rest as base categories.\n","            random.shuffle(cats_ids)\n","            Knovel = sorted(cats_ids[:nKnovel])\n","            Kbase = sorted(cats_ids[nKnovel:])\n","\n","        return Kbase, Knovel\n","\n","    def sample_test_examples_for_base_categories(self, Kbase, nTestBase):\n","        \"\"\"\n","        Sample `nTestBase` number of images from the `Kbase` categories.\n","\n","        Args:\n","            Kbase: a list of length `nKbase` with the ids of the categories from\n","                where the images will be sampled.\n","            nTestBase: the total number of images that will be sampled.\n","\n","        Returns:\n","            Tbase: a list of length `nTestBase` with 2-element tuples. The 1st\n","                element of each tuple is the image id that was sampled and the\n","                2nd elemend is its category label (which is in the range\n","                [0, len(Kbase)-1]).\n","        \"\"\"\n","        Tbase = []\n","        if len(Kbase) > 0:\n","            # Sample for each base category a number images such that the total\n","            # number sampled images of all categories to be equal to `nTestBase`.\n","            KbaseIndices = np.random.choice(\n","                np.arange(len(Kbase)), size=nTestBase, replace=True)\n","            KbaseIndices, NumImagesPerCategory = np.unique(\n","                KbaseIndices, return_counts=True)\n","\n","            for Kbase_idx, NumImages in zip(KbaseIndices, NumImagesPerCategory):\n","                imd_ids = self.sampleImageIdsFrom(\n","                    Kbase[Kbase_idx], sample_size=NumImages)\n","                Tbase += [(img_id, Kbase_idx) for img_id in imd_ids]\n","\n","        assert(len(Tbase) == nTestBase)\n","\n","        return Tbase\n","\n","    def sample_train_and_test_examples_for_novel_categories(\n","            self, Knovel, nTestNovel, nExemplars, nKbase):\n","        \"\"\"Samples train and test examples of the novel categories.\n","\n","        Args:\n","    \t    Knovel: a list with the ids of the novel categories.\n","            nTestNovel: the total number of test images that will be sampled\n","                from all the novel categories.\n","            nExemplars: the number of training examples per novel category that\n","                will be sampled.\n","            nKbase: the number of base categories. It is used as offset of the\n","                category index of each sampled image.\n","\n","        Returns:\n","            Tnovel: a list of length `nTestNovel` with 2-element tuples. The\n","                1st element of each tuple is the image id that was sampled and\n","                the 2nd element is its category label (which is in the range\n","                [nKbase, nKbase + len(Knovel) - 1]).\n","            Exemplars: a list of length len(Knovel) * nExemplars of 2-element\n","                tuples. The 1st element of each tuple is the image id that was\n","                sampled and the 2nd element is its category label (which is in\n","                the ragne [nKbase, nKbase + len(Knovel) - 1]).\n","        \"\"\"\n","\n","        if len(Knovel) == 0:\n","            return [], []\n","\n","        nKnovel = len(Knovel)\n","        Tnovel = []\n","        Exemplars = []\n","        assert((nTestNovel % nKnovel) == 0)\n","        nEvalExamplesPerClass = int(nTestNovel / nKnovel)\n","\n","        for Knovel_idx in range(len(Knovel)):\n","            imd_ids = self.sampleImageIdsFrom(\n","                Knovel[Knovel_idx],\n","                sample_size=(nEvalExamplesPerClass + nExemplars))\n","\n","            imds_tnovel = imd_ids[:nEvalExamplesPerClass]\n","            imds_ememplars = imd_ids[nEvalExamplesPerClass:]\n","\n","            Tnovel += [(img_id, nKbase+Knovel_idx) for img_id in imds_tnovel]\n","            Exemplars += [(img_id, nKbase+Knovel_idx) for img_id in imds_ememplars]\n","        assert(len(Tnovel) == nTestNovel)\n","        assert(len(Exemplars) == len(Knovel) * nExemplars)\n","        random.shuffle(Exemplars)\n","\n","        return Tnovel, Exemplars\n","\n","    def sample_episode(self):\n","        \"\"\"Samples a training episode.\"\"\"\n","        nKnovel = self.nKnovel\n","        nKbase = self.nKbase\n","        nTestNovel = self.nTestNovel\n","        nTestBase = self.nTestBase\n","        nExemplars = self.nExemplars\n","\n","        Kbase, Knovel = self.sample_base_and_novel_categories(nKbase, nKnovel)\n","        Tbase = self.sample_test_examples_for_base_categories(Kbase, nTestBase)\n","        Tnovel, Exemplars = self.sample_train_and_test_examples_for_novel_categories(\n","            Knovel, nTestNovel, nExemplars, nKbase)\n","\n","        # concatenate the base and novel category examples.\n","        Test = Tbase + Tnovel\n","        random.shuffle(Test)\n","        Kall = Kbase + Knovel\n","\n","        return Exemplars, Test, Kall, nKbase\n","\n","    def createExamplesTensorData(self, examples):\n","        \"\"\"\n","        Creates the examples image and label tensor data.\n","\n","        Args:\n","            examples: a list of 2-element tuples, each representing a\n","                train or test example. The 1st element of each tuple\n","                is the image id of the example and 2nd element is the\n","                category label of the example, which is in the range\n","                [0, nK - 1], where nK is the total number of categories\n","                (both novel and base).\n","\n","        Returns:\n","            images: a tensor of shape [nExamples, Height, Width, 3] with the\n","                example images, where nExamples is the number of examples\n","                (i.e., nExamples = len(examples)).\n","            labels: a tensor of shape [nExamples] with the category label\n","                of each example.\n","        \"\"\"\n","        images = torch.stack(\n","            [self.dataset[img_idx][0] for img_idx, _ in examples], dim=0)\n","        labels = torch.LongTensor([label for _, label in examples])\n","        return images, labels\n","\n","    def get_iterator(self, epoch=0):\n","        rand_seed = epoch\n","        random.seed(rand_seed)\n","        np.random.seed(rand_seed)\n","        def load_function(iter_idx):\n","            Exemplars, Test, Kall, nKbase = self.sample_episode()\n","            Xt, Yt = self.createExamplesTensorData(Test)\n","            Kall = torch.LongTensor(Kall)\n","            if len(Exemplars) > 0:\n","                Xe, Ye = self.createExamplesTensorData(Exemplars)\n","                return Xe, Ye, Xt, Yt, Kall, nKbase\n","            else:\n","                return Xt, Yt, Kall, nKbase\n","\n","        tnt_dataset = tnt.dataset.ListDataset(\n","            elem_list=range(self.epoch_size), load=load_function)\n","        data_loader = tnt_dataset.parallel(\n","            batch_size=self.batch_size,\n","            num_workers=(0 if self.is_eval_mode else self.num_workers),\n","            shuffle=(False if self.is_eval_mode else True))\n","\n","        return data_loader\n","\n","    def __call__(self, epoch=0):\n","        return self.get_iterator(epoch)\n","\n","    def __len__(self):\n","        return int(self.epoch_size / self.batch_size)"],"metadata":{"id":"fw29evvlgwrE","executionInfo":{"status":"ok","timestamp":1700144553696,"user_tz":-330,"elapsed":2,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Model"],"metadata":{"id":"lT2KO-TDg1YT"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch\n","\n","# Embedding network used in Meta-learning with differentiable closed-form solvers\n","# (Bertinetto et al., in submission to NIPS 2018).\n","# They call the ridge rigressor version as \"Ridge Regression Differentiable Discriminator (R2D2).\"\n","\n","# Note that they use a peculiar ordering of functions, namely conv-BN-pooling-lrelu,\n","# as opposed to the conventional one (conv-BN-lrelu-pooling).\n","\n","def R2D2_conv_block(in_channels, out_channels, retain_activation=True, keep_prob=1.0):\n","    block = nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n","        nn.BatchNorm2d(out_channels),\n","        nn.MaxPool2d(2)\n","    )\n","    if retain_activation:\n","        block.add_module(\"LeakyReLU\", nn.LeakyReLU(0.1))\n","\n","    if keep_prob < 1.0:\n","        block.add_module(\"Dropout\", nn.Dropout(p=1 - keep_prob, inplace=False))\n","\n","    return block\n","\n","class R2D2Embedding(nn.Module):\n","    def __init__(self, x_dim=3, h1_dim=96, h2_dim=192, h3_dim=384, z_dim=512, \\\n","                 retain_last_activation=False):\n","        super(R2D2Embedding, self).__init__()\n","\n","        self.block1 = R2D2_conv_block(x_dim, h1_dim)\n","        self.block2 = R2D2_conv_block(h1_dim, h2_dim)\n","        self.block3 = R2D2_conv_block(h2_dim, h3_dim, keep_prob=0.9)\n","        # In the last conv block, we disable activation function to boost the classification accuracy.\n","        # This trick was proposed by Gidaris et al. (CVPR 2018).\n","        # With this trick, the accuracy goes up from 50% to 51%.\n","        # Although the authors of R2D2 did not mention this trick in the paper,\n","        # we were unable to reproduce the result of Bertinetto et al. without resorting to this trick.\n","        self.block4 = R2D2_conv_block(h3_dim, z_dim, retain_activation=retain_last_activation, keep_prob=0.7)\n","\n","    def forward(self, x):\n","        b1 = self.block1(x)\n","        b2 = self.block2(b1)\n","        b3 = self.block3(b2)\n","        b4 = self.block4(b3)\n","        # Flatten and concatenate the output of the 3rd and 4th conv blocks as proposed in R2D2 paper.\n","        return torch.cat((b3.view(b3.size(0), -1), b4.view(b4.size(0), -1)), 1)"],"metadata":{"id":"ZjUEK1spg29k","executionInfo":{"status":"ok","timestamp":1700144579442,"user_tz":-330,"elapsed":2,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","#from models.dropblock import DropBlock\n","\n","# This ResNet network was designed following the practice of the following papers:\n","# TADAM: Task dependent adaptive metric for improved few-shot learning (Oreshkin et al., in NIPS 2018) and\n","# A Simple Neural Attentive Meta-Learner (Mishra et al., in ICLR 2018).\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, drop_rate=0.0, drop_block=False, block_size=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.LeakyReLU(0.1)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = conv3x3(planes, planes)\n","        self.bn3 = nn.BatchNorm2d(planes)\n","        self.maxpool = nn.MaxPool2d(stride)\n","        self.downsample = downsample\n","        self.stride = stride\n","        self.drop_rate = drop_rate\n","        self.num_batches_tracked = 0\n","        self.drop_block = drop_block\n","        self.block_size = block_size\n","        self.DropBlock = DropBlock(block_size=self.block_size)\n","\n","    def forward(self, x):\n","        self.num_batches_tracked += 1\n","\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        out = self.maxpool(out)\n","\n","        if self.drop_rate > 0:\n","            if self.drop_block == True:\n","                feat_size = out.size()[2]\n","                keep_rate = max(1.0 - self.drop_rate / (20*2000) * (self.num_batches_tracked), 1.0 - self.drop_rate)\n","                gamma = (1 - keep_rate) / self.block_size**2 * feat_size**2 / (feat_size - self.block_size + 1)**2\n","                out = self.DropBlock(out, gamma=gamma)\n","            else:\n","                out = F.dropout(out, p=self.drop_rate, training=self.training, inplace=True)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, keep_prob=1.0, avg_pool=False, drop_rate=0.0, dropblock_size=5):\n","        self.inplanes = 3\n","        super(ResNet, self).__init__()\n","\n","        self.layer1 = self._make_layer(block, 64, stride=2, drop_rate=drop_rate)\n","        self.layer2 = self._make_layer(block, 160, stride=2, drop_rate=drop_rate)\n","        self.layer3 = self._make_layer(block, 320, stride=2, drop_rate=drop_rate, drop_block=True, block_size=dropblock_size)\n","        self.layer4 = self._make_layer(block, 640, stride=2, drop_rate=drop_rate, drop_block=True, block_size=dropblock_size)\n","        if avg_pool:\n","            self.avgpool = nn.AvgPool2d(5, stride=1)\n","        self.keep_prob = keep_prob\n","        self.keep_avg_pool = avg_pool\n","        self.dropout = nn.Dropout(p=1 - self.keep_prob, inplace=False)\n","        self.drop_rate = drop_rate\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def _make_layer(self, block, planes, stride=1, drop_rate=0.0, drop_block=False, block_size=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=1, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample, drop_rate, drop_block, block_size))\n","        self.inplanes = planes * block.expansion\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        if self.keep_avg_pool:\n","            x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        return x\n","\n","\n","def resnet12(keep_prob=1.0, avg_pool=False, **kwargs):\n","    \"\"\"Constructs a ResNet-12 model.\n","    \"\"\"\n","    model = ResNet(BasicBlock, keep_prob=keep_prob, avg_pool=avg_pool, **kwargs)\n","    return model"],"metadata":{"id":"Fy80gejeg50z","executionInfo":{"status":"ok","timestamp":1700144605868,"user_tz":-330,"elapsed":2,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import os\n","import sys\n","\n","import torch\n","from torch.autograd import Variable\n","import torch.nn as nn\n","#from qpth.qp import QPFunction\n","\n","\n","def computeGramMatrix(A, B):\n","    \"\"\"\n","    Constructs a linear kernel matrix between A and B.\n","    We assume that each row in A and B represents a d-dimensional feature vector.\n","\n","    Parameters:\n","      A:  a (n_batch, n, d) Tensor.\n","      B:  a (n_batch, m, d) Tensor.\n","    Returns: a (n_batch, n, m) Tensor.\n","    \"\"\"\n","\n","    assert(A.dim() == 3)\n","    assert(B.dim() == 3)\n","    assert(A.size(0) == B.size(0) and A.size(2) == B.size(2))\n","\n","    return torch.bmm(A, B.transpose(1,2))\n","\n","\n","def binv(b_mat):\n","    \"\"\"\n","    Computes an inverse of each matrix in the batch.\n","    Pytorch 0.4.1 does not support batched matrix inverse.\n","    Hence, we are solving AX=I.\n","\n","    Parameters:\n","      b_mat:  a (n_batch, n, n) Tensor.\n","    Returns: a (n_batch, n, n) Tensor.\n","    \"\"\"\n","\n","    id_matrix = b_mat.new_ones(b_mat.size(-1)).diag().expand_as(b_mat).cuda()\n","    b_inv, _ = torch.gesv(id_matrix, b_mat)\n","\n","    return b_inv\n","\n","\n","def one_hot(indices, depth):\n","    \"\"\"\n","    Returns a one-hot tensor.\n","    This is a PyTorch equivalent of Tensorflow's tf.one_hot.\n","\n","    Parameters:\n","      indices:  a (n_batch, m) Tensor or (m) Tensor.\n","      depth: a scalar. Represents the depth of the one hot dimension.\n","    Returns: a (n_batch, m, depth) Tensor or (m, depth) Tensor.\n","    \"\"\"\n","\n","    encoded_indicies = torch.zeros(indices.size() + torch.Size([depth])).cuda()\n","    index = indices.view(indices.size()+torch.Size([1]))\n","    encoded_indicies = encoded_indicies.scatter_(1,index,1)\n","\n","    return encoded_indicies\n","\n","def batched_kronecker(matrix1, matrix2):\n","    matrix1_flatten = matrix1.reshape(matrix1.size()[0], -1)\n","    matrix2_flatten = matrix2.reshape(matrix2.size()[0], -1)\n","    return torch.bmm(matrix1_flatten.unsqueeze(2), matrix2_flatten.unsqueeze(1)).reshape([matrix1.size()[0]] + list(matrix1.size()[1:]) + list(matrix2.size()[1:])).permute([0, 1, 3, 2, 4]).reshape(matrix1.size(0), matrix1.size(1) * matrix2.size(1), matrix1.size(2) * matrix2.size(2))\n","\n","def MetaOptNetHead_Ridge(query, support, support_labels, n_way, n_shot, lambda_reg=50.0, double_precision=False):\n","    \"\"\"\n","    Fits the support set with ridge regression and\n","    returns the classification score on the query set.\n","\n","    Parameters:\n","      query:  a (tasks_per_batch, n_query, d) Tensor.\n","      support:  a (tasks_per_batch, n_support, d) Tensor.\n","      support_labels: a (tasks_per_batch, n_support) Tensor.\n","      n_way: a scalar. Represents the number of classes in a few-shot classification task.\n","      n_shot: a scalar. Represents the number of support examples given per class.\n","      lambda_reg: a scalar. Represents the strength of L2 regularization.\n","    Returns: a (tasks_per_batch, n_query, n_way) Tensor.\n","    \"\"\"\n","\n","    tasks_per_batch = query.size(0)\n","    n_support = support.size(1)\n","    n_query = query.size(1)\n","\n","    assert(query.dim() == 3)\n","    assert(support.dim() == 3)\n","    assert(query.size(0) == support.size(0) and query.size(2) == support.size(2))\n","    assert(n_support == n_way * n_shot)      # n_support must equal to n_way * n_shot\n","\n","    #Here we solve the dual problem:\n","    #Note that the classes are indexed by m & samples are indexed by i.\n","    #min_{\\alpha}  0.5 \\sum_m ||w_m(\\alpha)||^2 + \\sum_i \\sum_m e^m_i alpha^m_i\n","\n","    #where w_m(\\alpha) = \\sum_i \\alpha^m_i x_i,\n","\n","    #\\alpha is an (n_support, n_way) matrix\n","    kernel_matrix = computeGramMatrix(support, support)\n","    kernel_matrix += lambda_reg * torch.eye(n_support).expand(tasks_per_batch, n_support, n_support).cuda()\n","\n","    block_kernel_matrix = kernel_matrix.repeat(n_way, 1, 1) #(n_way * tasks_per_batch, n_support, n_support)\n","\n","    support_labels_one_hot = one_hot(support_labels.view(tasks_per_batch * n_support), n_way) # (tasks_per_batch * n_support, n_way)\n","    support_labels_one_hot = support_labels_one_hot.transpose(0, 1) # (n_way, tasks_per_batch * n_support)\n","    support_labels_one_hot = support_labels_one_hot.reshape(n_way * tasks_per_batch, n_support)     # (n_way*tasks_per_batch, n_support)\n","\n","    G = block_kernel_matrix\n","    e = -2.0 * support_labels_one_hot\n","\n","    #This is a fake inequlity constraint as qpth does not support QP without an inequality constraint.\n","    id_matrix_1 = torch.zeros(tasks_per_batch*n_way, n_support, n_support)\n","    C = Variable(id_matrix_1)\n","    h = Variable(torch.zeros((tasks_per_batch*n_way, n_support)))\n","    dummy = Variable(torch.Tensor()).cuda()      # We want to ignore the equality constraint.\n","\n","    if double_precision:\n","        G, e, C, h = [x.double().cuda() for x in [G, e, C, h]]\n","\n","    else:\n","        G, e, C, h = [x.float().cuda() for x in [G, e, C, h]]\n","\n","    # Solve the following QP to fit SVM:\n","    #        \\hat z =   argmin_z 1/2 z^T G z + e^T z\n","    #                 subject to Cz <= h\n","    # We use detach() to prevent backpropagation to fixed variables.\n","    qp_sol = QPFunction(verbose=False)(G, e.detach(), C.detach(), h.detach(), dummy.detach(), dummy.detach())\n","    #qp_sol = QPFunction(verbose=False)(G, e.detach(), dummy.detach(), dummy.detach(), dummy.detach(), dummy.detach())\n","\n","    #qp_sol (n_way*tasks_per_batch, n_support)\n","    qp_sol = qp_sol.reshape(n_way, tasks_per_batch, n_support)\n","    #qp_sol (n_way, tasks_per_batch, n_support)\n","    qp_sol = qp_sol.permute(1, 2, 0)\n","    #qp_sol (tasks_per_batch, n_support, n_way)\n","\n","    # Compute the classification score.\n","    compatibility = computeGramMatrix(support, query)\n","    compatibility = compatibility.float()\n","    compatibility = compatibility.unsqueeze(3).expand(tasks_per_batch, n_support, n_query, n_way)\n","    qp_sol = qp_sol.reshape(tasks_per_batch, n_support, n_way)\n","    logits = qp_sol.float().unsqueeze(2).expand(tasks_per_batch, n_support, n_query, n_way)\n","    logits = logits * compatibility\n","    logits = torch.sum(logits, 1)\n","\n","    return logits\n","\n","def R2D2Head(query, support, support_labels, n_way, n_shot, l2_regularizer_lambda=50.0):\n","    \"\"\"\n","    Fits the support set with ridge regression and\n","    returns the classification score on the query set.\n","\n","    This model is the classification head described in:\n","    Meta-learning with differentiable closed-form solvers\n","    (Bertinetto et al., in submission to NIPS 2018).\n","\n","    Parameters:\n","      query:  a (tasks_per_batch, n_query, d) Tensor.\n","      support:  a (tasks_per_batch, n_support, d) Tensor.\n","      support_labels: a (tasks_per_batch, n_support) Tensor.\n","      n_way: a scalar. Represents the number of classes in a few-shot classification task.\n","      n_shot: a scalar. Represents the number of support examples given per class.\n","      l2_regularizer_lambda: a scalar. Represents the strength of L2 regularization.\n","    Returns: a (tasks_per_batch, n_query, n_way) Tensor.\n","    \"\"\"\n","\n","    tasks_per_batch = query.size(0)\n","    n_support = support.size(1)\n","\n","    assert(query.dim() == 3)\n","    assert(support.dim() == 3)\n","    assert(query.size(0) == support.size(0) and query.size(2) == support.size(2))\n","    assert(n_support == n_way * n_shot)      # n_support must equal to n_way * n_shot\n","\n","    support_labels_one_hot = one_hot(support_labels.view(tasks_per_batch * n_support), n_way)\n","    support_labels_one_hot = support_labels_one_hot.view(tasks_per_batch, n_support, n_way)\n","\n","    id_matrix = torch.eye(n_support).expand(tasks_per_batch, n_support, n_support).cuda()\n","\n","    # Compute the dual form solution of the ridge regression.\n","    # W = X^T(X X^T - lambda * I)^(-1) Y\n","    ridge_sol = computeGramMatrix(support, support) + l2_regularizer_lambda * id_matrix\n","    ridge_sol = binv(ridge_sol)\n","    ridge_sol = torch.bmm(support.transpose(1,2), ridge_sol)\n","    ridge_sol = torch.bmm(ridge_sol, support_labels_one_hot)\n","\n","    # Compute the classification score.\n","    # score = W X\n","    logits = torch.bmm(query, ridge_sol)\n","\n","    return logits\n","\n","\n","def MetaOptNetHead_SVM_He(query, support, support_labels, n_way, n_shot, C_reg=0.01, double_precision=False):\n","    \"\"\"\n","    Fits the support set with multi-class SVM and\n","    returns the classification score on the query set.\n","\n","    This is the multi-class SVM presented in:\n","    A simplified multi-class support vector machine with reduced dual optimization\n","    (He et al., Pattern Recognition Letter 2012).\n","\n","    This SVM is desirable because the dual variable of size is n_support\n","    (as opposed to n_way*n_support in the Weston&Watkins or Crammer&Singer multi-class SVM).\n","    This model is the classification head that we have initially used for our project.\n","    This was dropped since it turned out that it performs suboptimally on the meta-learning scenarios.\n","\n","    Parameters:\n","      query:  a (tasks_per_batch, n_query, d) Tensor.\n","      support:  a (tasks_per_batch, n_support, d) Tensor.\n","      support_labels: a (tasks_per_batch, n_support) Tensor.\n","      n_way: a scalar. Represents the number of classes in a few-shot classification task.\n","      n_shot: a scalar. Represents the number of support examples given per class.\n","      C_reg: a scalar. Represents the cost parameter C in SVM.\n","    Returns: a (tasks_per_batch, n_query, n_way) Tensor.\n","    \"\"\"\n","\n","    tasks_per_batch = query.size(0)\n","    n_support = support.size(1)\n","    n_query = query.size(1)\n","\n","    assert(query.dim() == 3)\n","    assert(support.dim() == 3)\n","    assert(query.size(0) == support.size(0) and query.size(2) == support.size(2))\n","    assert(n_support == n_way * n_shot)      # n_support must equal to n_way * n_shot\n","\n","\n","    kernel_matrix = computeGramMatrix(support, support)\n","\n","    V = (support_labels * n_way - torch.ones(tasks_per_batch, n_support, n_way).cuda()) / (n_way - 1)\n","    G = computeGramMatrix(V, V).detach()\n","    G = kernel_matrix * G\n","\n","    e = Variable(-1.0 * torch.ones(tasks_per_batch, n_support))\n","    id_matrix = torch.eye(n_support).expand(tasks_per_batch, n_support, n_support)\n","    C = Variable(torch.cat((id_matrix, -id_matrix), 1))\n","    h = Variable(torch.cat((C_reg * torch.ones(tasks_per_batch, n_support), torch.zeros(tasks_per_batch, n_support)), 1))\n","    dummy = Variable(torch.Tensor()).cuda()      # We want to ignore the equality constraint.\n","\n","    if double_precision:\n","        G, e, C, h = [x.double().cuda() for x in [G, e, C, h]]\n","    else:\n","        G, e, C, h = [x.cuda() for x in [G, e, C, h]]\n","\n","    # Solve the following QP to fit SVM:\n","    #        \\hat z =   argmin_z 1/2 z^T G z + e^T z\n","    #                 subject to Cz <= h\n","    # We use detach() to prevent backpropagation to fixed variables.\n","    qp_sol = QPFunction(verbose=False)(G, e.detach(), C.detach(), h.detach(), dummy.detach(), dummy.detach())\n","\n","    # Compute the classification score.\n","    compatibility = computeGramMatrix(query, support)\n","    compatibility = compatibility.float()\n","\n","    logits = qp_sol.float().unsqueeze(1).expand(tasks_per_batch, n_query, n_support)\n","    logits = logits * compatibility\n","    logits = logits.view(tasks_per_batch, n_query, n_shot, n_way)\n","    logits = torch.sum(logits, 2)\n","\n","    return logits\n","\n","def ProtoNetHead(query, support, support_labels, n_way, n_shot, normalize=True):\n","    \"\"\"\n","    Constructs the prototype representation of each class(=mean of support vectors of each class) and\n","    returns the classification score (=L2 distance to each class prototype) on the query set.\n","\n","    This model is the classification head described in:\n","    Prototypical Networks for Few-shot Learning\n","    (Snell et al., NIPS 2017).\n","\n","    Parameters:\n","      query:  a (tasks_per_batch, n_query, d) Tensor.\n","      support:  a (tasks_per_batch, n_support, d) Tensor.\n","      support_labels: a (tasks_per_batch, n_support) Tensor.\n","      n_way: a scalar. Represents the number of classes in a few-shot classification task.\n","      n_shot: a scalar. Represents the number of support examples given per class.\n","      normalize: a boolean. Represents whether if we want to normalize the distances by the embedding dimension.\n","    Returns: a (tasks_per_batch, n_query, n_way) Tensor.\n","    \"\"\"\n","\n","    tasks_per_batch = query.size(0)\n","    n_support = support.size(1)\n","    n_query = query.size(1)\n","    d = query.size(2)\n","\n","    assert(query.dim() == 3)\n","    assert(support.dim() == 3)\n","    assert(query.size(0) == support.size(0) and query.size(2) == support.size(2))\n","    assert(n_support == n_way * n_shot)      # n_support must equal to n_way * n_shot\n","\n","    support_labels_one_hot = one_hot(support_labels.view(tasks_per_batch * n_support), n_way)\n","    support_labels_one_hot = support_labels_one_hot.view(tasks_per_batch, n_support, n_way)\n","\n","    # From:\n","    # https://github.com/gidariss/FewShotWithoutForgetting/blob/master/architectures/PrototypicalNetworksHead.py\n","    #************************* Compute Prototypes **************************\n","    labels_train_transposed = support_labels_one_hot.transpose(1,2)\n","    # Batch matrix multiplication:\n","    #   prototypes = labels_train_transposed * features_train ==>\n","    #   [batch_size x nKnovel x num_channels] =\n","    #       [batch_size x nKnovel x num_train_examples] * [batch_size * num_train_examples * num_channels]\n","    prototypes = torch.bmm(labels_train_transposed, support)\n","    # Divide with the number of examples per novel category.\n","    prototypes = prototypes.div(\n","        labels_train_transposed.sum(dim=2, keepdim=True).expand_as(prototypes)\n","    )\n","\n","    # Distance Matrix Vectorization Trick\n","    AB = computeGramMatrix(query, prototypes)\n","    AA = (query * query).sum(dim=2, keepdim=True)\n","    BB = (prototypes * prototypes).sum(dim=2, keepdim=True).reshape(tasks_per_batch, 1, n_way)\n","    logits = AA.expand_as(AB) - 2 * AB + BB.expand_as(AB)\n","    logits = -logits\n","\n","    if normalize:\n","        logits = logits / d\n","\n","    return logits\n","\n","def MetaOptNetHead_SVM_CS(query, support, support_labels, n_way, n_shot, C_reg=0.1, double_precision=False, maxIter=15):\n","    \"\"\"\n","    Fits the support set with multi-class SVM and\n","    returns the classification score on the query set.\n","\n","    This is the multi-class SVM presented in:\n","    On the Algorithmic Implementation of Multiclass Kernel-based Vector Machines\n","    (Crammer and Singer, Journal of Machine Learning Research 2001).\n","\n","    This model is the classification head that we use for the final version.\n","    Parameters:\n","      query:  a (tasks_per_batch, n_query, d) Tensor.\n","      support:  a (tasks_per_batch, n_support, d) Tensor.\n","      support_labels: a (tasks_per_batch, n_support) Tensor.\n","      n_way: a scalar. Represents the number of classes in a few-shot classification task.\n","      n_shot: a scalar. Represents the number of support examples given per class.\n","      C_reg: a scalar. Represents the cost parameter C in SVM.\n","    Returns: a (tasks_per_batch, n_query, n_way) Tensor.\n","    \"\"\"\n","\n","    tasks_per_batch = query.size(0)\n","    n_support = support.size(1)\n","    n_query = query.size(1)\n","\n","    assert(query.dim() == 3)\n","    assert(support.dim() == 3)\n","    assert(query.size(0) == support.size(0) and query.size(2) == support.size(2))\n","    assert(n_support == n_way * n_shot)      # n_support must equal to n_way * n_shot\n","\n","    #Here we solve the dual problem:\n","    #Note that the classes are indexed by m & samples are indexed by i.\n","    #min_{\\alpha}  0.5 \\sum_m ||w_m(\\alpha)||^2 + \\sum_i \\sum_m e^m_i alpha^m_i\n","    #s.t.  \\alpha^m_i <= C^m_i \\forall m,i , \\sum_m \\alpha^m_i=0 \\forall i\n","\n","    #where w_m(\\alpha) = \\sum_i \\alpha^m_i x_i,\n","    #and C^m_i = C if m  = y_i,\n","    #C^m_i = 0 if m != y_i.\n","    #This borrows the notation of liblinear.\n","\n","    #\\alpha is an (n_support, n_way) matrix\n","    kernel_matrix = computeGramMatrix(support, support)\n","\n","    id_matrix_0 = torch.eye(n_way).expand(tasks_per_batch, n_way, n_way).cuda()\n","    block_kernel_matrix = batched_kronecker(kernel_matrix, id_matrix_0)\n","    #This seems to help avoid PSD error from the QP solver.\n","    block_kernel_matrix += 1.0 * torch.eye(n_way*n_support).expand(tasks_per_batch, n_way*n_support, n_way*n_support).cuda()\n","\n","    support_labels_one_hot = one_hot(support_labels.view(tasks_per_batch * n_support), n_way) # (tasks_per_batch * n_support, n_support)\n","    support_labels_one_hot = support_labels_one_hot.view(tasks_per_batch, n_support, n_way)\n","    support_labels_one_hot = support_labels_one_hot.reshape(tasks_per_batch, n_support * n_way)\n","\n","    G = block_kernel_matrix\n","    e = -1.0 * support_labels_one_hot\n","    #print (G.size())\n","    #This part is for the inequality constraints:\n","    #\\alpha^m_i <= C^m_i \\forall m,i\n","    #where C^m_i = C if m  = y_i,\n","    #C^m_i = 0 if m != y_i.\n","    id_matrix_1 = torch.eye(n_way * n_support).expand(tasks_per_batch, n_way * n_support, n_way * n_support)\n","    C = Variable(id_matrix_1)\n","    h = Variable(C_reg * support_labels_one_hot)\n","    #print (C.size(), h.size())\n","    #This part is for the equality constraints:\n","    #\\sum_m \\alpha^m_i=0 \\forall i\n","    id_matrix_2 = torch.eye(n_support).expand(tasks_per_batch, n_support, n_support).cuda()\n","\n","    A = Variable(batched_kronecker(id_matrix_2, torch.ones(tasks_per_batch, 1, n_way).cuda()))\n","    b = Variable(torch.zeros(tasks_per_batch, n_support))\n","    #print (A.size(), b.size())\n","    if double_precision:\n","        G, e, C, h, A, b = [x.double().cuda() for x in [G, e, C, h, A, b]]\n","    else:\n","        G, e, C, h, A, b = [x.float().cuda() for x in [G, e, C, h, A, b]]\n","\n","    # Solve the following QP to fit SVM:\n","    #        \\hat z =   argmin_z 1/2 z^T G z + e^T z\n","    #                 subject to Cz <= h\n","    # We use detach() to prevent backpropagation to fixed variables.\n","    qp_sol = QPFunction(verbose=False, maxIter=maxIter)(G, e.detach(), C.detach(), h.detach(), A.detach(), b.detach())\n","\n","    # Compute the classification score.\n","    compatibility = computeGramMatrix(support, query)\n","    compatibility = compatibility.float()\n","    compatibility = compatibility.unsqueeze(3).expand(tasks_per_batch, n_support, n_query, n_way)\n","    qp_sol = qp_sol.reshape(tasks_per_batch, n_support, n_way)\n","    logits = qp_sol.float().unsqueeze(2).expand(tasks_per_batch, n_support, n_query, n_way)\n","    logits = logits * compatibility\n","    logits = torch.sum(logits, 1)\n","\n","    return logits\n","\n","def MetaOptNetHead_SVM_WW(query, support, support_labels, n_way, n_shot, C_reg=0.00001, double_precision=False):\n","    \"\"\"\n","    Fits the support set with multi-class SVM and\n","    returns the classification score on the query set.\n","\n","    This is the multi-class SVM presented in:\n","    Support Vector Machines for Multi Class Pattern Recognition\n","    (Weston and Watkins, ESANN 1999).\n","\n","    Parameters:\n","      query:  a (tasks_per_batch, n_query, d) Tensor.\n","      support:  a (tasks_per_batch, n_support, d) Tensor.\n","      support_labels: a (tasks_per_batch, n_support) Tensor.\n","      n_way: a scalar. Represents the number of classes in a few-shot classification task.\n","      n_shot: a scalar. Represents the number of support examples given per class.\n","      C_reg: a scalar. Represents the cost parameter C in SVM.\n","    Returns: a (tasks_per_batch, n_query, n_way) Tensor.\n","    \"\"\"\n","    \"\"\"\n","    Fits the support set with multi-class SVM and\n","    returns the classification score on the query set.\n","\n","    This is the multi-class SVM presented in:\n","    Support Vector Machines for Multi Class Pattern Recognition\n","    (Weston and Watkins, ESANN 1999).\n","\n","    Parameters:\n","      query:  a (tasks_per_batch, n_query, d) Tensor.\n","      support:  a (tasks_per_batch, n_support, d) Tensor.\n","      support_labels: a (tasks_per_batch, n_support) Tensor.\n","      n_way: a scalar. Represents the number of classes in a few-shot classification task.\n","      n_shot: a scalar. Represents the number of support examples given per class.\n","      C_reg: a scalar. Represents the cost parameter C in SVM.\n","    Returns: a (tasks_per_batch, n_query, n_way) Tensor.\n","    \"\"\"\n","    tasks_per_batch = query.size(0)\n","    n_support = support.size(1)\n","    n_query = query.size(1)\n","\n","    assert(query.dim() == 3)\n","    assert(support.dim() == 3)\n","    assert(query.size(0) == support.size(0) and query.size(2) == support.size(2))\n","    assert(n_support == n_way * n_shot)      # n_support must equal to n_way * n_shot\n","\n","    #In theory, \\alpha is an (n_support, n_way) matrix\n","    #NOTE: In this implementation, we solve for a flattened vector of size (n_way*n_support)\n","    #In order to turn it into a matrix, you must first reshape it into an (n_way, n_support) matrix\n","    #then transpose it, resulting in (n_support, n_way) matrix\n","    kernel_matrix = computeGramMatrix(support, support) + torch.ones(tasks_per_batch, n_support, n_support).cuda()\n","\n","    id_matrix_0 = torch.eye(n_way).expand(tasks_per_batch, n_way, n_way).cuda()\n","    block_kernel_matrix = batched_kronecker(id_matrix_0, kernel_matrix)\n","\n","    kernel_matrix_mask_x = support_labels.reshape(tasks_per_batch, n_support, 1).expand(tasks_per_batch, n_support, n_support)\n","    kernel_matrix_mask_y = support_labels.reshape(tasks_per_batch, 1, n_support).expand(tasks_per_batch, n_support, n_support)\n","    kernel_matrix_mask = (kernel_matrix_mask_x == kernel_matrix_mask_y).float()\n","\n","    block_kernel_matrix_inter = kernel_matrix_mask * kernel_matrix\n","    block_kernel_matrix += block_kernel_matrix_inter.repeat(1, n_way, n_way)\n","\n","    kernel_matrix_mask_second_term = support_labels.reshape(tasks_per_batch, n_support, 1).expand(tasks_per_batch, n_support, n_support * n_way)\n","    kernel_matrix_mask_second_term = kernel_matrix_mask_second_term == torch.arange(n_way).long().repeat(n_support).reshape(n_support, n_way).transpose(1, 0).reshape(1, -1).repeat(n_support, 1).cuda()\n","    kernel_matrix_mask_second_term = kernel_matrix_mask_second_term.float()\n","\n","    block_kernel_matrix -= (2.0 - 1e-4) * (kernel_matrix_mask_second_term * kernel_matrix.repeat(1, 1, n_way)).repeat(1, n_way, 1)\n","\n","    Y_support = one_hot(support_labels.view(tasks_per_batch * n_support), n_way)\n","    Y_support = Y_support.view(tasks_per_batch, n_support, n_way)\n","    Y_support = Y_support.transpose(1, 2)   # (tasks_per_batch, n_way, n_support)\n","    Y_support = Y_support.reshape(tasks_per_batch, n_way * n_support)\n","\n","    G = block_kernel_matrix\n","\n","    e = -2.0 * torch.ones(tasks_per_batch, n_way * n_support)\n","    id_matrix = torch.eye(n_way * n_support).expand(tasks_per_batch, n_way * n_support, n_way * n_support)\n","\n","    C_mat = C_reg * torch.ones(tasks_per_batch, n_way * n_support).cuda() - C_reg * Y_support\n","\n","    C = Variable(torch.cat((id_matrix, -id_matrix), 1))\n","    #C = Variable(torch.cat((id_matrix_masked, -id_matrix_masked), 1))\n","    zer = torch.zeros(tasks_per_batch, n_way * n_support).cuda()\n","\n","    h = Variable(torch.cat((C_mat, zer), 1))\n","\n","    dummy = Variable(torch.Tensor()).cuda()      # We want to ignore the equality constraint.\n","\n","    if double_precision:\n","        G, e, C, h = [x.double().cuda() for x in [G, e, C, h]]\n","    else:\n","        G, e, C, h = [x.cuda() for x in [G, e, C, h]]\n","\n","    # Solve the following QP to fit SVM:\n","    #        \\hat z =   argmin_z 1/2 z^T G z + e^T z\n","    #                 subject to Cz <= h\n","    # We use detach() to prevent backpropagation to fixed variables.\n","    #qp_sol = QPFunction(verbose=False)(G, e.detach(), C.detach(), h.detach(), dummy.detach(), dummy.detach())\n","    qp_sol = QPFunction(verbose=False)(G, e, C, h, dummy.detach(), dummy.detach())\n","\n","    # Compute the classification score.\n","    compatibility = computeGramMatrix(support, query) + torch.ones(tasks_per_batch, n_support, n_query).cuda()\n","    compatibility = compatibility.float()\n","    compatibility = compatibility.unsqueeze(1).expand(tasks_per_batch, n_way, n_support, n_query)\n","    qp_sol = qp_sol.float()\n","    qp_sol = qp_sol.reshape(tasks_per_batch, n_way, n_support)\n","    A_i = torch.sum(qp_sol, 1)   # (tasks_per_batch, n_support)\n","    A_i = A_i.unsqueeze(1).expand(tasks_per_batch, n_way, n_support)\n","    qp_sol = qp_sol.float().unsqueeze(3).expand(tasks_per_batch, n_way, n_support, n_query)\n","    Y_support_reshaped = Y_support.reshape(tasks_per_batch, n_way, n_support)\n","    Y_support_reshaped = A_i * Y_support_reshaped\n","    Y_support_reshaped = Y_support_reshaped.unsqueeze(3).expand(tasks_per_batch, n_way, n_support, n_query)\n","    logits = (Y_support_reshaped - qp_sol) * compatibility\n","\n","    logits = torch.sum(logits, 2)\n","\n","    return logits.transpose(1, 2)\n","\n","class ClassificationHead(nn.Module):\n","    def __init__(self, base_learner='MetaOptNet', enable_scale=True):\n","        super(ClassificationHead, self).__init__()\n","        if ('SVM-CS' in base_learner):\n","            self.head = MetaOptNetHead_SVM_CS\n","        elif ('Ridge' in base_learner):\n","            self.head = MetaOptNetHead_Ridge\n","        elif ('R2D2' in base_learner):\n","            self.head = R2D2Head\n","        elif ('Proto' in base_learner):\n","            self.head = ProtoNetHead\n","        elif ('SVM-He' in base_learner):\n","            self.head = MetaOptNetHead_SVM_He\n","        elif ('SVM-WW' in base_learner):\n","            self.head = MetaOptNetHead_SVM_WW\n","        else:\n","            print (\"Cannot recognize the base learner type\")\n","            assert(False)\n","\n","        # Add a learnable scale\n","        self.enable_scale = enable_scale\n","        self.scale = nn.Parameter(torch.FloatTensor([1.0]))\n","\n","    def forward(self, query, support, support_labels, n_way, n_shot, **kwargs):\n","        if self.enable_scale:\n","            return self.scale * self.head(query, support, support_labels, n_way, n_shot, **kwargs)\n","        else:\n","            return self.head(query, support, support_labels, n_way, n_shot, **kwargs)"],"metadata":{"id":"2LW0DDIdg_pP","executionInfo":{"status":"ok","timestamp":1700144640740,"user_tz":-330,"elapsed":2,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.distributions import Bernoulli\n","\n","\n","class DropBlock(nn.Module):\n","    def __init__(self, block_size):\n","        super(DropBlock, self).__init__()\n","\n","        self.block_size = block_size\n","        #self.gamma = gamma\n","        #self.bernouli = Bernoulli(gamma)\n","\n","    def forward(self, x, gamma):\n","        # shape: (bsize, channels, height, width)\n","\n","        if self.training:\n","            batch_size, channels, height, width = x.shape\n","\n","            bernoulli = Bernoulli(gamma)\n","            mask = bernoulli.sample((batch_size, channels, height - (self.block_size - 1), width - (self.block_size - 1))).cuda()\n","            #print((x.sample[-2], x.sample[-1]))\n","            block_mask = self._compute_block_mask(mask)\n","            #print (block_mask.size())\n","            #print (x.size())\n","            countM = block_mask.size()[0] * block_mask.size()[1] * block_mask.size()[2] * block_mask.size()[3]\n","            count_ones = block_mask.sum()\n","\n","            return block_mask * x * (countM / count_ones)\n","        else:\n","            return x\n","\n","    def _compute_block_mask(self, mask):\n","        left_padding = int((self.block_size-1) / 2)\n","        right_padding = int(self.block_size / 2)\n","\n","        batch_size, channels, height, width = mask.shape\n","        #print (\"mask\", mask[0][0])\n","        non_zero_idxs = mask.nonzero()\n","        nr_blocks = non_zero_idxs.shape[0]\n","\n","        offsets = torch.stack(\n","            [\n","                torch.arange(self.block_size).view(-1, 1).expand(self.block_size, self.block_size).reshape(-1), # - left_padding,\n","                torch.arange(self.block_size).repeat(self.block_size), #- left_padding\n","            ]\n","        ).t().cuda()\n","        offsets = torch.cat((torch.zeros(self.block_size**2, 2).cuda().long(), offsets.long()), 1)\n","\n","        if nr_blocks > 0:\n","            non_zero_idxs = non_zero_idxs.repeat(self.block_size ** 2, 1)\n","            offsets = offsets.repeat(nr_blocks, 1).view(-1, 4)\n","            offsets = offsets.long()\n","\n","            block_idxs = non_zero_idxs + offsets\n","            #block_idxs += left_padding\n","            padded_mask = F.pad(mask, (left_padding, right_padding, left_padding, right_padding))\n","            padded_mask[block_idxs[:, 0], block_idxs[:, 1], block_idxs[:, 2], block_idxs[:, 3]] = 1.\n","        else:\n","            padded_mask = F.pad(mask, (left_padding, right_padding, left_padding, right_padding))\n","\n","        block_mask = 1 - padded_mask#[:height, :width]\n","        return block_mask"],"metadata":{"id":"-LeewPfChHiL","executionInfo":{"status":"ok","timestamp":1700144656454,"user_tz":-330,"elapsed":707,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import math\n","\n","class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, retain_activation=True):\n","        super(ConvBlock, self).__init__()\n","\n","        self.block = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels)\n","        )\n","\n","        if retain_activation:\n","            self.block.add_module(\"ReLU\", nn.ReLU(inplace=True))\n","        self.block.add_module(\"MaxPool2d\", nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n","\n","    def forward(self, x):\n","        out = self.block(x)\n","        return out\n","\n","# Embedding network used in Matching Networks (Vinyals et al., NIPS 2016), Meta-LSTM (Ravi & Larochelle, ICLR 2017),\n","# MAML (w/ h_dim=z_dim=32) (Finn et al., ICML 2017), Prototypical Networks (Snell et al. NIPS 2017).\n","\n","class ProtoNetEmbedding(nn.Module):\n","    def __init__(self, x_dim=3, h_dim=64, z_dim=64, retain_last_activation=True):\n","        super(ProtoNetEmbedding, self).__init__()\n","        self.encoder = nn.Sequential(\n","          ConvBlock(x_dim, h_dim),\n","          ConvBlock(h_dim, h_dim),\n","          ConvBlock(h_dim, h_dim),\n","          ConvBlock(h_dim, z_dim, retain_activation=retain_last_activation),\n","        )\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        return x.view(x.size(0), -1)"],"metadata":{"id":"5pBxBxxshLfe","executionInfo":{"status":"ok","timestamp":1700144671498,"user_tz":-330,"elapsed":494,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["Train"],"metadata":{"id":"oMjj1R3NhVuC"}},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","import os\n","import argparse\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","\n","#from models.classification_heads import ClassificationHead\n","#from models.R2D2_embedding import R2D2Embedding\n","#from models.protonet_embedding import ProtoNetEmbedding\n","#from models.ResNet12_embedding import resnet12\n","\n","from utils import set_gpu, Timer, count_accuracy, check_dir, log\n","\n","def one_hot(indices, depth):\n","    \"\"\"\n","    Returns a one-hot tensor.\n","    This is a PyTorch equivalent of Tensorflow's tf.one_hot.\n","\n","    Parameters:\n","      indices:  a (n_batch, m) Tensor or (m) Tensor.\n","      depth: a scalar. Represents the depth of the one hot dimension.\n","    Returns: a (n_batch, m, depth) Tensor or (m, depth) Tensor.\n","    \"\"\"\n","\n","    encoded_indicies = torch.zeros(indices.size() + torch.Size([depth])).cuda()\n","    index = indices.view(indices.size()+torch.Size([1]))\n","    encoded_indicies = encoded_indicies.scatter_(1,index,1)\n","\n","    return encoded_indicies\n","\n","def get_model(options):\n","    # Choose the embedding network\n","    if options.network == 'ProtoNet':\n","        network = ProtoNetEmbedding().cuda()\n","    elif options.network == 'R2D2':\n","        network = R2D2Embedding().cuda()\n","    elif options.network == 'ResNet':\n","        if options.dataset == 'miniImageNet' or options.dataset == 'tieredImageNet':\n","            network = resnet12(avg_pool=False, drop_rate=0.1, dropblock_size=5).cuda()\n","            network = torch.nn.DataParallel(network, device_ids=[0, 1, 2, 3])\n","        else:\n","            network = resnet12(avg_pool=False, drop_rate=0.1, dropblock_size=2).cuda()\n","    else:\n","        print (\"Cannot recognize the network type\")\n","        assert(False)\n","\n","    # Choose the classification head\n","    if options.head == 'ProtoNet':\n","        cls_head = ClassificationHead(base_learner='ProtoNet').cuda()\n","    elif options.head == 'Ridge':\n","        cls_head = ClassificationHead(base_learner='Ridge').cuda()\n","    elif options.head == 'R2D2':\n","        cls_head = ClassificationHead(base_learner='R2D2').cuda()\n","    elif options.head == 'SVM':\n","        cls_head = ClassificationHead(base_learner='SVM-CS').cuda()\n","    else:\n","        print (\"Cannot recognize the dataset type\")\n","        assert(False)\n","\n","    return (network, cls_head)\n","\n","def get_dataset(options):\n","    # Choose the embedding network\n","    if options.dataset == 'miniImageNet':\n","        #from data.mini_imagenet import MiniImageNet, FewShotDataloader\n","        dataset_train = MiniImageNet(phase='train')\n","        dataset_val = MiniImageNet(phase='val')\n","        data_loader = FewShotDataloader\n","    elif options.dataset == 'tieredImageNet':\n","        #from data.tiered_imagenet import tieredImageNet, FewShotDataloader\n","        dataset_train = tieredImageNet(phase='train')\n","        dataset_val = tieredImageNet(phase='val')\n","        data_loader = FewShotDataloader\n","    elif options.dataset == 'CIFAR_FS':\n","        #from data.CIFAR_FS import CIFAR_FS, FewShotDataloader\n","        dataset_train = CIFAR_FS(phase='train')\n","        dataset_val = CIFAR_FS(phase='val')\n","        data_loader = FewShotDataloader\n","    elif options.dataset == 'FC100':\n","        #from data.FC100 import FC100, FewShotDataloader\n","        dataset_train = FC100(phase='train')\n","        dataset_val = FC100(phase='val')\n","        data_loader = FewShotDataloader\n","    else:\n","        print (\"Cannot recognize the dataset type\")\n","        assert(False)\n","\n","    return (dataset_train, dataset_val, data_loader)\n","\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--num-epoch', type=int, default=60,\n","                            help='number of training epochs')\n","    parser.add_argument('--save-epoch', type=int, default=10,\n","                            help='frequency of model saving')\n","    parser.add_argument('--train-shot', type=int, default=15,\n","                            help='number of support examples per training class')\n","    parser.add_argument('--val-shot', type=int, default=5,\n","                            help='number of support examples per validation class')\n","    parser.add_argument('--train-query', type=int, default=6,\n","                            help='number of query examples per training class')\n","    parser.add_argument('--val-episode', type=int, default=2000,\n","                            help='number of episodes per validation')\n","    parser.add_argument('--val-query', type=int, default=15,\n","                            help='number of query examples per validation class')\n","    parser.add_argument('--train-way', type=int, default=5,\n","                            help='number of classes in one training episode')\n","    parser.add_argument('--test-way', type=int, default=5,\n","                            help='number of classes in one test (or validation) episode')\n","    parser.add_argument('--save-path', default='./experiments/exp_1')\n","    parser.add_argument('--gpu', default='0, 1, 2, 3')\n","    parser.add_argument('--network', type=str, default='ProtoNet',\n","                            help='choose which embedding network to use. ProtoNet, R2D2, ResNet')\n","    parser.add_argument('--head', type=str, default='ProtoNet',\n","                            help='choose which classification head to use. ProtoNet, Ridge, R2D2, SVM')\n","    parser.add_argument('--dataset', type=str, default='miniImageNet',\n","                            help='choose which classification head to use. miniImageNet, tieredImageNet, CIFAR_FS, FC100')\n","    parser.add_argument('--episodes-per-batch', type=int, default=8,\n","                            help='number of episodes per batch')\n","    parser.add_argument('--eps', type=float, default=0.0,\n","                            help='epsilon of label smoothing')\n","\n","    opt = parser.parse_args()\n","\n","    (dataset_train, dataset_val, data_loader) = get_dataset(opt)\n","\n","    # Dataloader of Gidaris & Komodakis (CVPR 2018)\n","    dloader_train = data_loader(\n","        dataset=dataset_train,\n","        nKnovel=opt.train_way,\n","        nKbase=0,\n","        nExemplars=opt.train_shot, # num training examples per novel category\n","        nTestNovel=opt.train_way * opt.train_query, # num test examples for all the novel categories\n","        nTestBase=0, # num test examples for all the base categories\n","        batch_size=opt.episodes_per_batch,\n","        num_workers=4,\n","        epoch_size=opt.episodes_per_batch * 1000, # num of batches per epoch\n","    )\n","\n","    dloader_val = data_loader(\n","        dataset=dataset_val,\n","        nKnovel=opt.test_way,\n","        nKbase=0,\n","        nExemplars=opt.val_shot, # num training examples per novel category\n","        nTestNovel=opt.val_query * opt.test_way, # num test examples for all the novel categories\n","        nTestBase=0, # num test examples for all the base categories\n","        batch_size=1,\n","        num_workers=0,\n","        epoch_size=1 * opt.val_episode, # num of batches per epoch\n","    )\n","\n","    #set_gpu(opt.gpu)\n","    #check_dir('./experiments/')\n","    #check_dir(opt.save_path)\n","\n","    log_file_path = os.path.join(opt.save_path, \"train_log.txt\")\n","    #log(log_file_path, str(vars(opt)))\n","\n","    (embedding_net, cls_head) = get_model(opt)\n","\n","    optimizer = torch.optim.SGD([{'params': embedding_net.parameters()},\n","                                 {'params': cls_head.parameters()}], lr=0.1, momentum=0.9, \\\n","                                          weight_decay=5e-4, nesterov=True)\n","\n","    lambda_epoch = lambda e: 1.0 if e < 20 else (0.06 if e < 40 else 0.012 if e < 50 else (0.0024))\n","    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_epoch, last_epoch=-1)\n","\n","    max_val_acc = 0.0\n","\n","    #timer = Timer()\n","    x_entropy = torch.nn.CrossEntropyLoss()\n","\n","    for epoch in range(1, opt.num_epoch + 1):\n","        # Train on the training split\n","        lr_scheduler.step()\n","\n","        # Fetch the current epoch's learning rate\n","        epoch_learning_rate = 0.1\n","        for param_group in optimizer.param_groups:\n","            epoch_learning_rate = param_group['lr']\n","\n","        log(log_file_path, 'Train Epoch: {}\\tLearning Rate: {:.4f}'.format(\n","                            epoch, epoch_learning_rate))\n","\n","        _, _ = [x.train() for x in (embedding_net, cls_head)]\n","\n","        train_accuracies = []\n","        train_losses = []\n","\n","        for i, batch in enumerate(tqdm(dloader_train(epoch)), 1):\n","            data_support, labels_support, data_query, labels_query, _, _ = [x.cuda() for x in batch]\n","\n","            train_n_support = opt.train_way * opt.train_shot\n","            train_n_query = opt.train_way * opt.train_query\n","\n","            emb_support = embedding_net(data_support.reshape([-1] + list(data_support.shape[-3:])))\n","            emb_support = emb_support.reshape(opt.episodes_per_batch, train_n_support, -1)\n","\n","            emb_query = embedding_net(data_query.reshape([-1] + list(data_query.shape[-3:])))\n","            emb_query = emb_query.reshape(opt.episodes_per_batch, train_n_query, -1)\n","\n","            logit_query = cls_head(emb_query, emb_support, labels_support, opt.train_way, opt.train_shot)\n","\n","            smoothed_one_hot = one_hot(labels_query.reshape(-1), opt.train_way)\n","            smoothed_one_hot = smoothed_one_hot * (1 - opt.eps) + (1 - smoothed_one_hot) * opt.eps / (opt.train_way - 1)\n","\n","            log_prb = F.log_softmax(logit_query.reshape(-1, opt.train_way), dim=1)\n","            loss = -(smoothed_one_hot * log_prb).sum(dim=1)\n","            loss = loss.mean()\n","\n","            acc = count_accuracy(logit_query.reshape(-1, opt.train_way), labels_query.reshape(-1))\n","\n","            train_accuracies.append(acc.item())\n","            train_losses.append(loss.item())\n","\n","            if (i % 100 == 0):\n","                train_acc_avg = np.mean(np.array(train_accuracies))\n","                log(log_file_path, 'Train Epoch: {}\\tBatch: [{}/{}]\\tLoss: {:.4f}\\tAccuracy: {:.2f} % ({:.2f} %)'.format(\n","                            epoch, i, len(dloader_train), loss.item(), train_acc_avg, acc))\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Evaluate on the validation split\n","        _, _ = [x.eval() for x in (embedding_net, cls_head)]\n","\n","        val_accuracies = []\n","        val_losses = []\n","\n","        for i, batch in enumerate(tqdm(dloader_val(epoch)), 1):\n","            data_support, labels_support, data_query, labels_query, _, _ = [x.cuda() for x in batch]\n","\n","            test_n_support = opt.test_way * opt.val_shot\n","            test_n_query = opt.test_way * opt.val_query\n","\n","            emb_support = embedding_net(data_support.reshape([-1] + list(data_support.shape[-3:])))\n","            emb_support = emb_support.reshape(1, test_n_support, -1)\n","            emb_query = embedding_net(data_query.reshape([-1] + list(data_query.shape[-3:])))\n","            emb_query = emb_query.reshape(1, test_n_query, -1)\n","\n","            logit_query = cls_head(emb_query, emb_support, labels_support, opt.test_way, opt.val_shot)\n","\n","            loss = x_entropy(logit_query.reshape(-1, opt.test_way), labels_query.reshape(-1))\n","            acc = count_accuracy(logit_query.reshape(-1, opt.test_way), labels_query.reshape(-1))\n","\n","            val_accuracies.append(acc.item())\n","            val_losses.append(loss.item())\n","\n","        val_acc_avg = np.mean(np.array(val_accuracies))\n","        val_acc_ci95 = 1.96 * np.std(np.array(val_accuracies)) / np.sqrt(opt.val_episode)\n","\n","        val_loss_avg = np.mean(np.array(val_losses))\n","\n","        if val_acc_avg > max_val_acc:\n","            max_val_acc = val_acc_avg\n","            torch.save({'embedding': embedding_net.state_dict(), 'head': cls_head.state_dict()},\\\n","                       os.path.join(opt.save_path, 'best_model.pth'))\n","            log(log_file_path, 'Validation Epoch: {}\\t\\t\\tLoss: {:.4f}\\tAccuracy: {:.2f} ± {:.2f} % (Best)'\\\n","                  .format(epoch, val_loss_avg, val_acc_avg, val_acc_ci95))\n","        else:\n","            log(log_file_path, 'Validation Epoch: {}\\t\\t\\tLoss: {:.4f}\\tAccuracy: {:.2f} ± {:.2f} %'\\\n","                  .format(epoch, val_loss_avg, val_acc_avg, val_acc_ci95))\n","\n","        torch.save({'embedding': embedding_net.state_dict(), 'head': cls_head.state_dict()}\\\n","                   , os.path.join(opt.save_path, 'last_epoch.pth'))\n","\n","        if epoch % opt.save_epoch == 0:\n","            torch.save({'embedding': embedding_net.state_dict(), 'head': cls_head.state_dict()}\\\n","                       , os.path.join(opt.save_path, 'epoch_{}.pth'.format(epoch)))\n","\n","        log(log_file_path, 'Elapsed Time: {}/{}\\n'.format(timer.measure(), timer.measure(epoch / float(opt.num_epoch))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":262},"id":"BOTLdmGbhZ_7","executionInfo":{"status":"error","timestamp":1700144798893,"user_tz":-330,"elapsed":853,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"263598c9-c898-4cfb-c7dc-7046312470f2"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["usage: colab_kernel_launcher.py [-h] [--num-epoch NUM_EPOCH] [--save-epoch SAVE_EPOCH]\n","                                [--train-shot TRAIN_SHOT] [--val-shot VAL_SHOT]\n","                                [--train-query TRAIN_QUERY] [--val-episode VAL_EPISODE]\n","                                [--val-query VAL_QUERY] [--train-way TRAIN_WAY]\n","                                [--test-way TEST_WAY] [--save-path SAVE_PATH] [--gpu GPU]\n","                                [--network NETWORK] [--head HEAD] [--dataset DATASET]\n","                                [--episodes-per-batch EPISODES_PER_BATCH] [--eps EPS]\n","colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-921b2dbf-848b-4f78-984b-84397a60b4bb.json\n"]},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]}]}]}