{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN9NPxJ9CEGjdCcw7uyrgET"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Td3HFwhxd1TD","executionInfo":{"status":"ok","timestamp":1729856433648,"user_tz":-330,"elapsed":6667,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"a2258563-974b-4b6e-9f0d-78ba31253923"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Step 1: Mount Google Drive\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","os.chdir('/content/drive/MyDrive/surya/')"]},{"cell_type":"code","source":["# Step 2: Install Required Libraries\n","!pip install transformers faiss-cpu PyMuPDF pdf2image pillow\n","!apt-get install -y poppler-utils\n","!pip install langchain\n","!pip install -U langchain-community"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"USYBNLPrd7A2","executionInfo":{"status":"ok","timestamp":1729856448667,"user_tz":-330,"elapsed":15021,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"82ad3c3a-6eab-4288-a620-1149a319879e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0)\n","Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.24.12)\n","Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.17.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","poppler-utils is already the newest version (22.02.0-2ubuntu0.5).\n","0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n","Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.4)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.12)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.137)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.16.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.10)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n","Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.10)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n","Requirement already satisfied: langchain<0.4.0,>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.4)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.12)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.137)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.6.0)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.16.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.0)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.4->langchain-community) (0.3.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.4->langchain-community) (2.9.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain-community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain-community) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain-community) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.10)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain-community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain-community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain-community) (2.23.4)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n"]}]},{"cell_type":"code","source":["# Step 3: Extract Text and Images from PDF\n","import fitz  # PyMuPDF for PDF text extraction\n","from pdf2image import convert_from_path\n","from PIL import Image\n","\n","# Path to your PDF file\n","pdf_path = \"/content/drive/MyDrive/surya/Surya_Resume_AI.pdf\"\n","\n","# Initialize lists to hold text and image data\n","pdf_texts = []\n","pdf_images = []\n","\n","# Extract text and images from each page\n","with fitz.open(pdf_path) as pdf:\n","    for page_num in range(pdf.page_count):\n","        page = pdf[page_num]\n","        pdf_texts.append(page.get_text())  # Extract text from page\n","\n","        # Convert page to an image\n","        images = convert_from_path(pdf_path, first_page=page_num + 1, last_page=page_num + 1)\n","        pdf_images.extend(images)  # Store images"],"metadata":{"id":"3mc2PA-teF8l","executionInfo":{"status":"ok","timestamp":1729856448667,"user_tz":-330,"elapsed":3,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Step 4: Initialize CLIP Model and Processor\n","from transformers import CLIPProcessor, CLIPModel\n","import torch\n","import numpy as np\n","\n","clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n","processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n","\n","# Function to split long text into chunks for embedding\n","def split_text(text, chunk_size=77):\n","    words = text.split()\n","    return [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n","\n","# Prepare text data by splitting into chunks\n","chunked_texts = []\n","for text in pdf_texts:\n","    chunked_texts.extend(split_text(text))\n","\n","# Generate embeddings for text chunks\n","text_inputs = processor(text=chunked_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=77)\n","text_embeddings = clip_model.get_text_features(**text_inputs)\n","text_embeddings = text_embeddings / text_embeddings.norm(dim=-1, keepdim=True)\n","text_embeddings = text_embeddings.detach().cpu().numpy()\n","\n","# Generate embeddings for images\n","image_inputs = processor(images=pdf_images, return_tensors=\"pt\")\n","image_embeddings = clip_model.get_image_features(**image_inputs)\n","image_embeddings = image_embeddings / image_embeddings.norm(dim=-1, keepdim=True)\n","image_embeddings = image_embeddings.detach().cpu().numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abbrr-XJeO5d","executionInfo":{"status":"ok","timestamp":1729856455367,"user_tz":-330,"elapsed":6702,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"09082e7c-2afd-4ad0-df77-41ca0f75fa94"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from langchain.vectorstores import FAISS\n","import numpy as np\n","\n","# Combine text and image embeddings and metadata\n","combined_texts = chunked_texts + [\"Image\"] * len(pdf_images)  # Text labels for each embedding\n","combined_embeddings = np.concatenate((text_embeddings, image_embeddings), axis=0)  # Combined embeddings\n","\n","# Create a list of tuples containing text and corresponding embeddings\n","text_embedding_pairs = [(text, embedding) for text, embedding in zip(combined_texts, combined_embeddings)]\n","\n","# Initialize FAISS with precomputed embeddings and metadata\n","vector_store = FAISS.from_embeddings(\n","    text_embeddings=text_embedding_pairs,  # Pass the text-embedding pairs directly\n","    embedding=combined_embeddings,  # This is usually the embedding model\n","    metadatas=[{\"type\": t} for t in [\"text\"] * len(chunked_texts) + [\"image\"] * len(pdf_images)]  # Include metadata\n",")\n","\n","print(\"FAISS vector store created successfully.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WNxSz2kteTVt","executionInfo":{"status":"ok","timestamp":1729856593664,"user_tz":-330,"elapsed":540,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"6f281ca8-c6f4-4744-8a0e-bffbe05a570e"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"]},{"output_type":"stream","name":"stdout","text":["FAISS vector store created successfully.\n"]}]},{"cell_type":"code","source":["# Step 6: Define Query Functions for Text or Image-Based Output\n","\n","# Function to check if a query is asking for an image\n","def is_image_query(query):\n","    image_keywords = [\"image\", \"picture\", \"photo\", \"screenshot\", \"diagram\", \"biodata\"]\n","    return any(keyword in query.lower() for keyword in image_keywords)\n","\n","# Function to generate an embedding for a text query\n","def generate_text_embedding(query):\n","    text_input = processor(text=query, return_tensors=\"pt\", padding=True, truncation=True, max_length=77)\n","    text_embedding = clip_model.get_text_features(**text_input)\n","    text_embedding = text_embedding / text_embedding.norm(dim=-1, keepdim=True)\n","    return text_embedding.detach().cpu().numpy()"],"metadata":{"id":"kAh3yFJlfVCQ","executionInfo":{"status":"ok","timestamp":1729856627299,"user_tz":-330,"elapsed":574,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Step 7: Query the Vector Store and Display Results Based on Query Type\n","#query = \"Provide me an image of biodata.\"  # Example query; adjust as needed\n","query = \"Who is Suryakanta Karan\"  # Example query; adjust as needed\n","query_embedding = generate_text_embedding(query)\n","\n","# Perform the similarity search\n","results = vector_store.similarity_search_by_vector(query_embedding[0], k=10)  # Retrieve top 10 matches\n","\n","# Display results based on query type\n","print(\"\\nResults for Query:\")\n","image_query = is_image_query(query)\n","for result in results:\n","    if image_query and result.metadata.get(\"type\") == \"image\":\n","        print(\"Image Result:\")\n","        display(result.page_content)  # Replace with actual display code for images in Colab\n","    elif not image_query and result.metadata.get(\"type\") == \"text\":\n","        print(\"Text Description:\", result.page_content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-VZlrtoefYLG","executionInfo":{"status":"ok","timestamp":1729856687584,"user_tz":-330,"elapsed":557,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"c3f9be75-2f27-4068-db0c-a7f861c9b904"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Results for Query:\n","Text Description: Suryakanta Karan M: +91 8770228646 Email: suryakantakaran93@gmail.com LinkedIn: in/suryakanta-karan-595b4b34/ Professional Summary • Seasoned Sr. Lead Data Scientist with over 10+ years of expertise in developing, fine-tuning, and deploying Large Language Models (LLMs) such as GPT and LLaMA. Proven ability to deliver scalable NLP solutions using cutting-edge techniques including Retrieval-Augmented Generation (RAG), Reinforcement Learning from Human Feedback (RLHF), and advanced prompt engineering. Demonstrated leadership in managing cross-functional teams, mentoring engineers, and driving AI innovations that improve model accuracy\n","Text Description: Sampling) and Top-K Sampling techniques in cloud environments to optimize text generation models, balancing response quality and computational efficiency\n","Text Description: • Trained machine learning models (e.g., Decision Trees, Random Forest, and Neural Networks) to classify fraudulent and legitimate transactions, achieving high precision and recall scores. • Employed advanced anomaly detection techniques to identify deviations in transaction patterns, flagging potential fraud cases for review. • Integrated real-time fraud detection mechanisms into banking platforms, ensuring the system could detect and prevent fraudulent transactions as they occur. • Tuned model hyperparameters and adjusted detection thresholds to reduce false positives and\n","Text Description: and Entity Recognition: • Developed predictive models using machine learning algorithms (e.g., XGBoost, LSTM) to forecast commodity prices, leading to a 15% improvement in decision-making. • Integrated real-time market data using APIs, enabling up-to-date trading insights and enhancing trading strategies. • Designed AI algorithms for risk management, reducing potential losses by analyzing market volatility. • Collaborated with traders and financial analysts to implement an automated trading system, improving trade execution speed and profitability. • Deployed models using\n","Text Description: • Lead and mentored data science teams to ensure the successful delivery of data science projects, providing guidance on best practices, and ensuring compliance with relevant data privacy and security regulations. • Leveraged Large Language Models (LLMs) for natural language processing (NLP) tasks, such as text preprocessing, feature extraction, Question answering, and sentiment analysis. • Developed End to end RAG LLM App Using Llama2, BART, GPT-3.5, LlamaIndex models with Huggingface and OpenAI. • Implemented data cleanup and\n","Text Description: • Hands-on experience with containerization technologies like Docker and Kubernetes • Familiar with CI/CD best practices, Git, Unit Testing, ML Ops and microservices for API integration, Pipeline and model deployment Professional Experience Wissen Technology: Senior Lead Data Scientist 16th Dec 2022 – Present Responsibilities: • Collaborated with cross-functional teams to identify business requirements and technical specifications, leveraging Large Language Models (LLMs) for textual and audio data, ensuring accurate interpretation of stakeholder needs and alignment with technical solutions.\n","Text Description: handle structured and unstructured data from various documents. Deployed the solution across multiple business processes, improving operational speed and accuracy in document management. Education • Masters in Artificial Intelligence from Indian Institute of Technology – Jodhpur – 2025 • B. Tech (CSE) from Biju Patnaik University of Technology Odisha in 2014 Certifications & Courses • Machine Learning with Python Programming: iHUB DivyaSampark, IIT Roorkee & RBPL • Oracle Database 11g Administrator Certified Associate (OCA)\n","Text Description: machine unlearning techniques to ensure the removal of unnecessary or outdated information, improving the efficiency and relevance of the models. • Injected incremental data on a weekly basis from various sources such as Confluence, web APIs, xlsx, CSV files, and direct database connections into LLMs, enhancing the accuracy of in-house question-answering systems by 20% and improving user engagement with minimal intervention. • Designed deep learning models with TensorFlow, PyTorch, and Keras to classify unstructured data such as\n","Text Description: Feedback (RLHF), prompt engineering, and instruction tuning • Expertise in tokenization and embeddings (ELMo, GloVe, FastText) • Experience with Optical Character Recognition (OCR) and NLP frameworks for document processing • Utilized advanced fine-tuning techniques such as LoRA, QLoRa, federated learning, and machine unlearning for optimizing models AI Techniques • Expertise in federated learning, differential privacy, and privacy-preserving AI models • Deep learning models such as Transformers, LSTMs, GANs, VAEs, and Neural Networks • Real-time NLP streaming models\n","Text Description: M.Tech in Artificial Intelligence from IIT Jodhpur, focused on advancing AI technologies for real-world applications. Technical Skills Programming Languages & Data Science: • Programming: Python, SQL, Linux, Java • Data Science: PyTorch, TensorFlow, Hugging Face , Transformers, Vision Transformer (ViT), Machine Learning, Deep Learning, OCR. Pandas, NLP, Computer Vision, OCR, Keras,ML Ops, DL Ops NLP Techniques: • Extensive experience with transformer-based models (GPT, LLaMA 3, BERT, T5) • Proficient in Retrieval-Augmented Generation (RAG), Reinforcement Learning from Human\n"]}]}]}