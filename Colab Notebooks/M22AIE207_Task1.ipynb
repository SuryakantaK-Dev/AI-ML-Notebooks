{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPlhJu37pkIU6YLfePn2g8b"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Suryakanta Karan (M22AIE207) m22aie207@iitj.ac.in**"],"metadata":{"id":"V05p_z7LKKTy"}},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","os.chdir('/content/drive/MyDrive/surya/DL_Assignment/Fractal-1_Assignment-1')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fzvy6aa4KMHz","executionInfo":{"status":"ok","timestamp":1697727459381,"user_tz":-330,"elapsed":6837,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"a0a213f3-6467-4c21-8c85-e385e068bc30"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Import libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n","from keras.models import Model\n","from keras.datasets import mnist\n","from keras.preprocessing.image import ImageDataGenerator\n"],"metadata":{"id":"DOuAZjnTKZfk","executionInfo":{"status":"ok","timestamp":1697723913511,"user_tz":-330,"elapsed":3,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import os\n","import urllib.request\n","import tarfile\n","\n","# Specify the URL and file name\n","url = \"http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\"\n","file_name = \"VOCtrainval_06-Nov-2007.tar\"\n","\n","# Specify the path to check for the file\n","file_path = \"/content/drive/MyDrive/surya/DL_Assignment/Fractal-2_Assignment-2/\"\n","\n","# Specify the directory where you want to extract the files\n","output_directory = os.path.join(file_path, \"VOC2007\")\n","\n","# Check if the output_directory already exists\n","if not os.path.exists(output_directory):\n","    # Check if the file already exists in the specified path\n","    if not os.path.exists(os.path.join(file_path, file_name)):\n","        # If it doesn't exist, download the file\n","        urllib.request.urlretrieve(url, os.path.join(file_path, file_name))\n","\n","    # Open the TAR archive\n","    with tarfile.open(os.path.join(file_path, file_name), 'r') as tar_ref:\n","        # Extract all the contents to the specified directory\n","        tar_ref.extractall(output_directory)\n","else:\n","    print(f\"The directory '{output_directory}' already exists. No need to download and extract.\")\n"],"metadata":{"id":"jIr_SoPoNA8P","executionInfo":{"status":"ok","timestamp":1697724224320,"user_tz":-330,"elapsed":137728,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"YYBoT34fQbcz"}},{"cell_type":"code","source":["import os\n","import shutil\n","import random\n","from sklearn.model_selection import train_test_split\n","import cv2\n","\n","# Define the paths to your dataset and where you want to store the splits\n","dataset_path = '/content/drive/MyDrive/surya/DL_Assignment/Fractal-2_Assignment-2/VOC2007/VOCdevkit/VOC2007/'\n","output_path = '/content/drive/MyDrive/surya/DL_Assignment/Fractal-2_Assignment-2/VOC2007/VOCdevkit/VOC2007/Output'\n","\n","# Define the desired image size and pixel normalization values\n","image_size = (224, 224)\n","pixel_mean = (0.485, 0.456, 0.406)\n","pixel_std = (0.229, 0.224, 0.225)\n","\n","# Function to resize and normalize an image\n","def preprocess_image(image_path):\n","    img = cv2.imread(image_path)\n","    img = cv2.resize(img, image_size)\n","    img = (img / 255.0 - pixel_mean) / pixel_std\n","    return img\n","\n","# Create output directories\n","os.makedirs(output_path, exist_ok=True)\n","os.makedirs(os.path.join(output_path, 'train'), exist_ok=True)\n","os.makedirs(os.path.join(output_path, 'val'), exist_ok=True)\n","os.makedirs(os.path.join(output_path, 'test'), exist_ok=True)\n","\n","# List of image filenames\n","image_files = os.listdir(os.path.join(dataset_path, 'JPEGImages'))\n","\n","# Split the dataset into train, validation, and test sets\n","if True:  # Change to False for 70-10-20 split\n","    train_size = 0.8\n","else:\n","    train_size = 0.7\n","\n","train_files, test_files = train_test_split(image_files, train_size=train_size, random_state=42)\n","val_files, test_files = train_test_split(test_files, test_size=0.5, random_state=42)\n","\n","# Copy and preprocess images\n","for split, files in [('train', train_files), ('val', val_files), ('test', test_files)]:\n","    for file in files:\n","        image_path = os.path.join(dataset_path, 'JPEGImages', file)\n","        output_image_path = os.path.join(output_path, split, file)\n","        output_image = preprocess_image(image_path)\n","        cv2.imwrite(output_image_path, output_image)\n","\n","# Copy corresponding XML annotations\n","for split in ['train', 'val', 'test']:\n","    for file in os.listdir(os.path.join(dataset_path, 'Annotations')):\n","        if file.replace('.xml', '.jpg') in os.listdir(os.path.join(output_path, split)):\n","            shutil.copy(\n","                os.path.join(dataset_path, 'Annotations', file),\n","                os.path.join(output_path, split, file),\n","            )\n","\n","print(\"Dataset preparation and split completed.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IuxM1dtRVcpm","executionInfo":{"status":"ok","timestamp":1697728852550,"user_tz":-330,"elapsed":734584,"user":{"displayName":"Suryakanta Karan (M22AIE207)","userId":"09990899035878511614"}},"outputId":"84316e4e-abfd-4c33-c44d-78841c7d5819"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset preparation and split completed.\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import Input, Dense, GaussianNoise, Masking\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","import cv2\n","from tensorflow.keras.layers import Reshape\n","\n","#decoder = Reshape(input_shape[1:])(decoder)\n","\n","# Function to create and train autoencoder\n","def create_autoencoder(bottleneck_dim):\n","    input_shape = (224, 224, 3)\n","\n","    # Encoder\n","    input_layer = Input(shape=input_shape)\n","    encoder = Dense(bottleneck_dim, activation='relu')(input_layer)\n","\n","    # Decoder\n","    decoder = Dense(np.prod(input_shape), activation='sigmoid')(encoder)\n","    decoder = GaussianNoise(0.1)(decoder)\n","    decoder = Masking(mask_value=0.0)(decoder)\n","    decoder = Reshape(input_shape)(decoder)\n","    #decoder = Reshape(input_shape[1:])(decoder)\n","\n","    # Autoencoder\n","    autoencoder = Model(inputs=input_layer, outputs=decoder)\n","    autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n","\n","    return autoencoder\n","\n","# Function to apply masking strategy to images\n","def apply_mask(images, mask_percentage):\n","    mask = np.random.choice([0, 1], size=images.shape, p=[mask_percentage, 1 - mask_percentage])\n","    masked_images = images * mask\n","    return masked_images\n","\n","# Function to load and preprocess images\n","def load_and_preprocess_image(image_path):\n","    img = cv2.imread(image_path)\n","    if img is not None:\n","        img = img / 255.0  # Normalize the pixel values\n","    return img\n","\n","# Function to load the dataset\n","def load_dataset(split_path):\n","    dataset = []\n","    for split in ['train', 'val', 'test']:\n","        split_images = []\n","        for file in os.listdir(os.path.join(split_path, split)):\n","            image_path = os.path.join(split_path, split, file)\n","            img = load_and_preprocess_image(image_path)\n","            if img is not None:\n","                split_images.append(img)\n","        dataset.append(np.array(split_images))\n","    return dataset\n","\n","# Train and evaluate autoencoder\n","def train_and_evaluate_autoencoder(bottleneck_dim, mask_percentage, dataset):\n","    autoencoder = create_autoencoder(bottleneck_dim)\n","\n","    # Train autoencoder\n","    autoencoder.fit(\n","        apply_mask(dataset[0], mask_percentage),\n","        dataset[0],\n","        epochs=10,\n","        batch_size=32,\n","        validation_data=(apply_mask(dataset[1], mask_percentage), dataset[1]),\n","        verbose=2,\n","    )\n","\n","    # Evaluate autoencoder\n","    reconstructed_images = autoencoder.predict(apply_mask(dataset[2], mask_percentage))\n","    mse = mean_squared_error(dataset[2], reconstructed_images)\n","    mae = mean_absolute_error(dataset[2], reconstructed_images)\n","\n","    return mse, mae\n","\n","# Load the dataset\n","dataset_path = '/content/drive/MyDrive/surya/DL_Assignment/Fractal-2_Assignment-2/VOC2007/VOCdevkit/VOC2007/Output'\n","dataset = load_dataset(dataset_path)\n","\n","# Experiment 3: Varying bottleneck dimensions\n","bottleneck_dimensions = [256, 128, 64, 32, 16]\n","reconstruction_errors = []\n","\n","for bottleneck_dim in bottleneck_dimensions:\n","    mse, _ = train_and_evaluate_autoencoder(bottleneck_dim, 0, dataset)\n","    reconstruction_errors.append(mse)\n","\n","best_bottleneck_dim = bottleneck_dimensions[np.argmin(reconstruction_errors)]\n","\n","# Experiment 4: Masking strategy\n","mask_percentages = [0.2, 0.4, 0.6, 0.8]\n","mse_results = []\n","\n","for mask_percentage in mask_percentages:\n","    mse, _ = train_and_evaluate_autoencoder(best_bottleneck_dim, mask_percentage, dataset)\n","    mse_results.append(mse)\n","\n","# Experiment 5: Plot reconstruction errors\n","plt.figure(figsize=(8, 6))\n","plt.plot(bottleneck_dimensions, reconstruction_errors, marker='o', label='Bottleneck Dimensions')\n","plt.plot(mask_percentages, mse_results, marker='o', label='Masking Strategy')\n","plt.xlabel('Bottleneck Dimension / Mask Percentage')\n","plt.ylabel('Mean Squared Error')\n","plt.legend()\n","plt.title('Reconstruction Error for Autoencoder Models')\n","plt.show()\n","\n","# Experiment 6: Evaluation\n","print(f\"Best Bottleneck Dimension: {best_bottleneck_dim}\")\n","\n","# Train the autoencoder with the best bottleneck dimension and evaluate\n","final_mse, final_mae = train_and_evaluate_autoencoder(best_bottleneck_dim, 0.4, dataset)\n","print(f\"Final MSE: {final_mse}\")\n","print(f\"Final MAE: {final_mae}\")\n"],"metadata":{"id":"mTt3lXQ1YyLW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from skimage.metrics import structural_similarity as ssim\n","\n","# Function to visualize and compare images\n","def visualize_images(original, masked, reconstructed, title):\n","    plt.figure(figsize=(15, 5))\n","\n","    # Original Image\n","    plt.subplot(1, 3, 1)\n","    plt.imshow(original)\n","    plt.title(\"Original Image\")\n","\n","    # Masked Image\n","    plt.subplot(1, 3, 2)\n","    plt.imshow(masked)\n","    plt.title(\"Masked Image\")\n","\n","    # Reconstructed Image\n","    plt.subplot(1, 3, 3)\n","    plt.imshow(reconstructed)\n","    plt.title(\"Reconstructed Image\")\n","\n","    plt.suptitle(title)\n","    plt.show()\n","\n","# Function to calculate Structural Similarity Index (SSI)\n","def calculate_ssim(original, reconstructed):\n","    return ssim(original, reconstructed, multichannel=True)\n","\n","# Load the best split and best masking strategy\n","best_split = '80-10-10'  # Choose the best split (e.g., '80-10-10')\n","best_bottleneck_dim = 256  # Choose the best bottleneck dimension\n","best_mask_percentage = 0.4  # Choose the best masking strategy (e.g., 0.4)\n","\n","# Load the dataset for the best split\n","best_dataset_path = '/content/drive/MyDrive/surya/DL_Assignment/Fractal-2_Assignment-2/VOC2007/VOCdevkit/VOC2007/Output/'\n","best_dataset = load_dataset(best_dataset_path)\n","\n","# Train and evaluate autoencoder for the best split and masking strategy\n","best_mse, best_mae = train_and_evaluate_autoencoder(best_bottleneck_dim, best_mask_percentage, best_dataset)\n","\n","# Visualize and compare images for a sample\n","sample_index = 0  # Choose an index from the dataset\n","original_image = best_dataset[2][sample_index]  # Test set image\n","masked_image = apply_mask(original_image, best_mask_percentage)\n","reconstructed_image = autoencoder.predict(masked_image[None, ...])\n","\n","visualize_images(original_image, masked_image[0], reconstructed_image[0], \"Image Comparison\")\n","\n","# Calculate SSI for image quality\n","ssi = calculate_ssim(original_image, reconstructed_image[0])\n","print(f\"SSI: {ssi}\")\n"],"metadata":{"id":"POGr5tpOe3z-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Task 2"],"metadata":{"id":"_S35hd9Pm79D"}},{"cell_type":"code","source":["# Import libraries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from sklearn.metrics import confusion_matrix, roc_auc_score\n","\n","# Download and preprocess the STL-10 dataset\n","transform = transforms.Compose(\n","    [transforms.Resize((28, 28)), # Resize the images to 28x28\n","     transforms.ToTensor(), # Convert the images to tensors\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # Normalize the pixel values\n","\n","trainset = torchvision.datasets.STL10(root='/content/drive/MyDrive/surya/DL_Assignment/Fractal-2_Assignment-2/VOC2007/VOCdevkit/VOC2007/JPEGImages', split='train', download=True, transform=transform) # Load the train set\n","testset = torchvision.datasets.STL10(root='/content/drive/MyDrive/surya/DL_Assignment/Fractal-2_Assignment-2/VOC2007/VOCdevkit/VOC2007/JPEGImages', split='test', download=True, transform=transform) # Load the test set\n","unlabeledset = torchvision.datasets.STL10(root='/content/drive/MyDrive/surya/DL_Assignment/Fractal-2_Assignment-2/VOC2007/VOCdevkit/VOC2007/JPEGImages', split='unlabeled', download=True, transform=transform) # Load the unlabeled set\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2) # Create a data loader for the train set\n","testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2) # Create a data loader for the test set\n","unlabeledloader = torch.utils.data.DataLoader(unlabeledset, batch_size=32, shuffle=True, num_workers=2) # Create a data loader for the unlabeled set\n","\n","# Define an autoencoder with three hidden layers and a bottleneck dimension of 256\n","class Autoencoder(nn.Module):\n","    def __init__(self):\n","        super(Autoencoder, self).__init__()\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(3, 16, 3, padding=1), # First convolutional layer with 16 filters\n","            nn.ReLU(), # First activation function\n","            nn.MaxPool2d(2), # First pooling layer to reduce the spatial dimensions by half\n","            nn.Conv2d(16, 8, 3, padding=1), # Second convolutional layer with 8 filters\n","            nn.ReLU(), # Second activation function\n","            nn.MaxPool2d(2), # Second pooling layer to reduce the spatial dimensions by half\n","            nn.Conv2d(8, 8, 3, padding=1), # Third convolutional layer with 8 filters\n","            nn.ReLU(), # Third activation function\n","            nn.MaxPool2d(2) # Third pooling layer to reduce the spatial dimensions by half and produce the encoded representation of size (4, 4, 8)\n","        )\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(8, 8, 3), # First deconvolutional layer with 8 filters\n","            nn.ReLU(), # First activation function\n","            nn.Upsample(scale_factor=2), # First upsampling layer to increase the spatial dimensions by two times\n","            nn.ConvTranspose2d(8, 8, 3), # Second deconvolutional layer with 8 filters\n","            nn.ReLU(), # Second activation function\n","            nn.Upsample(scale_factor=2), # Second upsampling layer to increase the spatial dimensions by two times\n","            nn.ConvTranspose2d(8, 16, 3), # Third deconvolutional layer with 16 filters\n","            nn.ReLU(), # Third activation function\n","            nn.Upsample(scale_factor=2), # Third upsampling layer to increase the spatial dimensions by two times\n","            nn.ConvTranspose2d(16, 3, 3, padding=1), # Final layer to produce the decoded image of size (28, 28, 3)\n","            nn.Sigmoid() # Final activation function\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x) # Encode the input image\n","        x = self.decoder(x) # Decode the encoded representation\n","        return x\n","\n","# Instantiate the autoencoder model\n","autoencoder = Autoencoder()\n","\n","# Define the loss function and the optimizer\n","criterion = nn.MSELoss() # Use mean squared error as the loss function\n","optimizer = optim.Adam(autoencoder.parameters()) # Use Adam as the optimizer\n","\n","# Train the autoencoder on the unlabeled data for 50 epochs\n","num_epochs = 50\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for i, data in enumerate(unlabeledloader, 0):\n","        inputs, _ = data # Get the inputs and ignore the labels\n","        optimizer.zero_grad() # Zero the parameter gradients\n","        outputs = autoencoder(inputs) # Forward pass\n","        loss = criterion(outputs, inputs) # Compute the loss\n","        loss.backward() # Backward pass\n","        optimizer.step() # Update"],"metadata":{"id":"lcGDPFW8m9yW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"CMj0CUO2m7La"}}]}